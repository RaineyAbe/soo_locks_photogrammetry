{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2c9d518",
   "metadata": {},
   "source": [
    "# Calibrate cameras, create initial orthoimage and partial DSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aac52a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "import shutil\n",
    "# Ignore warnings (rasterio throws a warning whenever an image is not georeferenced. Annoying in this case.)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Locate image files\n",
    "data_folder = '/Users/rdcrlrka/Research/Soo_locks'\n",
    "image_folder = os.path.join(data_folder, '20251001_imagery', 'frames_IR')\n",
    "image_list = sorted(glob(os.path.join(image_folder, '*.tiff')))\n",
    "print(f\"{len(image_list)} images located\")\n",
    "\n",
    "# Grab other input files\n",
    "refdem_file = os.path.join(os.getcwd(), '..', 'inputs', '20251001_Soo_Model_1cm_mean_UTM19N-fake_filled_cropped.tif')\n",
    "gcp_folder = os.path.join(os.getcwd(), '..', 'inputs', 'gcp')\n",
    "cams_file = os.path.join(os.getcwd(), '..', 'inputs', 'cams_lonlat-fake.txt')\n",
    "\n",
    "# Define output folders\n",
    "out_folder = image_folder + '_proc_out'\n",
    "os.makedirs(out_folder, exist_ok=True)\n",
    "new_image_folder = os.path.join(out_folder, 'single_band_images')\n",
    "undistorted_folder = os.path.join(out_folder, 'undistorted_images_cams')\n",
    "init_ortho_folder = os.path.join(out_folder, 'init_ortho')\n",
    "init_stereo_folder = os.path.join(out_folder, 'init_stereo')\n",
    "ba_folder = os.path.join(out_folder, 'bundle_adjust')\n",
    "final_ortho_folder = os.path.join(out_folder, 'final_ortho')\n",
    "final_stereo_folder = os.path.join(out_folder, 'final_stereo')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c8f447",
   "metadata": {},
   "source": [
    "## Merge GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef6f860",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcp_merged_file = os.path.join(gcp_folder, 'GCP_merged.csv')\n",
    "if not os.path.exists(gcp_merged_file):\n",
    "\n",
    "    gcp_list = sorted(glob(os.path.join(gcp_folder, '*.gcp')))\n",
    "    df_list = []\n",
    "    for gcp_file in gcp_list:\n",
    "        df = pd.read_csv(\n",
    "            gcp_file,\n",
    "            sep=',',\n",
    "            header=None,\n",
    "            skiprows=[0],\n",
    "            names=[\n",
    "                'point_index', 'lat', 'lon', 'Z', 'lat_sigma', 'lon_sigma', 'Z_sigma', \n",
    "                'image_path', 'col_sample', 'row_sample', 'use_lat', 'use_lon']\n",
    "        )\n",
    "        df_list += [df]\n",
    "\n",
    "    dfs = pd.concat(df_list).reset_index(drop=True)\n",
    "\n",
    "    # reproject to UTM zone 19N\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        dfs,\n",
    "        geometry=[Point(x,y) for x,y in dfs[['lon', 'lat']].values],\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "    gdf = gdf.to_crs(\"EPSG:32619\")\n",
    "    gdf['X'] = [x.coords.xy[0][0] for x in gdf['geometry']]\n",
    "    gdf['Y'] = [x.coords.xy[1][0] for x in gdf['geometry']]\n",
    "\n",
    "    # use just the image file name\n",
    "    gdf['image_name'] = [os.path.basename(x) for x in gdf['image_path']]\n",
    "\n",
    "    # select relevant columns\n",
    "    gdf = gdf[['image_name', 'X', 'Y', 'Z', 'col_sample', 'row_sample']]\n",
    "\n",
    "    # save to file\n",
    "    gdf.to_csv(gcp_merged_file, sep=',', index=False)\n",
    "    print('Saved merged GCP:', gcp_merged_file)\n",
    "else:\n",
    "    print('Merged GCP already exists in file, skipping merge.')\n",
    "\n",
    "\n",
    "# Reproject from UTM zone 19 N to ECEF for use in ASP\n",
    "gcp_merged_ecef_file = os.path.join(gcp_folder, 'GCP_merged_ECEF.csv')\n",
    "if not os.path.exists(gcp_merged_ecef_file):\n",
    "    # Load the merged file\n",
    "    gcp_merged = pd.read_csv(gcp_merged_file, sep=',')\n",
    "\n",
    "    # Reproject from UTM to ECEF\n",
    "    geom = [Point(x,y,z) for x,y,z in gcp_merged[['X', 'Y', 'Z']].values]\n",
    "    gdf = gpd.GeoDataFrame(geometry=geom, crs=\"EPSG:32619\")\n",
    "    gdf = gdf.to_crs(\"EPSG:4978\")\n",
    "    gcp_merged['X'] = [x.x for x in gdf['geometry']]\n",
    "    gcp_merged['Y'] = [x.y for x in gdf['geometry']]\n",
    "    gcp_merged['Z'] = [x.z for x in gdf['geometry']]\n",
    "\n",
    "    # Save to file\n",
    "    gcp_merged.to_csv(gcp_merged_ecef_file, sep=',', index=False)\n",
    "    print('Saved merged GCP in ECEF coordinates:', gcp_merged_ecef_file)\n",
    "else:\n",
    "    print('Merged GCP in ECEF coordinates already exists in file, skipping reprojection.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c79d1b",
   "metadata": {},
   "source": [
    "## Convert images to single band in case they're RGB\n",
    "\n",
    "A couple IR images (near the windows) were captured in RGB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d63e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(new_image_folder, exist_ok=True)\n",
    "\n",
    "# iterate over images\n",
    "print('Saving single-band images to:', new_image_folder)\n",
    "for image_file in tqdm(image_list):\n",
    "    # convert images to single band\n",
    "    out_fn = os.path.join(new_image_folder, os.path.basename(image_file))\n",
    "    if os.path.exists(out_fn):\n",
    "        continue\n",
    "    cmd = [\n",
    "        \"gdal_translate\",\n",
    "        \"-b\", \"1\",\n",
    "        image_file, out_fn\n",
    "    ]\n",
    "    subprocess.run(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105faf4f",
   "metadata": {},
   "source": [
    "## Calibrate cameras using GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c64d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tsai(tsai_dict, filename):\n",
    "    \"\"\"\n",
    "    Save a TSAI (.tsai) pinhole camera file from a dictionary.\n",
    "    \"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(\"VERSION_4\\n\")\n",
    "        f.write(\"PINHOLE\\n\")\n",
    "        f.write(f\"fu = {tsai_dict['fu']}\\n\")\n",
    "        f.write(f\"fv = {tsai_dict['fv']}\\n\")\n",
    "        f.write(f\"cu = {tsai_dict['cu']}\\n\")\n",
    "        f.write(f\"cv = {tsai_dict['cv']}\\n\")\n",
    "        f.write(f\"u_direction = {' '.join(map(str, tsai_dict['u_direction']))}\\n\")\n",
    "        f.write(f\"v_direction = {' '.join(map(str, tsai_dict['v_direction']))}\\n\")\n",
    "        f.write(f\"w_direction = {' '.join(map(str, tsai_dict['w_direction']))}\\n\")\n",
    "        f.write(f\"C = {' '.join(map(str, tsai_dict['C']))}\\n\")\n",
    "        f.write(\"R = \" + \" \".join(map(str, tsai_dict['R'].flatten())) + \"\\n\")\n",
    "        f.write(f\"pitch = {tsai_dict['pitch']}\\n\")\n",
    "        # Add small distortion for bundle adjust\n",
    "        f.write(\"TSAI\\n\")\n",
    "        f.write(\"k1 = -1e-6\\nk2 = 1e-6\\np1 = 0\\np2 = 0\\nk3 = 1e-6\\n\")\n",
    "\n",
    "\n",
    "def calibrate_shared_intrinsics(image_files, gcp_file, output_folder=None, file_prefix=None):\n",
    "    object_points_list = []\n",
    "    image_points_list = []\n",
    "    image_size = None\n",
    "\n",
    "    # --- Load merged GCP ---\n",
    "    gcp = pd.read_csv(gcp_file, sep=',')    \n",
    "\n",
    "    # --- Compile GCP (object) and image (pixel) points --- \n",
    "    for image_file in image_files:\n",
    "        # Subset GCP to image\n",
    "        gcp_image = gcp.loc[gcp['image_name']==os.path.basename(image_file)]\n",
    "\n",
    "        # Object and image points\n",
    "        obj_pts = gcp_image[['X','Y','Z']].values.astype(np.float32)\n",
    "        image_pts = gcp_image[['col_sample','row_sample']].values.astype(np.float32)\n",
    "        obj_pts = obj_pts.reshape(-1,1,3)\n",
    "        image_pts = image_pts.reshape(-1,1,2)\n",
    "\n",
    "        object_points_list.append(obj_pts)\n",
    "        image_points_list.append(image_pts)\n",
    "\n",
    "        # get image size\n",
    "        if image_size is None:\n",
    "            image = cv2.imread(image_file, cv2.IMREAD_GRAYSCALE)\n",
    "            image_size = (image.shape[1], image.shape[0])\n",
    "\n",
    "    if len(object_points_list) == 0:\n",
    "        raise ValueError(\"No valid images for calibration\")\n",
    "    \n",
    "    # --- Subtract the mean of all object points for better calculation ---\n",
    "    all_obj_pts = np.vstack([op.reshape(-1,3) for op in object_points_list])\n",
    "    object_points_mean = all_obj_pts.mean(axis=0)\n",
    "    object_points_list = [x - object_points_mean for x in object_points_list]\n",
    "\n",
    "    # --- Initialize intrinsics --- \n",
    "    fx = fy = 2000\n",
    "    cx = image_size[0] / 2\n",
    "    cy = image_size[1] / 2\n",
    "    K_init = np.array([\n",
    "        [fx,0,cx],\n",
    "        [0,fy,cy],\n",
    "        [0,0,1]\n",
    "        ], dtype=np.float64)\n",
    "    dist_init = np.zeros(8)\n",
    "    flags = (\n",
    "        cv2.CALIB_USE_INTRINSIC_GUESS\n",
    "        | cv2.CALIB_FIX_PRINCIPAL_POINT \n",
    "        | cv2.CALIB_ZERO_TANGENT_DIST\n",
    "        )\n",
    "\n",
    "    # --- Calibrate cameras ---\n",
    "    rms, K, dist, rvecs, tvecs = cv2.calibrateCamera(\n",
    "        object_points_list,\n",
    "        image_points_list,\n",
    "        image_size,\n",
    "        K_init,\n",
    "        dist_init,\n",
    "        flags=flags\n",
    "    )\n",
    "\n",
    "    print(\"Shared calibration done\")\n",
    "    print(\"RMS reprojection error:\", rms)\n",
    "    print(\"Camera matrix K:\\n\", K)\n",
    "    print(\"Distortion coefficients:\", dist.ravel())\n",
    "\n",
    "    # --- Calculate adjusted camera matrix ---\n",
    "    w,h = image_size\n",
    "    K_new, _ = cv2.getOptimalNewCameraMatrix(K, dist, (w,h), 1, (w, h))\n",
    "\n",
    "    # --- Save camera calibration parameters ---\n",
    "    calib_file = os.path.join(output_folder, file_prefix + 'camera_calibration_params.csv')\n",
    "    calib_df = pd.DataFrame({\n",
    "        'image_name': image_files,\n",
    "        'K': [K]*len(image_files),\n",
    "        'K_new': [K_new]*len(image_files),\n",
    "        'distortion_coefficients': [dist]*len(image_files),\n",
    "        'RMS': [rms]*len(image_files)\n",
    "    })\n",
    "    calib_df.to_csv(calib_file, index=False)\n",
    "    print(\"Saved calibration params:\", calib_file)\n",
    "\n",
    "    # --- Save undistorted images and camera extrinsics ---\n",
    "    for i, image_file in enumerate(image_files):\n",
    "        # Undistort image\n",
    "        image_undistorted_file = os.path.join(\n",
    "            output_folder, \n",
    "            os.path.splitext(os.path.basename(image_file))[0] + '_undistorted.tiff'\n",
    "            )\n",
    "        image = cv2.imread(image_file, cv2.IMREAD_GRAYSCALE)\n",
    "        image_undistorted = cv2.undistort(image, K, dist, None, K_new)\n",
    "        cv2.imwrite(image_undistorted_file, image_undistorted)\n",
    "\n",
    "        # Convert rotation matrix from world -> camera to camera -> world\n",
    "        R_wc = cv2.Rodrigues(rvecs[i])[0]\n",
    "        R_cw = R_wc.T\n",
    "\n",
    "        # Calculate camera center\n",
    "        C = -R_cw @ tvecs[i].reshape(3) + object_points_mean.reshape(3)\n",
    "\n",
    "        tsai_dict = {\n",
    "            'fu': K_new[0,0],\n",
    "            'fv': K_new[1,1],\n",
    "            'cu': K_new[0,2],\n",
    "            'cv': K_new[1,2],\n",
    "            'u_direction': [1,0,0],\n",
    "            'v_direction': [0,1,0],\n",
    "            'w_direction': [0,0,1],\n",
    "            'C': C,\n",
    "            'R': R_cw,\n",
    "            'pitch': 1\n",
    "        }\n",
    "\n",
    "        tsai_file = os.path.join(\n",
    "            output_folder, \n",
    "            os.path.splitext(os.path.basename(image_file))[0] + '_undistorted.tsai'\n",
    "            )\n",
    "        save_tsai(tsai_dict, tsai_file)\n",
    "\n",
    "    return\n",
    "\n",
    "os.makedirs(undistorted_folder, exist_ok=True)\n",
    "\n",
    "# GROUP 1\n",
    "print('\\nGROUP 1: ch01-08\\n----------')\n",
    "image_list = sorted(glob(os.path.join(new_image_folder, '*.tiff')))[0:8]\n",
    "# calculate shared calibration\n",
    "print('Optimizing shared camera intrinsics using GCP...')\n",
    "calibrate_shared_intrinsics(image_list, gcp_merged_ecef_file, undistorted_folder, file_prefix='group1-')\n",
    "\n",
    "# GROUP 2\n",
    "print('\\nGROUP 2: ch09-16\\n----------')\n",
    "image_list = sorted(glob(os.path.join(new_image_folder, '*.tiff')))[8:]\n",
    "# calculate shared calibration\n",
    "print('Optimizing shared camera intrinsics using GCP...')\n",
    "calibrate_shared_intrinsics(image_list, gcp_merged_ecef_file, undistorted_folder, file_prefix='group2-')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec464908",
   "metadata": {},
   "source": [
    "## Initial orthorectification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf51adfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(init_ortho_folder, exist_ok=True)\n",
    "\n",
    "image_list = sorted(glob(os.path.join(undistorted_folder, '*_undistorted.tiff')))\n",
    "cam_list = sorted(glob(os.path.join(undistorted_folder, '*_undistorted.tsai')))\n",
    "\n",
    "# Mapproject\n",
    "for image_file, cam_file in zip(image_list, cam_list):\n",
    "    image_out_file = os.path.join(init_ortho_folder, os.path.basename(image_file).replace('.tiff', '_map.tiff'))\n",
    "    cmd = [\n",
    "        'mapproject',\n",
    "        '--threads', '12',\n",
    "        '--nodata-value', '0',\n",
    "        '--tr', '0.003',\n",
    "        refdem_file, image_file, cam_file, image_out_file\n",
    "    ]\n",
    "    subprocess.run(cmd)\n",
    "\n",
    "# Mosaic orthoimages\n",
    "print('\\nMosaicking orthoimages')\n",
    "image_list = sorted(glob(os.path.join(init_ortho_folder, '*.tiff')))\n",
    "mosaic_file = os.path.join(init_ortho_folder, f'orthomosaic.tif')\n",
    "fnc = shutil.which('gdal_merge.py')\n",
    "cmd = [\n",
    "    'python', fnc,\n",
    "    '-o', mosaic_file,\n",
    "    '-n', '0',\n",
    "    '-a_nodata', '-9999'\n",
    "] + image_list\n",
    "subprocess.run(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3910bacc",
   "metadata": {},
   "source": [
    "## Run stereo preprocessing to create dense match files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df298f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_stereo_folder = os.path.join(out_folder, 'init_stereo')\n",
    "os.makedirs(init_stereo_folder, exist_ok=True)\n",
    "\n",
    "image_list = sorted(glob(os.path.join(undistorted_folder, '*.tiff')))\n",
    "cam_list = sorted(glob(os.path.join(undistorted_folder, '*.tsai')))\n",
    "\n",
    "# Set up image pairs\n",
    "image1_list, image2_list = image_list[0:-1], image_list[1:]\n",
    "cam1_list, cam2_list = cam_list[0:-1], cam_list[1:]\n",
    "\n",
    "# skip the 8/9 cams pair (different intrinsics solving during bundle adjust)\n",
    "iskip = [i for i in range(0,len(image1_list)) if 'ch08' in image1_list[i]][0]\n",
    "image1_list = image1_list[0:iskip] + image1_list[iskip+1:]\n",
    "image2_list = image2_list[0:iskip] + image2_list[iskip+1:]\n",
    "cam1_list = cam1_list[0:iskip] + cam1_list[iskip+1:]\n",
    "cam2_list = cam2_list[0:iskip] + cam2_list[iskip+1:]\n",
    "\n",
    "# Iterate over pairs\n",
    "for i in tqdm(range(len(image1_list))):\n",
    "    image1, image2 = image1_list[i], image2_list[i]\n",
    "    cam1, cam2 = cam1_list[i], cam2_list[i]\n",
    "\n",
    "    pair_prefix = os.path.join(\n",
    "        init_stereo_folder,\n",
    "        os.path.splitext(os.path.basename(image1))[0] + '__' + os.path.splitext(os.path.basename(image2))[0],\n",
    "        'run'\n",
    "        )\n",
    "    \n",
    "    cmd = [\n",
    "        'parallel_stereo',\n",
    "        '--threads-singleprocess', '12',\n",
    "        '--threads-multiprocess', '12',\n",
    "        '--stop-point', '1',\n",
    "        image1, image2,\n",
    "        cam1, cam2,\n",
    "        pair_prefix,\n",
    "    ]\n",
    "    subprocess.run(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d9a851",
   "metadata": {},
   "source": [
    "## Bundle adjust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98bd743",
   "metadata": {},
   "outputs": [],
   "source": [
    "asp_folder = '/Applications/StereoPipeline-3.6.0-alpha-2025-10-15-arm64-OSX/bin'\n",
    "\n",
    "ba_folder = os.path.join(out_folder, 'bundle_adjust')\n",
    "os.makedirs(ba_folder, exist_ok=True)\n",
    "\n",
    "image_list = sorted(glob(os.path.join(undistorted_folder, '*.tiff')))\n",
    "cam_list = sorted(glob(os.path.join(undistorted_folder, '*.tsai')))\n",
    "\n",
    "# Copy dense matches to bundle adjust folder\n",
    "match_list = sorted(glob(os.path.join(init_stereo_folder, '*', '*.match')))\n",
    "for match_file in match_list:\n",
    "    # get image pair\n",
    "    pair = os.path.dirname(match_file).split('/')[-1]\n",
    "    # check which group it's in\n",
    "    first_channel = pair.split('ch')[1][0:2]\n",
    "    group = 1 if float(first_channel) < 9 else 2\n",
    "    # define output file\n",
    "    match_out_file = os.path.join(\n",
    "        ba_folder, \n",
    "        f'run_group{group}-{pair}' + '.match'\n",
    "        )\n",
    "    # copy\n",
    "    _ = shutil.copy2(match_file, match_out_file)\n",
    "\n",
    "# GROUP 1\n",
    "# print('\\nGROUP 1: ch01-08\\n----------')\n",
    "# image_list_group1 = image_list[0:8]\n",
    "# cam_list_group1 = cam_list[0:8]\n",
    "# # Run bundle adjust\n",
    "# cmd = [\n",
    "#     os.path.join(asp_folder, 'parallel_bundle_adjust'),\n",
    "#     '--threads', '12',\n",
    "#     '--num-iterations', '2000',\n",
    "#     '--num-passes', '2',\n",
    "#     '--inline-adjustments',\n",
    "#     '--force-reuse-match-files',\n",
    "#     '--fixed-distortion-indices', '2,3',\n",
    "#     '--heights-from-dem', refdem_file,\n",
    "#     '--heights-from-dem-uncertainty', '0.01',\n",
    "#     '--solve-intrinsics',\n",
    "#     '--intrinsics-to-share', 'optical_center,other_intrinsics',\n",
    "#     '--intrinsics-to-float', 'all',\n",
    "#     '-o', os.path.join(ba_folder, 'run_group1')\n",
    "# ] + image_list_group1 + cam_list_group1\n",
    "# subprocess.run(cmd)\n",
    "\n",
    "# GROUP 2\n",
    "print('\\nGROUP 2: ch09-16\\n----------')\n",
    "image_list_group2 = image_list[8:]\n",
    "cam_list_group2 = cam_list[8:]\n",
    "# Run bundle adjust\n",
    "cmd = [\n",
    "    os.path.join(asp_folder, 'parallel_bundle_adjust'),\n",
    "    '--threads', '12',\n",
    "    '--num-iterations', '2000',\n",
    "    '--num-passes', '2',\n",
    "    '--inline-adjustments',\n",
    "    '--force-reuse-match-files',\n",
    "    '--fixed-distortion-indices', '2,3',\n",
    "    '--heights-from-dem', refdem_file,\n",
    "    '--heights-from-dem-uncertainty', '0.01',\n",
    "    '--solve-intrinsics',\n",
    "    '--intrinsics-to-share', 'optical_center,other_intrinsics',\n",
    "    '--intrinsics-to-float', 'all',\n",
    "    '-o', os.path.join(ba_folder, 'run_group2')\n",
    "] + image_list_group2 + cam_list_group2\n",
    "subprocess.run(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39935435",
   "metadata": {},
   "source": [
    "## Final orthorectification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9facfc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(final_ortho_folder, exist_ok=True)\n",
    "\n",
    "image_list = sorted(glob(os.path.join(undistorted_folder, '*_undistorted.tiff')))\n",
    "cam_list = sorted(glob(os.path.join(ba_folder, '*.tsai')))\n",
    "\n",
    "# Mapproject\n",
    "pbar = tqdm(total=len(image_list))\n",
    "for image_file, cam_file in zip(image_list, cam_list):\n",
    "    image_out_file = os.path.join(final_ortho_folder, os.path.basename(image_file).replace('.tiff', '_map.tiff'))\n",
    "    cmd = [\n",
    "        os.path.join(asp_folder, 'mapproject'),\n",
    "        '--threads', '12',\n",
    "        '--nodata-value', '0',\n",
    "        '--tr', '0.003',\n",
    "        refdem_file, image_file, cam_file, image_out_file\n",
    "    ]\n",
    "    subprocess.run(cmd)\n",
    "    pbar.update(1)\n",
    "\n",
    "# Mosaic orthoimages\n",
    "print('\\nMosaicking orthoimages')\n",
    "image_list = sorted(glob(os.path.join(final_ortho_folder, '*.tiff')))\n",
    "mosaic_file = os.path.join(final_ortho_folder, f'orthomosaic.tif')\n",
    "fnc = shutil.which('gdal_merge.py')\n",
    "cmd = [\n",
    "    'python', fnc,\n",
    "    '-o', mosaic_file,\n",
    "    '-n', '0',\n",
    "    '-a_nodata', '-9999'\n",
    "] + image_list\n",
    "subprocess.run(cmd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03085baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing hybrid approach\n",
    "\n",
    "K = np.array([\n",
    "    [5.70449177e+03, 0.00000000e+00, 1.92000000e+03], \n",
    "    [0.00000000e+00, 5.69647956e+03, 1.08000000e+03], \n",
    "    [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]\n",
    "    ])\n",
    "\n",
    "dist = np.array([-2.32172794, 8.16330791, 0, 0, -15.0270846])\n",
    "\n",
    "image_file = glob(os.path.join(new_image_folder, '*ch01*.tiff'))[0]\n",
    "image = cv2.imread(image_file, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "h,w = image.shape\n",
    "K_new, roi = cv2.getOptimalNewCameraMatrix(\n",
    "        K, dist, (w, h), 1, (w, h)\n",
    "    )\n",
    "image_undistorted = cv2.undistort(image, K, dist, None, K_new)\n",
    "image_undistorted_file = os.path.join(out_folder, 'testing', os.path.basename(image_file).replace('.tiff', 'undistorted_full.tiff'))\n",
    "cv2.imwrite(image_undistorted_file, image_undistorted)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(image_undistorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c944723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc63f415",
   "metadata": {},
   "source": [
    "## Plot current overlap and gaps in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c7cbbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soo_locs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
