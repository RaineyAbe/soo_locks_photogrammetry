{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2c9d518",
   "metadata": {},
   "source": [
    "# Calibrate cameras, create initial orthoimage and partial DSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aac52a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "import pyproj\n",
    "import shutil\n",
    "# Ignore warnings (rasterio throws a warning whenever an image is not georeferenced. Annoying in this case.)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Locate image files\n",
    "data_folder = '/Users/rdcrlrka/Research/Soo_locks'\n",
    "image_folder = os.path.join(data_folder, '20251001_imagery', 'frames_IR')\n",
    "image_list = sorted(glob(os.path.join(image_folder, '*.tiff')))\n",
    "print(f\"{len(image_list)} images located\")\n",
    "\n",
    "# Grab other input files\n",
    "refdem_file = os.path.join(os.getcwd(), '..', 'inputs', '20251001_Soo_Model_1cm_mean_UTM19N-fake_filled.tif')\n",
    "gcp_folder = os.path.join(os.getcwd(), '..', 'inputs', 'gcp')\n",
    "cams_file = os.path.join(os.getcwd(), '..', 'inputs', 'cams_lonlat-fake.txt')\n",
    "\n",
    "# Define output folders\n",
    "out_folder = image_folder + '_proc_out'\n",
    "os.makedirs(out_folder, exist_ok=True)\n",
    "new_image_folder = os.path.join(out_folder, 'single_band_images')\n",
    "undistorted_folder = os.path.join(out_folder, 'undistorted_images_cams')\n",
    "init_ortho_folder = os.path.join(out_folder, 'init_ortho')\n",
    "init_stereo_folder = os.path.join(out_folder, 'init_stereo')\n",
    "ba_folder = os.path.join(out_folder, 'bundle_adjust')\n",
    "final_ortho_folder = os.path.join(out_folder, 'final_ortho')\n",
    "final_stereo_folder = os.path.join(out_folder, 'final_stereo')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c8f447",
   "metadata": {},
   "source": [
    "## Merge GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef6f860",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcp_merged_file = os.path.join(gcp_folder, 'GCP_merged.csv')\n",
    "if not os.path.exists(gcp_merged_file):\n",
    "\n",
    "    gcp_list = sorted(glob(os.path.join(gcp_folder, '*.gcp')))\n",
    "    df_list = []\n",
    "    for gcp_file in gcp_list:\n",
    "        df = pd.read_csv(\n",
    "            gcp_file,\n",
    "            sep=',',\n",
    "            header=None,\n",
    "            skiprows=[0],\n",
    "            names=[\n",
    "                'point_index', 'lat', 'lon', 'Z', 'lat_sigma', 'lon_sigma', 'Z_sigma', \n",
    "                'image_path', 'col_sample', 'row_sample', 'use_lat', 'use_lon']\n",
    "        )\n",
    "        df_list += [df]\n",
    "\n",
    "    dfs = pd.concat(df_list).reset_index(drop=True)\n",
    "\n",
    "    # reproject to UTM zone 19N\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        dfs,\n",
    "        geometry=[Point(x,y) for x,y in dfs[['lon', 'lat']].values],\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "    gdf = gdf.to_crs(\"EPSG:32619\")\n",
    "    gdf['X'] = [x.coords.xy[0][0] for x in gdf['geometry']]\n",
    "    gdf['Y'] = [x.coords.xy[1][0] for x in gdf['geometry']]\n",
    "\n",
    "    # use just the image file name\n",
    "    gdf['image_name'] = [os.path.basename(x) for x in gdf['image_path']]\n",
    "\n",
    "    # select relevant columns\n",
    "    gdf = gdf[['image_name', 'X', 'Y', 'Z', 'col_sample', 'row_sample']]\n",
    "\n",
    "    # save to file\n",
    "    gdf.to_csv(gcp_merged_file, sep=',', index=False)\n",
    "    print('Saved merged GCP:', gcp_merged_file)\n",
    "else:\n",
    "    print('Merged GCP already exists in file, skipping merge.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c79d1b",
   "metadata": {},
   "source": [
    "## Convert images to single band in case they're RGB\n",
    "\n",
    "A couple IR images (near the windows) were captured in RGB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d63e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(new_image_folder, exist_ok=True)\n",
    "\n",
    "# iterate over images\n",
    "print('Saving single-band images to:', new_image_folder)\n",
    "for image_file in tqdm(image_list):\n",
    "    # convert images to single band\n",
    "    out_fn = os.path.join(new_image_folder, os.path.basename(image_file))\n",
    "    if os.path.exists(out_fn):\n",
    "        continue\n",
    "    cmd = [\n",
    "        \"gdal_translate\",\n",
    "        \"-b\", \"1\",\n",
    "        image_file, out_fn\n",
    "    ]\n",
    "    subprocess.run(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105faf4f",
   "metadata": {},
   "source": [
    "## Calibrate cameras using GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c64d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tsai(tsai_dict, filename):\n",
    "    \"\"\"\n",
    "    Save a TSAI (.tsai) pinhole camera file from a dictionary.\n",
    "    \"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(\"VERSION_4\\n\")\n",
    "        f.write(\"PINHOLE\\n\")\n",
    "        f.write(f\"fu = {tsai_dict['fu']}\\n\")\n",
    "        f.write(f\"fv = {tsai_dict['fv']}\\n\")\n",
    "        f.write(f\"cu = {tsai_dict['cu']}\\n\")\n",
    "        f.write(f\"cv = {tsai_dict['cv']}\\n\")\n",
    "        f.write(f\"u_direction = {' '.join(map(str, tsai_dict['u_direction']))}\\n\")\n",
    "        f.write(f\"v_direction = {' '.join(map(str, tsai_dict['v_direction']))}\\n\")\n",
    "        f.write(f\"w_direction = {' '.join(map(str, tsai_dict['w_direction']))}\\n\")\n",
    "        f.write(f\"C = {' '.join(map(str, tsai_dict['C']))}\\n\")\n",
    "        f.write(\"R = \" + \" \".join(map(str, tsai_dict['R'].flatten())) + \"\\n\")\n",
    "        f.write(f\"pitch = {tsai_dict['pitch']}\\n\")\n",
    "        f.write(\"NULL\\n\")\n",
    "\n",
    "\n",
    "def opencv_to_tsai_cam(K, rvec, tvec, object_points_mean, utm_crs=\"EPSG:32619\"):\n",
    "    \"\"\"\n",
    "    Convert an OpenCV camera to APS-compatible pinhole camera format.\n",
    "    See the ASP docs for more info: https://stereopipeline.readthedocs.io/en/latest/pinholemodels.html\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    K : np.ndarray (3x3)\n",
    "        intrinsic matrix\n",
    "    rvec : np.ndarray (3x1)\n",
    "        rotation vector (world -> camera)\n",
    "    tvec : np.ndarray (3x1)\n",
    "        translation vector (world -> camera) in UTM meters.\n",
    "    object_points_mean: np.ndarray (3,)\n",
    "        mean of the object points used in solvePnP (to restore absolute position)\n",
    "    utm_crs : str\n",
    "        CRS of the camera / object points (default EPSG:32619)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tsai_dict : dict\n",
    "        TSAI camera parameters ready for ASP\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute rotation matrix camera -> world in UTM\n",
    "    R_wc = cv2.Rodrigues(rvec)[0]   # world -> camera\n",
    "    R_cw = R_wc.T                   # camera -> world (UTM)\n",
    "\n",
    "    # Calculate camera center in UTM coordinates\n",
    "    C_utm = -R_cw @ tvec.reshape(3) + object_points_mean.reshape(3)\n",
    "\n",
    "    # Transform C to ECEF\n",
    "    transformer = pyproj.Transformer.from_crs(utm_crs, \"EPSG:4978\", always_xy=True)\n",
    "    X_ecef, Y_ecef, Z_ecef = transformer.transform(C_utm[0], C_utm[1], C_utm[2])\n",
    "    C_ecef = np.array([X_ecef, Y_ecef, Z_ecef])\n",
    "\n",
    "    # Calculate rotation from camera -> ECEF\n",
    "    # Transform the UTM axes directions to ECEF at the camera location\n",
    "    # We'll use a small delta along UTM axes to compute approximate ECEF rotation\n",
    "    delta = 1.0  # 1 meter\n",
    "    pts_utm = np.array([\n",
    "        C_utm,\n",
    "        C_utm + R_cw[:,0]*delta,  # X axis\n",
    "        C_utm + R_cw[:,1]*delta,  # Y axis\n",
    "        C_utm + R_cw[:,2]*delta   # Z axis\n",
    "    ])\n",
    "\n",
    "    # Transform these points to ECEF\n",
    "    ecef_pts = np.array([transformer.transform(x,y,z) for x,y,z in pts_utm])\n",
    "    # Build new axes in ECEF\n",
    "    X_axis = ecef_pts[1] - ecef_pts[0]\n",
    "    Y_axis = ecef_pts[2] - ecef_pts[0]\n",
    "    Z_axis = ecef_pts[3] - ecef_pts[0]\n",
    "\n",
    "    # Normalize axes\n",
    "    X_axis /= np.linalg.norm(X_axis)\n",
    "    Y_axis /= np.linalg.norm(Y_axis)\n",
    "    Z_axis /= np.linalg.norm(Z_axis)\n",
    "\n",
    "    R_ecef = np.stack([X_axis, Y_axis, Z_axis], axis=1)  # camera -> ECEF\n",
    "\n",
    "    # Build TSAI dictionary\n",
    "    tsai_dict = {\n",
    "        'VERSION': 4,\n",
    "        'TYPE': 'PINHOLE',\n",
    "        'fu': float(K[0,0]),\n",
    "        'fv': float(K[1,1]),\n",
    "        'cu': float(K[0,2]),\n",
    "        'cv': float(K[1,2]),\n",
    "        'u_direction': np.array([1,0,0]),\n",
    "        'v_direction': np.array([0,1,0]),\n",
    "        'w_direction': np.array([0,0,1]),\n",
    "        'C': C_ecef.astype(float),\n",
    "        'R': R_ecef.astype(float),\n",
    "        'pitch': 1\n",
    "    }\n",
    "\n",
    "    return tsai_dict\n",
    "\n",
    "\n",
    "def calibrate_shared_intrinsics(image_files, gcp_file, output_folder=None, file_prefix=None):\n",
    "    object_points_list = []\n",
    "    image_points_list = []\n",
    "    image_size = None\n",
    "\n",
    "    # --- Load merged GCP ---\n",
    "    gcp = pd.read_csv(gcp_file, sep=',')\n",
    "\n",
    "    # --- Compile GCP (object) and image (pixel) points --- \n",
    "    for image_file in image_files:\n",
    "        # Subset GCP to image\n",
    "        gcp_image = gcp.loc[gcp['image_name']==os.path.basename(image_file)]\n",
    "\n",
    "        # Object and image points\n",
    "        obj_pts = gcp_image[['X','Y','Z']].values.astype(np.float32)\n",
    "        image_pts = gcp_image[['col_sample','row_sample']].values.astype(np.float32)\n",
    "        obj_pts = obj_pts.reshape(-1,1,3)\n",
    "        image_pts = image_pts.reshape(-1,1,2)\n",
    "\n",
    "        object_points_list.append(obj_pts)\n",
    "        image_points_list.append(image_pts)\n",
    "\n",
    "        # get image size\n",
    "        if image_size is None:\n",
    "            image = cv2.imread(image_file, cv2.IMREAD_GRAYSCALE)\n",
    "            image_size = (image.shape[1], image.shape[0])\n",
    "\n",
    "    if len(object_points_list) == 0:\n",
    "        raise ValueError(\"No valid images for calibration\")\n",
    "\n",
    "    # --- Initialize intrinsics --- \n",
    "    fx = fy = 2000\n",
    "    cx = image_size[0] / 2\n",
    "    cy = image_size[1] / 2\n",
    "    K_init = np.array([\n",
    "        [fx,0,cx],\n",
    "        [0,fy,cy],\n",
    "        [0,0,1]\n",
    "        ], dtype=np.float64)\n",
    "    dist_init = np.zeros(8)\n",
    "    flags = (\n",
    "        cv2.CALIB_USE_INTRINSIC_GUESS\n",
    "        # | cv2.CALIB_RATIONAL_MODEL\n",
    "        | cv2.CALIB_FIX_PRINCIPAL_POINT \n",
    "        | cv2.CALIB_ZERO_TANGENT_DIST\n",
    "        )\n",
    "\n",
    "    # --- Calibrate cameras ---\n",
    "    rms, K, dist, _, _ = cv2.calibrateCamera(\n",
    "        object_points_list,\n",
    "        image_points_list,\n",
    "        image_size,\n",
    "        K_init,\n",
    "        dist_init,\n",
    "        flags=flags\n",
    "    )\n",
    "\n",
    "    # --- Calibrate mean of all object points ---\n",
    "    all_obj_pts = np.vstack([op.reshape(-1,3) for op in object_points_list])\n",
    "    object_points_mean = all_obj_pts.mean(axis=0)\n",
    "\n",
    "    print(\"Shared calibration done\")\n",
    "    print(\"RMS reprojection error:\", rms)\n",
    "    print(\"Camera matrix K:\\n\", K)\n",
    "    print(\"Distortion coefficients:\", dist.ravel())\n",
    "\n",
    "    # --- Save results to file ---\n",
    "    calib_file = os.path.join(output_folder, file_prefix + 'camera_calibration_params.csv')\n",
    "    calib_df = pd.DataFrame({\n",
    "        'image_name': image_files,\n",
    "        'K': [K]*len(image_files),\n",
    "        'distortions_coefficients': [dist]*len(image_files),\n",
    "        'RMS': [rms]*len(image_files)\n",
    "    })\n",
    "    calib_df.to_csv(calib_file, index=False, header=True)\n",
    "    print('Saved camera calibration parameters:', calib_file)\n",
    "        \n",
    "    return rms, K, dist, object_points_mean\n",
    "\n",
    "\n",
    "def undistort_calibrate_extrinsics(image_file, gcp_file, K, dist, object_points_mean, output_folder, plot_results=True):\n",
    "    \"\"\"\n",
    "    Undistort image, calculate per-image rvec/tvec, save TSAI and undistorted image\n",
    "    \"\"\"\n",
    "    image_name = os.path.basename(image_file)\n",
    "\n",
    "    # --- Construct the image (pixel) and object (GCP) points ---\n",
    "    # Load GCP\n",
    "    gcp = pd.read_csv(gcp_file, sep=',')\n",
    "    # subset to image\n",
    "    gcp = gcp.loc[gcp['image_name']==image_name]\n",
    "\n",
    "    # Object points mean-centered\n",
    "    obj_pts = gcp[['X','Y','Z']].values.astype(np.float32) - object_points_mean\n",
    "    image_pts = gcp[['col_sample','row_sample']].values.astype(np.float32)\n",
    "\n",
    "    # --- Solve for camera extrinsics ---\n",
    "    success, rvec, tvec = cv2.solvePnP(obj_pts, image_pts, K, dist, flags=cv2.SOLVEPNP_ITERATIVE)\n",
    "    if not success:\n",
    "        raise RuntimeError(f\"solvePnP failed for {image_file}\")\n",
    "\n",
    "    # --- Undistort the image and the GCP pixel coordinates ---\n",
    "    # Undistort the image\n",
    "    image = cv2.imread(image_file, cv2.IMREAD_GRAYSCALE)\n",
    "    h,w = image.shape\n",
    "    # K_new, _ = cv2.getOptimalNewCameraMatrix(K, dist, (w,h), 1, (w,h))\n",
    "    # image_undistorted = cv2.undistort(image, K, dist, None, K_new)\n",
    "    image_undistorted = cv2.undistort(image, K, dist, None, K)\n",
    "    \n",
    "    # Calculate new GCP pixel indices for the undistorted image\n",
    "    undistorted_pts = cv2.undistortPoints(image_pts, K, dist, P=K).reshape(-1, 2)\n",
    "    gcp['col_sample_undistorted'] = undistorted_pts[:, 0]\n",
    "    gcp['row_sample_undistorted'] = undistorted_pts[:, 1]\n",
    "\n",
    "    # --- Save results to file ---\n",
    "    # Undistorted image\n",
    "    image_undist_file = os.path.join(output_folder, os.path.splitext(image_name)[0] + '_undistorted.tiff')\n",
    "    cv2.imwrite(image_undist_file, image_undistorted)\n",
    "    # print(f\"Saved undistorted image: {image_undist_file}\")\n",
    "\n",
    "    # Prepare undistorted GCP for ASP-friendly saving\n",
    "    # reproject to lat-lon\n",
    "    gcp_reformat = gcp.copy()\n",
    "    gcp_reformat['geometry'] = [Point(x,y) for x,y in gcp[['X','Y']].values]\n",
    "    gcp_gdf = gpd.GeoDataFrame(geometry=gcp_reformat['geometry'], crs='EPSG:32619')\n",
    "    gcp_gdf = gcp_gdf.to_crs(\"EPSG:4326\")\n",
    "    gcp_reformat['lon'] = [x.coords.xy[0][0] for x in gcp_gdf['geometry']]\n",
    "    gcp_reformat['lat'] = [x.coords.xy[1][0] for x in gcp_gdf['geometry']]\n",
    "    # update image names\n",
    "    gcp_reformat['image_name'] = [x.replace('.tiff','_undistorted.tiff') for x in gcp_reformat['image_name']]\n",
    "    # add other relevant columns\n",
    "    gcp_reformat[['lat_std', 'lon_std', 'Z_std']] = 0.2, 0.2, 0.2\n",
    "    gcp_reformat[['use_lat', 'use_lon']] = 1, 1\n",
    "    # reorder and select appropriate columns\n",
    "    gcp_reformat = gcp_reformat[[\n",
    "        'lat', 'lon', 'Z', 'lat_std', 'lon_std', 'Z_std', \n",
    "        'image_name', 'col_sample_undistorted', 'row_sample_undistorted',\n",
    "        'use_lat', 'use_lon'\n",
    "        ]]\n",
    "    gcp_reformat.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Undistorted GCPs\n",
    "    gcp_undistorted_file = os.path.join(output_folder, os.path.splitext(image_name)[0] + '_undistorted.gcp')\n",
    "    gcp_reformat.to_csv(\n",
    "        gcp_undistorted_file, \n",
    "        sep=' ',\n",
    "        index=True,\n",
    "        header=False\n",
    "        )\n",
    "    # print(f\"Saved undistorted GCPs: {gcp_undistorted_file}\")\n",
    "\n",
    "    # TSAI camera model\n",
    "    tsai_file = os.path.join(output_folder, os.path.splitext(image_name)[0] + '_undistorted.tsai')\n",
    "    tsai_dict = opencv_to_tsai_cam(K, rvec, tvec, object_points_mean)\n",
    "    save_tsai(tsai_dict, tsai_file)\n",
    "    # print(f\"Saved TSAI: {tsai_file}\")\n",
    "\n",
    "    # --- Plot results ---\n",
    "    if plot_results:\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        ax[0].imshow(image, cmap='Grays_r')\n",
    "        ax[0].plot(\n",
    "            gcp['col_sample'], gcp['row_sample'], 'xr',\n",
    "            markersize=5, linewidth=1.5\n",
    "            )\n",
    "        ax[0].set_title('Original')\n",
    "        ax[1].imshow(image_undistorted, cmap='gray')\n",
    "        ax[1].plot(\n",
    "            gcp['col_sample_undistorted'], gcp['row_sample_undistorted'], 'xr',\n",
    "            markersize=5, linewidth=1.5\n",
    "            )\n",
    "        ax[1].set_title('Undistorted')\n",
    "        for axis in ax:\n",
    "            axis.set_xticks([]), axis.set_yticks([])\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # save to file\n",
    "        fig_file = os.path.join(output_folder, os.path.splitext(image_name)[0] + '_undistorted.png')\n",
    "        fig.savefig(fig_file, dpi=300, bbox_inches='tight')\n",
    "        # print('Saved results figure:', fig_file)\n",
    "\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "os.makedirs(undistorted_folder, exist_ok=True)\n",
    "\n",
    "# GROUP 1\n",
    "print('\\nGROUP 1: ch01-08\\n----------')\n",
    "image_list = sorted(glob(os.path.join(new_image_folder, '*.tiff')))[0:8]\n",
    "# calculate shared calibration\n",
    "print('Optimizing shared camera intrinsics using GCP...')\n",
    "rms, K, dist, object_points_mean = calibrate_shared_intrinsics(image_list, gcp_merged_file, undistorted_folder, file_prefix='group1-')\n",
    "# per-image processing\n",
    "print('Estimating camera extrics for individual images...')\n",
    "for image_file in tqdm(image_list):\n",
    "    undistort_calibrate_extrinsics(image_file, gcp_merged_file, K, dist, object_points_mean, undistorted_folder)\n",
    "\n",
    "# GROUP 2\n",
    "print('\\nGROUP 2: ch09-16\\n----------')\n",
    "image_list = sorted(glob(os.path.join(new_image_folder, '*.tiff')))[8:]\n",
    "# calculate shared calibration\n",
    "print('Optimizing shared camera intrinsics using GCP...')\n",
    "rms, K, dist, object_points_mean = calibrate_shared_intrinsics(image_list, gcp_merged_file, undistorted_folder, file_prefix='group2-')\n",
    "# per-image processing\n",
    "print('Estimating camera extrics for individual images...')\n",
    "for image_file in tqdm(image_list):\n",
    "    undistort_calibrate_extrinsics(image_file, gcp_merged_file, K, dist, object_points_mean, undistorted_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec464908",
   "metadata": {},
   "source": [
    "## Initial orthorectification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf51adfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(init_ortho_folder, exist_ok=True)\n",
    "\n",
    "image_list = sorted(glob(os.path.join(undistorted_folder, '*_undistorted.tiff')))\n",
    "cam_list = sorted(glob(os.path.join(undistorted_folder, '*.tsai')))\n",
    "\n",
    "# Mapproject\n",
    "pbar = tqdm(total=len(image_list))\n",
    "for image_file, cam_file in zip(image_list, cam_list):\n",
    "    image_out_file = os.path.join(init_ortho_folder, os.path.basename(image_file).replace('.tiff', '_map.tiff'))\n",
    "    cmd = [\n",
    "        'mapproject',\n",
    "        '--threads', '12',\n",
    "        '--nodata-value', '0',\n",
    "        '--tr', '0.003',\n",
    "        refdem_file, image_file, cam_file, image_out_file\n",
    "    ]\n",
    "    subprocess.run(cmd)\n",
    "    pbar.update(1)\n",
    "\n",
    "# Mosaic orthoimages\n",
    "print('\\nMosaicking orthoimages')\n",
    "image_list = sorted(glob(os.path.join(init_ortho_folder, '*.tiff')))\n",
    "mosaic_file = os.path.join(init_ortho_folder, f'orthomosaic.tif')\n",
    "fnc = shutil.which('gdal_merge.py')\n",
    "cmd = [\n",
    "    'python', fnc,\n",
    "    '-o', mosaic_file,\n",
    "    '-n', '0',\n",
    "    '-a_nodata', '-9999'\n",
    "] + image_list\n",
    "subprocess.run(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3910bacc",
   "metadata": {},
   "source": [
    "## Run stereo preprocessing to create dense match files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df298f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_stereo_folder = os.path.join(out_folder, 'init_stereo')\n",
    "os.makedirs(init_stereo_folder, exist_ok=True)\n",
    "\n",
    "image_list = sorted(glob(os.path.join(undistorted_folder, '*.tiff')))\n",
    "cam_list = sorted(glob(os.path.join(undistorted_folder, '*.tsai')))\n",
    "\n",
    "# Set up image pairs\n",
    "image1_list, image2_list = image_list[0:-1], image_list[1:]\n",
    "cam1_list, cam2_list = cam_list[0:-1], cam_list[1:]\n",
    "\n",
    "# skip the 8/9 cams pair (different intrinsics solving during bundle adjust)\n",
    "iskip = [i for i in range(0,len(image1_list)) if 'ch08' in image1_list[i]][0]\n",
    "image1_list = image1_list[0:iskip] + image1_list[iskip+1:]\n",
    "image2_list = image2_list[0:iskip] + image2_list[iskip+1:]\n",
    "cam1_list = cam1_list[0:iskip] + cam1_list[iskip+1:]\n",
    "cam2_list = cam2_list[0:iskip] + cam2_list[iskip+1:]\n",
    "\n",
    "# Iterate over pairs\n",
    "for i in tqdm(range(len(image1_list))):\n",
    "    image1, image2 = image1_list[i], image2_list[i]\n",
    "    cam1, cam2 = cam1_list[i], cam2_list[i]\n",
    "\n",
    "    pair_prefix = os.path.join(\n",
    "        init_stereo_folder,\n",
    "        os.path.splitext(os.path.basename(image1))[0] + '__' + os.path.splitext(os.path.basename(image2))[0],\n",
    "        'run'\n",
    "        )\n",
    "    \n",
    "    cmd = [\n",
    "        'parallel_stereo',\n",
    "        '--threads-singleprocess', '12',\n",
    "        '--threads-multiprocess', '12',\n",
    "        '--stop-point', '1',\n",
    "        image1, image2,\n",
    "        cam1, cam2,\n",
    "        pair_prefix,\n",
    "    ]\n",
    "    subprocess.run(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d9a851",
   "metadata": {},
   "source": [
    "## Bundle adjust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98bd743",
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_folder = os.path.join(out_folder, 'bundle_adjust')\n",
    "os.makedirs(ba_folder, exist_ok=True)\n",
    "\n",
    "image_list = sorted(glob(os.path.join(undistorted_folder, '*.tiff')))\n",
    "cam_list = sorted(glob(os.path.join(undistorted_folder, '*.tsai')))\n",
    "\n",
    "# Add small initial intrinsics values to cameras\n",
    "for cam_file in cam_list:\n",
    "    with open(cam_file, 'r') as f:\n",
    "        cam_lines = f.read().split('\\n')\n",
    "    # check if it's already been added\n",
    "    if sum([x=='TSAI' for x in cam_lines]) > 0:\n",
    "        continue\n",
    "    cam_lines = cam_lines[0:-1]\n",
    "    cam_lines[-1] = 'TSAI'\n",
    "    cam_lines += ['k1 = -1e-6']\n",
    "    cam_lines += ['k2 = 1e-6']\n",
    "    cam_lines += ['p1 = 0']\n",
    "    cam_lines += ['p2 = 0']\n",
    "    cam_lines += ['k3 = 1e-6']\n",
    "    cam_lines_merged = '\\n'.join(cam_lines) + '\\n'\n",
    "    with open(cam_file, 'w') as f:\n",
    "        f.write(cam_lines_merged)\n",
    "    \n",
    "# Copy dense matches to bundle adjust folder\n",
    "match_list = sorted(glob(os.path.join(init_stereo_folder, '*', '*.match')))\n",
    "for match_file in match_list:\n",
    "    match_out_file = os.path.join(ba_folder, os.path.basename(match_file))\n",
    "    _ = shutil.copy2(match_file, match_out_file)\n",
    "\n",
    "# GROUP 1\n",
    "print('\\nGROUP 1: ch01-08\\n----------')\n",
    "image_list_group1 = image_list[0:8]\n",
    "cam_list_group1 = cam_list[0:8]\n",
    "# Run bundle adjust\n",
    "cmd = [\n",
    "    'parallel_bundle_adjust',\n",
    "    '--threads', '12',\n",
    "    '--num-iterations', '2000',\n",
    "    '--num-passes', '2',\n",
    "    '--inline-adjustments',\n",
    "    '--force-reuse-match-files',\n",
    "    '--heights-from-dem', refdem_file,\n",
    "    '--heights-from-dem-uncertainty', '0.01',\n",
    "    '--solve-intrinsics',\n",
    "    '--intrinsics-to-share', 'optical_center,other_intrinsics',\n",
    "    '--intrinsics-to-float', 'all',\n",
    "    '-o', os.path.join(ba_folder, 'run_group1')\n",
    "] + image_list_group1 + cam_list_group1\n",
    "subprocess.run(cmd)\n",
    "\n",
    "# GROUP 2\n",
    "print('\\nGROUP 2: ch09-16\\n----------')\n",
    "image_list_group2 = image_list[8:]\n",
    "cam_list_group2 = cam_list[8:]\n",
    "# Run bundle adjust\n",
    "cmd = [\n",
    "    'parallel_bundle_adjust',\n",
    "    '--threads', '12',\n",
    "    '--num-iterations', '2000',\n",
    "    '--num-passes', '2',\n",
    "    '--inline-adjustments',\n",
    "    '--force-reuse-match-files',\n",
    "    '--heights-from-dem', refdem_file,\n",
    "    '--heights-from-dem-uncertainty', '0.01',\n",
    "    '--solve-intrinsics',\n",
    "    '--intrinsics-to-share', 'optical_center,other_intrinsics',\n",
    "    '--intrinsics-to-float', 'all',\n",
    "    '-o', os.path.join(ba_folder, 'run_group2')\n",
    "] + image_list_group2 + cam_list_group2\n",
    "subprocess.run(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39935435",
   "metadata": {},
   "source": [
    "## Final orthorectification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9facfc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(final_ortho_folder, exist_ok=True)\n",
    "\n",
    "image_list = sorted(glob(os.path.join(undistorted_folder, '*_undistorted.tiff')))\n",
    "cam_list = sorted(glob(os.path.join(ba_folder, '*.tsai')))\n",
    "print(len(image_list), len(cam_list))\n",
    "\n",
    "# Mapproject\n",
    "pbar = tqdm(total=len(image_list))\n",
    "for image_file, cam_file in zip(image_list, cam_list):\n",
    "    image_out_file = os.path.join(final_ortho_folder, os.path.basename(image_file).replace('.tiff', '_map.tiff'))\n",
    "    cmd = [\n",
    "        'mapproject',\n",
    "        '--threads', '12',\n",
    "        '--nodata-value', '0',\n",
    "        '--tr', '0.003',\n",
    "        refdem_file, image_file, cam_file, image_out_file\n",
    "    ]\n",
    "    subprocess.run(cmd)\n",
    "    pbar.update(1)\n",
    "\n",
    "# Mosaic orthoimages\n",
    "print('\\nMosaicking orthoimages')\n",
    "image_list = sorted(glob(os.path.join(final_ortho_folder, '*.tiff')))\n",
    "mosaic_file = os.path.join(final_ortho_folder, f'orthomosaic.tif')\n",
    "fnc = shutil.which('gdal_merge.py')\n",
    "cmd = [\n",
    "    'python', fnc,\n",
    "    '-o', mosaic_file,\n",
    "    '-n', '0',\n",
    "    '-a_nodata', '-9999'\n",
    "] + image_list\n",
    "subprocess.run(cmd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d22387",
   "metadata": {},
   "source": [
    "## Try mosaicking by identifying closest camera at each pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afd641a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio as rio\n",
    "\n",
    "image_list = sorted(glob(os.path.join(final_ortho_folder, '*.tiff')))\n",
    "cam_list = sorted(glob(os.path.join(ba_folder, '*.tsai')))\n",
    "\n",
    "# skip image 2 for now\n",
    "image_list = [x for x in image_list if 'ch02' not in x]\n",
    "cam_list = [x for x in cam_list if 'ch02' not in x]\n",
    "\n",
    "# Open DEM to use as reference grid\n",
    "refdem = rxr.open_rasterio(refdem_file).squeeze()\n",
    "# upsample to 3 mm - CRASHED\n",
    "# refdem = refdem.rio.reproject(\n",
    "#     refdem.rio.crs,\n",
    "#     resolution=(0.003, 0.003),\n",
    "#     resampling=rio.enums.Resampling.bilinear\n",
    "# )\n",
    "\n",
    "def read_camera_center(tsai_path):\n",
    "    \"\"\"Parse camera center (C = x y z) from a .tsai pinhole model file.\"\"\"\n",
    "    with open(tsai_path) as f:\n",
    "        cam_lines = f.read().split('\\n')\n",
    "    for line in cam_lines:\n",
    "        if 'C = ' in line:\n",
    "            C = line.split(' ')[2:]\n",
    "            cx_ecef = float(C[0])\n",
    "            cy_ecef = float(C[1])\n",
    "            cz_ecef = float(C[2])\n",
    "    # reproject to UTM\n",
    "    gdf = gpd.GeoDataFrame(geometry=[Point(cx_ecef, cy_ecef, cz_ecef)], crs=\"EPSG:4978\")\n",
    "    gdf = gdf.to_crs(\"EPSG:32619\")\n",
    "    cx, cy, cz = gdf['geometry'].x[0], gdf['geometry'].y[0], gdf['geometry'].z[0]\n",
    "\n",
    "    return np.array([cx, cy, cz])\n",
    "\n",
    "def mosaic_from_stack(stack, closest_idx_img):\n",
    "    \"\"\"Select pixel values from the stack using the nearest-camera index.\"\"\"\n",
    "    data = stack.data  # (camera, band, y, x)\n",
    "    out = np.zeros((data.shape[1], data.shape[2], data.shape[3]), dtype=data.dtype)\n",
    "    for b in range(data.shape[1]):\n",
    "        out[b, :, :] = np.take_along_axis(\n",
    "            data[:, b, :, :],\n",
    "            closest_idx_img[None, :, :],\n",
    "            axis=0\n",
    "        )[0]\n",
    "    return out\n",
    "\n",
    "datasets = [rxr.open_rasterio(f).squeeze() for f in image_list]\n",
    "# match refdem grid\n",
    "datasets = [f.rio.reproject_match(refdem) for f in datasets]\n",
    "\n",
    "camera_centers = np.array([read_camera_center(f) for f in cam_list])\n",
    "print(\"Loaded camera centers\")\n",
    "print(camera_centers)\n",
    "\n",
    "# Create per-pixel 3D coordinates from reference DEM\n",
    "print('Creating 3D reference grid from DEM')\n",
    "xv, yv = np.meshgrid(refdem.x.values, refdem.y.values)\n",
    "Z = refdem.data\n",
    "xyz_points = np.stack([xv.ravel(), yv.ravel(), Z.ravel()], axis=1)\n",
    "\n",
    "# Calculate distances to each camera\n",
    "print('Identifying closest camera to each pixel')\n",
    "distances = np.linalg.norm(\n",
    "    xyz_points[:, None, :] - camera_centers[None, :, :],\n",
    "    axis=2\n",
    ")\n",
    "closest_idx = np.argmin(distances, axis=1)\n",
    "closest_idx_img = closest_idx.reshape(refdem.shape)\n",
    "closest_idx_img\n",
    "\n",
    "# # Create mosaic\n",
    "# stack = xr.concat(datasets, dim=\"camera\")\n",
    "# mosaic_data = mosaic_from_stack(stack, closest_idx_img)\n",
    "\n",
    "# Convert to DataArray for easy export\n",
    "# mosaic = xr.DataArray(\n",
    "#     mosaic_data,\n",
    "#     dims=(\"band\", \"y\", \"x\"),\n",
    "#     coords={\"band\": stack.band, \"y\": stack.y, \"x\": stack.x},\n",
    "#     attrs=stack[0].attrs\n",
    "# )\n",
    "# mosaic.rio.write_crs(stack.rio.crs, inplace=True)\n",
    "\n",
    "# mosaic\n",
    "# mosaic.rio.to_raster(OUTPUT_TIF)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041d1448",
   "metadata": {},
   "source": [
    "## Test running stereo for DEM construction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780c1b72",
   "metadata": {},
   "source": [
    "### Run stereo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099f03a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(final_stereo_folder, exist_ok=True)\n",
    "\n",
    "image_list = sorted(glob(os.path.join(final_ortho_folder, '*_map.tiff')))\n",
    "cam_list = sorted(glob(os.path.join(ba_folder, '*.tsai')))\n",
    "\n",
    "# Set up image pairs\n",
    "image1_list, image2_list = image_list[0:-1], image_list[1:]\n",
    "cam1_list, cam2_list = cam_list[0:-1], cam_list[1:]\n",
    "\n",
    "# Iterate over pairs\n",
    "for i in tqdm(range(len(image1_list))):\n",
    "    image1, image2 = image1_list[i], image2_list[i]\n",
    "    cam1, cam2 = cam1_list[i], cam2_list[i]\n",
    "\n",
    "    pair_prefix = os.path.join(\n",
    "        final_stereo_folder,\n",
    "        os.path.splitext(os.path.basename(image1))[0] + '__' + os.path.splitext(os.path.basename(image2))[0],\n",
    "        'run'\n",
    "        )\n",
    "    \n",
    "    cmd = [\n",
    "        'parallel_stereo',\n",
    "        '--threads-singleprocess', '12',\n",
    "        '--threads-multiprocess', '12',\n",
    "        image1, image2,\n",
    "        cam1, cam2,\n",
    "        pair_prefix,\n",
    "        refdem_file\n",
    "    ]\n",
    "    subprocess.run(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd351ec",
   "metadata": {},
   "source": [
    "### Rasterize point clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e63a1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_files = sorted(glob(os.path.join(final_stereo_folder, '*', '*-PC.tif')))\n",
    "for pc in tqdm(pc_files):\n",
    "    cmd = [\n",
    "        'point2dem',\n",
    "        '--threads', '12',\n",
    "        '--tr', '0.01',\n",
    "        pc\n",
    "    ]\n",
    "    subprocess.run(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c9bbe9",
   "metadata": {},
   "source": [
    "### Mosaic DEMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5a4f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_fns = sorted(glob(os.path.join(final_stereo_folder, '*', '*DEM.tif')))\n",
    "mosaic_fn = os.path.join(final_stereo_folder, f'DEM_mosaic.tif')\n",
    "cmd = [\n",
    "    'dem_mosaic',\n",
    "    '--threads', '12',\n",
    "    '-o', mosaic_fn\n",
    "] + dem_fns\n",
    "subprocess.run(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e062a81a",
   "metadata": {},
   "source": [
    "### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79100e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the input files\n",
    "def load_raster(raster_file):\n",
    "    raster = rxr.open_rasterio(raster_file).squeeze()\n",
    "    crs = raster.rio.crs\n",
    "    raster = xr.where(raster < -100, np.nan, raster)\n",
    "    raster.rio.write_crs(crs, inplace=True)\n",
    "    return raster\n",
    "ortho_file = os.path.join(final_ortho_folder, 'orthomosaic.tif')\n",
    "ortho = load_raster(ortho_file)\n",
    "dem_file = os.path.join(final_stereo_folder, 'DEM_mosaic.tif')\n",
    "dem = load_raster(dem_file)\n",
    "refdem = load_raster(refdem_file)\n",
    "refdem = refdem.rio.reproject_match(dem)\n",
    "\n",
    "plt.rcParams.update({'font.sans-serif': 'Verdana', 'font.size': 12})\n",
    "fig, ax = plt.subplots(1, 3, figsize=(18,8))\n",
    "# Ortho\n",
    "ax[0].imshow(\n",
    "    ortho,\n",
    "    cmap='Grays_r',\n",
    "    extent=(min(ortho.x), max(ortho.x), min(ortho.y), max(ortho.y))\n",
    ")\n",
    "ax[0].set_title('IR image mosaic')\n",
    "# DEM\n",
    "im = ax[1].imshow(\n",
    "    dem, \n",
    "    cmap='terrain', \n",
    "    extent=(min(dem.x), max(dem.x), min(dem.y), max(dem.y), 'meters')\n",
    "    )\n",
    "cb = fig.colorbar(im, shrink=0.5)\n",
    "ax[1].set_title('DSM mosaic')\n",
    "# DEM - refdem\n",
    "im = ax[2].imshow(\n",
    "    dem - refdem, \n",
    "    cmap='coolwarm_r',\n",
    "    clim=(-1,1),\n",
    "    extent=(min(dem.x), max(dem.x), min(dem.y), max(dem.y))\n",
    "    )\n",
    "cb = fig.colorbar(im, shrink=0.5, label='meters')\n",
    "ax[2].set_title('DSM mosaic - Lidar mean')\n",
    "\n",
    "for axis in ax:\n",
    "    axis.set_xticks([])\n",
    "    axis.set_yticks([])\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save to file\n",
    "fig_file = os.path.join(out_folder, 'result.jpg')\n",
    "fig.savefig(fig_file, dpi=300, bbox_inches='tight')\n",
    "print('Figure saved to file:', fig_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soo_locs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
