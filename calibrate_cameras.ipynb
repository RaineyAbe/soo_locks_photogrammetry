{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2c9d518",
   "metadata": {},
   "source": [
    "# Calibrate cameras, create initial orthoimage and partial DSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6aac52a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 images located\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import rasterio as rio\n",
    "from affine import Affine\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "# Ignore warnings (rasterio throws a warning whenever an image is not georeferenced. Annoying in this case.)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Define input image files\n",
    "data_folder = '/Users/rdcrlrka/Research/Soo_locks'\n",
    "img_folder = os.path.join(data_folder, '20251001_imagery', 'frames_IR')\n",
    "img_list = sorted(glob(os.path.join(img_folder, '*.tiff')))\n",
    "print(f\"{len(img_list)} images located\")\n",
    "\n",
    "# Grab standard input files\n",
    "refdem_file = os.path.join(os.getcwd(), 'inputs', '20251001_Soo_Model_1cm_Intensity_UTM19N-fake.tif')\n",
    "gcp_folder = os.path.join(os.getcwd(), 'inputs', 'gcp')\n",
    "cams_file = os.path.join(os.getcwd(), 'inputs', 'cams_lonlat-fake.txt')\n",
    "\n",
    "# Define output folders\n",
    "out_folder = img_folder + '_proc_out'\n",
    "os.makedirs(out_folder, exist_ok=True)\n",
    "new_img_folder = os.path.join(out_folder, 'single_band_images')\n",
    "undistorted_folder = os.path.join(out_folder, 'undistorted_images')\n",
    "cam_folder = os.path.join(out_folder, 'cam_gen')\n",
    "\n",
    "ba_folder = os.path.join(out_folder, 'bundle_adjust')\n",
    "init_ortho_folder = os.path.join(out_folder, 'init_ortho')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c79d1b",
   "metadata": {},
   "source": [
    "## Convert images to single band in case they're RGB\n",
    "\n",
    "A couple IR images (near the windows) were captured in RGB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66d63e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving single-band images to: /Users/rdcrlrka/Research/Soo_locks/20251001_imagery/frames_IR_proc_out/single_band_images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 15932.78it/s]\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(new_img_folder, exist_ok=True)\n",
    "\n",
    "# iterate over images\n",
    "print('Saving single-band images to:', new_img_folder)\n",
    "for img_fn in tqdm(img_list[0:8]):\n",
    "    # convert images to single band\n",
    "    out_fn = os.path.join(new_img_folder, os.path.basename(img_fn))\n",
    "    if os.path.exists(out_fn):\n",
    "        continue\n",
    "    cmd = [\n",
    "        \"gdal_translate\",\n",
    "        \"-b\", \"1\",\n",
    "        img_fn, out_fn\n",
    "    ]\n",
    "    subprocess.run(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105faf4f",
   "metadata": {},
   "source": [
    "## Undistort images using GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bab3d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data for 6 images...\n",
      "Running calibration on 6 images...\n",
      "Calibration complete.\n",
      "RMS reprojection error: 24.599006189509957\n",
      "Camera Matrix (K):\n",
      " [[4.44460121e+03 0.00000000e+00 1.92000000e+03]\n",
      " [0.00000000e+00 4.46098142e+03 1.08000000e+03]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "Distortion Coefficients: [-1.45377416  3.50293614  0.          0.         -4.26900282]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:01<00:09,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved undistorted raster to: /Users/rdcrlrka/Research/Soo_locks/20251001_imagery/frames_IR_proc_out/undistorted_images/N910A6_ch01_main_20251001180000_20251001180626_undistorted.tiff\n",
      "Saved undistorted GCP to: /Users/rdcrlrka/Research/Soo_locks/20251001_imagery/frames_IR_proc_out/undistorted_images/N910A6_ch01_main_20251001180000_20251001180626_undistorted.gcp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:03<00:07,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved undistorted raster to: /Users/rdcrlrka/Research/Soo_locks/20251001_imagery/frames_IR_proc_out/undistorted_images/N910A6_ch02_main_20251001180001_20251001180626_undistorted.tiff\n",
      "Saved undistorted GCP to: /Users/rdcrlrka/Research/Soo_locks/20251001_imagery/frames_IR_proc_out/undistorted_images/N910A6_ch02_main_20251001180001_20251001180626_undistorted.gcp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:05<00:05,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved undistorted raster to: /Users/rdcrlrka/Research/Soo_locks/20251001_imagery/frames_IR_proc_out/undistorted_images/N910A6_ch03_main_20251001180002_20251001180626_undistorted.tiff\n",
      "Saved undistorted GCP to: /Users/rdcrlrka/Research/Soo_locks/20251001_imagery/frames_IR_proc_out/undistorted_images/N910A6_ch03_main_20251001180002_20251001180626_undistorted.gcp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:06<00:03,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved undistorted raster to: /Users/rdcrlrka/Research/Soo_locks/20251001_imagery/frames_IR_proc_out/undistorted_images/N910A6_ch04_main_20251001180003_20251001180626_undistorted.tiff\n",
      "Saved undistorted GCP to: /Users/rdcrlrka/Research/Soo_locks/20251001_imagery/frames_IR_proc_out/undistorted_images/N910A6_ch04_main_20251001180003_20251001180626_undistorted.gcp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:08<00:01,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved undistorted raster to: /Users/rdcrlrka/Research/Soo_locks/20251001_imagery/frames_IR_proc_out/undistorted_images/N910A6_ch05_main_20251001180004_20251001180626_undistorted.tiff\n",
      "Saved undistorted GCP to: /Users/rdcrlrka/Research/Soo_locks/20251001_imagery/frames_IR_proc_out/undistorted_images/N910A6_ch05_main_20251001180004_20251001180626_undistorted.gcp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:10<00:00,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved undistorted raster to: /Users/rdcrlrka/Research/Soo_locks/20251001_imagery/frames_IR_proc_out/undistorted_images/N910A6_ch06_main_20251001180005_20251001180626_undistorted.tiff\n",
      "Saved undistorted GCP to: /Users/rdcrlrka/Research/Soo_locks/20251001_imagery/frames_IR_proc_out/undistorted_images/N910A6_ch06_main_20251001180005_20251001180626_undistorted.gcp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# def warp_image_using_gcp(image_undistorted, gcp_df, K, dist, dst_crs=\"EPSG:32619\"):\n",
    "\n",
    "#     # --- Undistort GCP pixel coordinates ---\n",
    "#     img_pts = gcp_df[['sample_col', 'sample_row']].values.astype(np.float32).reshape(-1, 1, 2)\n",
    "#     undistorted_pts = cv2.undistortPoints(img_pts, K, dist, P=K).reshape(-1, 2)\n",
    "#     gcp_df['sample_col_undist'] = undistorted_pts[:, 0]\n",
    "#     gcp_df['sample_row_undist'] = undistorted_pts[:, 1]\n",
    "\n",
    "#     # --- Estimate affine transform from undistorted image pixels to world coords ---\n",
    "#     img_pts = gcp_df[['sample_col_undist', 'sample_row_undist']].values.astype(np.float32)\n",
    "#     world_pts = gcp_df[['X', 'Y']].values.astype(np.float32)\n",
    "#     M, _ = cv2.estimateAffinePartial2D(img_pts, world_pts, method=cv2.LMEDS)\n",
    "\n",
    "#     # --- Estimate pixel size (resolution) from affine transform ---\n",
    "#     scale_x = np.linalg.norm(M[:, 0])\n",
    "#     scale_y = np.linalg.norm(M[:, 1])\n",
    "\n",
    "#     pixel_size_x = scale_x\n",
    "#     pixel_size_y = scale_y\n",
    "\n",
    "#     # --- Compose scaled affine matrix to preserve resolution ---\n",
    "#     scaling = np.array([\n",
    "#         [1 / pixel_size_x, 0, 0],\n",
    "#         [0, 1 / pixel_size_y, 0],\n",
    "#         [0, 0, 1]\n",
    "#     ])\n",
    "#     M_hom = np.vstack([M, [0, 0, 1]])  # 3x3\n",
    "#     M_scaled = scaling @ M_hom  # Affine matrix with resolution normalization\n",
    "\n",
    "#     # --- Transform image corners using scaled matrix ---\n",
    "#     h, w = image_undistorted.shape[:2]\n",
    "#     corners = np.array([\n",
    "#         [0, 0],\n",
    "#         [w, 0],\n",
    "#         [0, h],\n",
    "#         [w, h]\n",
    "#     ], dtype=np.float32)\n",
    "#     corners_hom = np.hstack([corners, np.ones((4, 1))])\n",
    "#     transformed_corners = (M_scaled @ corners_hom.T).T\n",
    "\n",
    "#     # --- Compute bounds in pixel coordinates ---\n",
    "#     x_coords = transformed_corners[:, 0]\n",
    "#     y_coords = transformed_corners[:, 1]\n",
    "#     x_min_px, x_max_px = np.floor(np.min(x_coords)), np.ceil(np.max(x_coords))\n",
    "#     y_min_px, y_max_px = np.floor(np.min(y_coords)), np.ceil(np.max(y_coords))\n",
    "\n",
    "#     width = int(x_max_px - x_min_px)\n",
    "#     height = int(y_max_px - y_min_px)\n",
    "\n",
    "#     # --- Apply final translation to ensure top-left is (0, 0) in output image ---\n",
    "#     translation = np.array([\n",
    "#         [1, 0, -x_min_px],\n",
    "#         [0, 1, -y_min_px],\n",
    "#         [0, 0, 1]\n",
    "#     ])\n",
    "#     M_final = translation @ M_scaled\n",
    "#     M_final = M_final[:2, :]  # Back to 2x3 for OpenCV\n",
    "\n",
    "#     # --- Warp image using final matrix ---\n",
    "#     image_undistorted_warped = cv2.warpAffine(\n",
    "#         image_undistorted,\n",
    "#         M_final,\n",
    "#         (width, height),\n",
    "#         flags=cv2.INTER_LINEAR,\n",
    "#         borderValue=0\n",
    "#     )\n",
    "#     # set no data to nan\n",
    "#     image_undistorted_warped = np.where(image_undistorted_warped==0, np.nan, image_undistorted_warped)\n",
    "\n",
    "#     # plt.imshow(image_undistorted_warped)\n",
    "#     # plt.show()\n",
    "\n",
    "#     # --- Generate geospatial coordinates for warped image ---\n",
    "#     x_origin = (x_min_px * pixel_size_x)\n",
    "#     y_origin = (y_min_px * pixel_size_y)\n",
    "\n",
    "#     x_coords = np.linspace(x_origin, x_origin + pixel_size_x * width, num=width, endpoint=False)\n",
    "#     y_coords = np.linspace(y_origin, y_origin + pixel_size_y * height, num=height, endpoint=False)\n",
    "\n",
    "#     dims = ['y', 'x'] if image_undistorted.ndim == 2 else ['y', 'x', 'band']\n",
    "#     image_da = xr.DataArray(\n",
    "#         data=image_undistorted_warped,\n",
    "#         dims=dims,\n",
    "#         coords=dict(\n",
    "#             y=y_coords,\n",
    "#             x=x_coords\n",
    "#         )\n",
    "#     )\n",
    "#     image_da.rio.write_crs(dst_crs, inplace=True)\n",
    "\n",
    "#     return image_da, gcp_df\n",
    "\n",
    "\n",
    "def estimate_shared_intrinsics(image_files, gcp_files, output_folder, fx_mm=2.8, plot_results=True):\n",
    "\n",
    "    object_points_list = []\n",
    "    image_points_list = []\n",
    "    image_size = None\n",
    "\n",
    "    print(f\"Preparing data for {len(image_files)} images...\")\n",
    "\n",
    "    for image_file in image_files:\n",
    "        img_name = os.path.basename(image_file)\n",
    "\n",
    "        # Load GCP file for this image\n",
    "        gcp_file = [x for x in gcp_files if (os.path.splitext(img_name)[0] in x)]\n",
    "        if not gcp_file:\n",
    "            print(f\"No GCP file found for {img_name}, skipping.\")\n",
    "            continue\n",
    "        gcp_file = gcp_file[0]\n",
    "\n",
    "        gcp = pd.read_csv(\n",
    "            gcp_file,\n",
    "            sep=', ',\n",
    "            header=None,\n",
    "            skiprows=[0],\n",
    "            engine='python',\n",
    "            names=['pt_idx', 'Y', 'X', 'Z', 'Y_std', 'X_std', 'Z_std',\n",
    "                    'img_path', 'sample_col', 'sample_row', 'use_Y', 'use_X', 'use_Z']\n",
    "        )\n",
    "\n",
    "        # Reproject to UTM (EPSG:32619)\n",
    "        gcp['geometry'] = [Point(x, y) for x, y in gcp[['X', 'Y']].values]\n",
    "        gcp_gdf = gpd.GeoDataFrame(geometry=gcp['geometry'], crs=\"EPSG:4326\")\n",
    "        gcp_gdf = gcp_gdf.to_crs(\"EPSG:32619\")\n",
    "        gcp['X'] = gcp_gdf.geometry.x\n",
    "        gcp['Y'] = gcp_gdf.geometry.y\n",
    "\n",
    "        if len(gcp) < 6:\n",
    "            print(f\"Skipping {img_name}: only {len(gcp)} GCPs found.\")\n",
    "            continue\n",
    "\n",
    "        # Prepare object and image points\n",
    "        object_points = gcp[[\"X\", \"Y\", \"Z\"]].values.astype(np.float32).reshape(-1, 1, 3)\n",
    "        object_points -= object_points.mean(axis=0)  # center around origin\n",
    "\n",
    "        image_points = gcp[[\"sample_col\", \"sample_row\"]].values.astype(np.float32)\n",
    "        image_points = image_points.reshape(-1, 1, 2)\n",
    "\n",
    "        img = cv2.imread(image_file, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            print(f\"Failed to read {image_file}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        if image_size is None:\n",
    "            h, w = img.shape\n",
    "            image_size = (w, h)\n",
    "        else:\n",
    "            assert image_size == (img.shape[1], img.shape[0]), \"All images must have the same size\"\n",
    "\n",
    "        object_points_list.append(object_points)\n",
    "        image_points_list.append(image_points)\n",
    "\n",
    "    if len(object_points_list) == 0:\n",
    "        raise ValueError(\"No valid GCPs found for any images.\")\n",
    "\n",
    "    # --- Calibration ---\n",
    "    fx = fy = 2000\n",
    "    cx = image_size[0] / 2\n",
    "    cy = image_size[1] / 2\n",
    "    K_init = np.array([[fx, 0, cx],\n",
    "                       [0, fy, cy],\n",
    "                       [0,  0,  1]], dtype=np.float64)\n",
    "    dist_init = np.zeros(5)\n",
    "\n",
    "    flags = (\n",
    "        cv2.CALIB_USE_INTRINSIC_GUESS |\n",
    "        cv2.CALIB_FIX_PRINCIPAL_POINT |\n",
    "        cv2.CALIB_ZERO_TANGENT_DIST\n",
    "    )\n",
    "\n",
    "    print(f\"Running calibration on {len(object_points_list)} images...\")\n",
    "\n",
    "    ret, K, dist, rvecs, tvecs = cv2.calibrateCamera(\n",
    "        object_points_list,\n",
    "        image_points_list,\n",
    "        image_size,\n",
    "        K_init,\n",
    "        dist_init,\n",
    "        flags=flags\n",
    "    )\n",
    "\n",
    "    print(\"Calibration complete.\")\n",
    "    print(\"RMS reprojection error:\", ret)\n",
    "    print(\"Camera Matrix (K):\\n\", K)\n",
    "    print(\"Distortion Coefficients:\", dist.ravel())\n",
    "\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # --- Undistort and georeference each image ---\n",
    "    for image_file in tqdm(image_files):\n",
    "        img_name = os.path.basename(image_file)\n",
    "\n",
    "        # Load the GCPs\n",
    "        gcp_file = [x for x in gcp_files if (os.path.splitext(img_name)[0] in x)]\n",
    "        if not gcp_file:\n",
    "            continue\n",
    "        gcp_file = gcp_file[0]\n",
    "        gcp = pd.read_csv(\n",
    "            gcp_file,\n",
    "            sep=', ',\n",
    "            header=None,\n",
    "            skiprows=[0],\n",
    "            engine='python',\n",
    "            names=['pt_idx', 'Y', 'X', 'Z', 'Y_std', 'X_std', 'Z_std',\n",
    "                   'img_path', 'sample_col', 'sample_row', 'use_Y', 'use_X', 'use_Z']\n",
    "        )\n",
    "\n",
    "        # Reproject GCPs again\n",
    "        gcp['geometry'] = [Point(x, y) for x, y in gcp[['X', 'Y']].values]\n",
    "        gcp_gdf = gpd.GeoDataFrame(geometry=gcp['geometry'], crs=\"EPSG:4326\")\n",
    "        gcp_gdf = gcp_gdf.to_crs(\"EPSG:32619\")\n",
    "        gcp['X'] = gcp_gdf.geometry.x\n",
    "        gcp['Y'] = gcp_gdf.geometry.y\n",
    "\n",
    "        # Read the raw image\n",
    "        img = cv2.imread(image_file, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        # Undistort the image and the GCP\n",
    "        map1, map2 = cv2.initUndistortRectifyMap(K, dist, None, K, image_size, cv2.CV_32FC1)\n",
    "        img_undistorted = cv2.remap(img, map1, map2, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        # Calculate new GCP pixel indices for the undistorted image\n",
    "        img_pts = gcp[['sample_col', 'sample_row']].values.astype(np.float32).reshape(-1, 1, 2)\n",
    "        undistorted_pts = cv2.undistortPoints(img_pts, K, dist, P=K).reshape(-1, 2)\n",
    "        gcp['sample_col_undist'] = undistorted_pts[:, 0]\n",
    "        gcp['sample_row_undist'] = undistorted_pts[:, 1]\n",
    "        \n",
    "        if plot_results:\n",
    "            fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
    "            ax[0].imshow(img, cmap='gray')\n",
    "            ax[0].plot(gcp['sample_col'], gcp['sample_row'], 'xr',\n",
    "                       markersize=5, linewidth=1.5)\n",
    "            ax[0].set_title('Original')\n",
    "            ax[1].imshow(img_undistorted, cmap='gray')\n",
    "            ax[1].plot(gcp['sample_col_undist'], gcp['sample_row_undist'], 'xr',\n",
    "                       markersize=5, linewidth=1.5)\n",
    "            ax[1].set_title('Undistorted')\n",
    "            for axis in ax:\n",
    "                axis.set_xticks([]), axis.set_yticks([])\n",
    "            plt.suptitle(img_name)\n",
    "            plt.tight_layout()\n",
    "\n",
    "            # save to file\n",
    "            fig_fn = os.path.join(output_folder, os.path.splitext(img_name)[0] + '_undistorted.png')\n",
    "            fig.savefig(fig_fn, dpi=300, bbox_inches='tight')\n",
    "\n",
    "            plt.close()\n",
    "\n",
    "        # Save undistorted image as GeoTIFF\n",
    "        img_undistorted_file = os.path.join(output_folder, os.path.splitext(img_name)[0] + '_undistorted.tiff')\n",
    "        img_undistorted_xr = xr.DataArray(\n",
    "            data=np.flipud(img_undistorted),\n",
    "            dims=['y', 'x'],\n",
    "            coords=dict(\n",
    "                y=np.arange(0,img_undistorted.shape[0]),\n",
    "                x=np.arange(0,img_undistorted.shape[1])\n",
    "            )\n",
    "        )\n",
    "        img_undistorted_xr.rio.to_raster(img_undistorted_file)\n",
    "        print('Saved undistorted raster to:', img_undistorted_file)\n",
    "\n",
    "        # Reformat GCP for saving\n",
    "        # reproject to lat-lon (fake)\n",
    "        gcp['geometry'] = [Point(x,y) for x,y in gcp[['X','Y']].values]\n",
    "        gcp_gdf = gpd.GeoDataFrame(geometry=gcp['geometry'], crs=\"EPSG:32619\")\n",
    "        gcp_gdf = gcp_gdf.to_crs(\"EPSG:4326\")\n",
    "        gcp['X'] = [x.coords.xy[0][0] for x in gcp_gdf['geometry']]\n",
    "        gcp['Y'] = [x.coords.xy[1][0] for x in gcp_gdf['geometry']]\n",
    "        # update the image name\n",
    "        gcp['img_name'] = [os.path.basename(x).replace('.tiff', '_undistorted.tiff') for x in gcp['img_path']]\n",
    "        # select the appropriate rows in order\n",
    "        gcp['sample_col'] = gcp['sample_col_undist']\n",
    "        gcp['sample_row'] = gcp['sample_row_undist']\n",
    "        gcp = gcp[['pt_idx', 'Y', 'X', 'Z', 'Y_std', 'X_std', 'Z_std', 'img_name', 'sample_col', 'sample_row', 'use_Y', 'use_X']]\n",
    "\n",
    "        # Save undistorted GCP as CSV        \n",
    "        gcp_undistorted_file = os.path.join(output_folder, os.path.splitext(os.path.basename(gcp_file))[0] + '_undistorted.gcp')\n",
    "        gcp.to_csv(\n",
    "            gcp_undistorted_file, \n",
    "            sep=',', \n",
    "            index=False,\n",
    "            header=False\n",
    "            )\n",
    "        print('Saved undistorted GCP to:', gcp_undistorted_file)\n",
    "\n",
    "    return img_undistorted, gcp\n",
    "\n",
    "\n",
    "image_list = sorted(glob(os.path.join(new_img_folder, '*.tiff')))\n",
    "gcp_list = sorted(glob(os.path.join(gcp_folder, '*.gcp')))\n",
    "\n",
    "# Process first group of images\n",
    "image_list_group1 = image_list[0:6]\n",
    "img_undistorted, gcp = estimate_shared_intrinsics(\n",
    "    image_list_group1,\n",
    "    gcp_list,\n",
    "    undistorted_folder,\n",
    "    plot_results=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4959d0e0",
   "metadata": {},
   "source": [
    "## Generate initial camera models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f7d6d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Focal length (pixels): 1720.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t--> Setting number of processing threads to: 12\n",
      "Using datum: Geodetic Datum --> Name: WGS_1984  Spheroid: WGS 84  Semi-major axis: 6378137  Semi-minor axis: 6356752.3142451793  Meridian: Greenwich at 0  Proj4 Str: +proj=longlat +datum=WGS84 +no_defs\n",
      "Using nodata value: -9999\n",
      "Camera center (lon-lat-height) set on the command line: Vector3(-73.488768183874271,3.4031005725631767e-05,-3.863)\n",
      "Could not determine a valid height value at lon-lat: -73.488759911372853 4.4212098441672778e-05. Will use a height of -8.\n",
      "Median pixel projection error in the coarse camera: 1761.7551854342082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:02<00:10,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Levenberg-Marquardt solver failed. Results may be inaccurate.\n",
      "Median pixel projection error in the refined camera: 2099.7879078997926\n",
      "Output camera center lon, lat, and height above datum: Vector3(-73.48875751848125,4.4030130947677164e-05,-7.4758407596162746)\n",
      "Writing: /Users/rdcrlrka/Research/Soo_locks/20251001_imagery/frames_IR_proc_out/cam_gen/N910A6_ch01_main_20251001180000_20251001180626_undistorted.tsai\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:03<00:07,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t--> Setting number of processing threads to: 12\n",
      "Using datum: Geodetic Datum --> Name: WGS_1984  Spheroid: WGS 84  Semi-major axis: 6378137  Semi-minor axis: 6356752.3142451793  Meridian: Greenwich at 0  Proj4 Str: +proj=longlat +datum=WGS84 +no_defs\n",
      "Using nodata value: -9999\n",
      "Camera center (lon-lat-height) set on the command line: Vector3(-73.488777229775167,6.7430654324343009e-05,-3.778)\n",
      "Median pixel projection error in the coarse camera: 1507.7975664606211\n",
      "Median pixel projection error in the refined camera: 1558.8001588041839\n",
      "Output camera center lon, lat, and height above datum: Vector3(-73.384124694245173,-0.044795866903730892,3685.7109194116547)\n",
      "Writing: /Users/rdcrlrka/Research/Soo_locks/20251001_imagery/frames_IR_proc_out/cam_gen/N910A6_ch02_main_20251001180001_20251001180626_undistorted.tsai\n",
      "\t--> Setting number of processing threads to: 12\n",
      "Using datum: Geodetic Datum --> Name: WGS_1984  Spheroid: WGS 84  Semi-major axis: 6378137  Semi-minor axis: 6356752.3142451793  Meridian: Greenwich at 0  Proj4 Str: +proj=longlat +datum=WGS84 +no_defs\n",
      "Using nodata value: -9999\n",
      "Camera center (lon-lat-height) set on the command line: Vector3(-73.488786104560191,9.7559876635296342e-05,-3.7120000000000002)\n",
      "Median pixel projection error in the coarse camera: 1598.400095083507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:05<00:05,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Levenberg-Marquardt solver failed. Results may be inaccurate.\n",
      "Median pixel projection error in the refined camera: 1515.1538593291104\n",
      "Output camera center lon, lat, and height above datum: Vector3(-73.488815157045508,0.0001001614873235072,5658.0068227100746)\n",
      "Writing: /Users/rdcrlrka/Research/Soo_locks/20251001_imagery/frames_IR_proc_out/cam_gen/N910A6_ch03_main_20251001180002_20251001180626_undistorted.tsai\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:07<00:03,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t--> Setting number of processing threads to: 12\n",
      "Using datum: Geodetic Datum --> Name: WGS_1984  Spheroid: WGS 84  Semi-major axis: 6378137  Semi-minor axis: 6356752.3142451793  Meridian: Greenwich at 0  Proj4 Str: +proj=longlat +datum=WGS84 +no_defs\n",
      "Using nodata value: -9999\n",
      "Camera center (lon-lat-height) set on the command line: Vector3(-73.488795429984549,0.00013154758682599999,-3.6419999999999999)\n",
      "Median pixel projection error in the coarse camera: 1664.0953326868441\n",
      "Median pixel projection error in the refined camera: 1336.7930639518172\n",
      "Output camera center lon, lat, and height above datum: Vector3(-73.489980407895032,-0.00071540038317027496,47099.745333227052)\n",
      "Writing: /Users/rdcrlrka/Research/Soo_locks/20251001_imagery/frames_IR_proc_out/cam_gen/N910A6_ch04_main_20251001180003_20251001180626_undistorted.tsai\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:08<00:01,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t--> Setting number of processing threads to: 12\n",
      "Using datum: Geodetic Datum --> Name: WGS_1984  Spheroid: WGS 84  Semi-major axis: 6378137  Semi-minor axis: 6356752.3142451793  Meridian: Greenwich at 0  Proj4 Str: +proj=longlat +datum=WGS84 +no_defs\n",
      "Using nodata value: -9999\n",
      "Camera center (lon-lat-height) set on the command line: Vector3(-73.48880679806058,0.0001618328422275,-3.532)\n",
      "Median pixel projection error in the coarse camera: 1414.7086676363992\n",
      "Median pixel projection error in the refined camera: 1638.775779336627\n",
      "Output camera center lon, lat, and height above datum: Vector3(-73.483068419337698,0.0015474428795117473,8665.4174038834444)\n",
      "Writing: /Users/rdcrlrka/Research/Soo_locks/20251001_imagery/frames_IR_proc_out/cam_gen/N910A6_ch05_main_20251001180004_20251001180626_undistorted.tsai\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:10<00:00,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t--> Setting number of processing threads to: 12\n",
      "Using datum: Geodetic Datum --> Name: WGS_1984  Spheroid: WGS 84  Semi-major axis: 6378137  Semi-minor axis: 6356752.3142451793  Meridian: Greenwich at 0  Proj4 Str: +proj=longlat +datum=WGS84 +no_defs\n",
      "Using nodata value: -9999\n",
      "Camera center (lon-lat-height) set on the command line: Vector3(-73.488813745770074,0.0001955598913277,-3.5169999999999999)\n",
      "Median pixel projection error in the coarse camera: 2862.1605171374395\n",
      "Median pixel projection error in the refined camera: 1477.0094161453283\n",
      "Output camera center lon, lat, and height above datum: Vector3(-73.495468703809294,-0.0053102586722478945,12610.625966402533)\n",
      "Writing: /Users/rdcrlrka/Research/Soo_locks/20251001_imagery/frames_IR_proc_out/cam_gen/N910A6_ch06_main_20251001180005_20251001180626_undistorted.tsai\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_cameras(image_list, gcp_list, cams_file, f_m=2.8*1e-3, gsd_m=2.5*1e-3, altitude_m=4.3):\n",
    "    # Load \"lat-lon\" camera positions\n",
    "    cams = pd.read_csv(\n",
    "        cams_file,\n",
    "        sep=' ',\n",
    "        header=None,\n",
    "        names=['img_name', 'lon', 'lat', 'Z', 'lon_std', 'lat_std']\n",
    "        )\n",
    "\n",
    "    # Estimate initial camera intrinsics in pixels\n",
    "    # convert focal length from mm to pixels\n",
    "    # GSD = (Altidude * Pixel Pitch) / Focal Length\n",
    "    # --> Pixel Pitch = (GSD * Focal Length) / Altitude\n",
    "    px_pitch = (gsd_m * f_m) / altitude_m\n",
    "    # Convert focal length to pixels to use a pitch of 1\n",
    "    f_px = f_m / px_pitch\n",
    "    print('Focal length (pixels):', f_px)\n",
    "\n",
    "    pbar = tqdm(total=len(image_list))\n",
    "    for image_file in image_list:\n",
    "        image_file_base = os.path.splitext(os.path.basename(image_file))[0].replace('_undistorted','')\n",
    "\n",
    "        # Subset camera positions\n",
    "        cam = cams.loc[cams['img_name'].str.contains(image_file_base)]\n",
    "\n",
    "        # Load GCP\n",
    "        gcp_file = [x for x in gcp_list if image_file_base in x]\n",
    "        if len(gcp_file) < 1:\n",
    "            raise ValueError(f\"No GCP file found for image: {image_file}\")\n",
    "        gcp = pd.read_csv(\n",
    "            gcp_file[0], \n",
    "            sep=',', \n",
    "            header=None,\n",
    "            names=['pt_idx', 'Y', 'X', 'Z', 'Y_std', 'X_std', 'Z_std', 'img_name', 'sample_col', 'sample_row', 'use_Y', 'use_X']\n",
    "            )\n",
    "\n",
    "        # get \"lat-lon\" values and image pixel indices pairs\n",
    "        lonlat_str = [(str(lon),str(lat)) for lon,lat in gcp[['X', 'Y']].values]\n",
    "        lonlat_str = [' '.join(xy) for xy in lonlat_str]\n",
    "        lonlat_str = ', '.join(lonlat_str)\n",
    "\n",
    "        pxval_str = [(str(c),str(r)) for c,r in gcp[['sample_col', 'sample_row']].values]\n",
    "        pxval_str = [' '.join(xy) for xy in pxval_str]\n",
    "        pxval_str = ', '.join(pxval_str)\n",
    "\n",
    "        # Image dimensions\n",
    "        with rio.open(image_file) as src:\n",
    "            w_px = src.width\n",
    "            h_px = src.height\n",
    "\n",
    "        # Optical center\n",
    "        cu = w_px / 2\n",
    "        cv = h_px / 2\n",
    "\n",
    "        # construct command\n",
    "        cmd = [\n",
    "            'cam_gen',\n",
    "            # input image file\n",
    "            image_file,\n",
    "            '--threads', '12',\n",
    "            '--camera-type', 'pinhole',\n",
    "            '--refine-camera',\n",
    "            '--reference-dem', refdem_file,\n",
    "            # default height where DEM is NaN\n",
    "            '--height-above-datum', str(float(np.round(gcp['Z'].mean()))),\n",
    "            '--focal-length', str(f_px),\n",
    "            '--pixel-pitch', '1',\n",
    "            # horizontal, vertical components\n",
    "            '--optical-center', str(int(cu)), str(int(cv)),\n",
    "            # lon, lat, height\n",
    "            '--camera-center-llh', str(cam['lon'].values[0]), str(cam['lat'].values[0]), str(cam['Z'].values[0]),\n",
    "            '--lon-lat-values', lonlat_str,\n",
    "            '--pixel-values', pxval_str,\n",
    "            # output camera\n",
    "            '-o', os.path.join(\n",
    "                cam_folder, \n",
    "                os.path.splitext(os.path.basename(image_file))[0] + '.tsai'\n",
    "                ),\n",
    "        ]\n",
    "        subprocess.run(cmd)\n",
    "        pbar.update(1)\n",
    "\n",
    "os.makedirs(cam_folder, exist_ok=True)\n",
    "\n",
    "img_list = sorted(glob(os.path.join(undistorted_folder, '*_undistorted.tiff')))[0:6]\n",
    "gcp_list = sorted(glob(os.path.join(undistorted_folder, '*.gcp')))\n",
    "\n",
    "generate_cameras(img_list, gcp_list, cams_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b566291f",
   "metadata": {},
   "source": [
    "## Align images to the lidar reflectance image using GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987005bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(ba_folder, exist_ok=True)\n",
    "\n",
    "img_list = sorted(glob(os.path.join(undistorted_folder, '*.tiff')))\n",
    "gcp_list = sorted(glob(os.path.join(undistorted_folder, '*.gcp')))\n",
    "cam_list = sorted(glob(os.path.join(cam_folder, '*.tsai')))\n",
    "\n",
    "# run bundle_adjust in groups of two images for better optimization\n",
    "for i in np.arange(0, len(img_list)-1, step=2):\n",
    "    img1, img2 = img_list[i:i+2]\n",
    "    cam1, cam2 = cam_list[i:i+2]\n",
    "    gcp1, gcp2 = gcp_list[i:i+2]\n",
    "    \n",
    "    pair_prefix = os.path.join(\n",
    "        ba_folder, \n",
    "        '__'.join([os.path.splitext(os.path.basename(x))[0] for x in (img1, img2)]),\n",
    "        'run'\n",
    "        )\n",
    "    \n",
    "    cmd = [\n",
    "    'parallel_bundle_adjust',\n",
    "        '-t', 'pinhole',\n",
    "        '--threads', '12',\n",
    "        '--num-iterations', '2000',\n",
    "        '--num-passes', '2',\n",
    "        # create new camera files\n",
    "        '--inline-adjustments',\n",
    "        '--heights-from-dem', refdem_file,\n",
    "        '--heights-from-dem-uncertainty', '0.02',\n",
    "        '--remove-outliers-params', \"75.0 3.0 20 25\",\n",
    "        '-o', pair_prefix,\n",
    "        img1, img2,\n",
    "        cam1, cam2,\n",
    "        gcp1, gcp2\n",
    "    ]\n",
    "    subprocess.run(cmd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebda1161",
   "metadata": {},
   "source": [
    "## Mapproject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d69689d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(init_ortho_folder, exist_ok=True)\n",
    "\n",
    "img_list = sorted(glob(os.path.join(undistorted_folder, '*_undistorted.tiff')))\n",
    "cam_list = sorted(glob(os.path.join(ba_folder, '*', '*.tsai')))\n",
    "\n",
    "pbar = tqdm(total=len(img_list))\n",
    "for img_file, cam_file in zip(img_list, cam_list):\n",
    "    img_out_file = os.path.join(init_ortho_folder, os.path.basename(img_file).replace('.tiff', '_map.tiff'))\n",
    "    cmd = [\n",
    "        'mapproject',\n",
    "        '--threads', '12',\n",
    "        '--tr', '0.005',\n",
    "        refdem_file, img_file, cam_file, img_out_file\n",
    "    ]\n",
    "    subprocess.run(cmd)\n",
    "    pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabe7530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # align photos using the undistorted GCP\n",
    "# gcp_list = sorted(glob(os.path.join(undistorted_folder, '*.gcp')))\n",
    "# img_list = sorted(glob(os.path.join(undistorted_folder, '*.tiff')))\n",
    "\n",
    "# def compute_georeferencing_transform(gcp_df):\n",
    "#     \"\"\"\n",
    "#     Compute a similarity transform (rotation, scale, translation) from image pixels to UTM coords.\n",
    "#     Returns an Affine transform object usable with rasterio.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Use undistorted GCP pixel coordinates\n",
    "#     img_pts = gcp_df[['sample_col_undist', 'sample_row_undist']].values.astype(np.float32)\n",
    "#     world_pts = gcp_df[['X', 'Y']].values.astype(np.float32)\n",
    "\n",
    "#     # Estimate similarity transform\n",
    "#     M, inliers = cv2.estimateAffinePartial2D(img_pts, world_pts, method=cv2.LMEDS)\n",
    "\n",
    "#     if M is None:\n",
    "#         raise RuntimeError(\"Could not estimate transform.\")\n",
    "\n",
    "#     # Convert OpenCV affine matrix (2x3) to rasterio-style Affine\n",
    "#     a, b, c = M[0]\n",
    "#     d, e, f = M[1]\n",
    "\n",
    "#     transform = Affine(a, b, c, d, e, f)\n",
    "#     print(transform)\n",
    "    \n",
    "#     return transform\n",
    "\n",
    "\n",
    "# os.makedirs(align_cv_folder, exist_ok=True)\n",
    "\n",
    "# for gcp_file in tqdm(gcp_list[0:1]):\n",
    "#     # open the GCP file\n",
    "#     gcp = pd.read_csv(\n",
    "#             gcp_file,\n",
    "#             sep=' ',\n",
    "#             header=None,\n",
    "#             skiprows=[0],\n",
    "#             engine='python',\n",
    "#             names=['Y', 'X', 'Z', 'Y_std', 'X_std', 'Z_std',\n",
    "#                     'img_path', 'sample_col', 'sample_row', 'use_Y', 'use_X', 'use_Z', 'geometry',\n",
    "#                     'sample_col_undist', 'sample_row_undist']\n",
    "#         )\n",
    "    \n",
    "#     # get the image file name\n",
    "#     img_name_base = os.path.splitext(os.path.basename(gcp.iloc[0]['img_path']))[0]\n",
    "#     img_file = [x for x in img_list if img_name_base in x][0]\n",
    "\n",
    "#     # load the original transform\n",
    "#     img = rxr.open_rasterio(img_file).squeeze()\n",
    "#     img_transform = img.rio.transform()\n",
    "\n",
    "#     # estimate the alignment transform\n",
    "#     align_transform = compute_georeferencing_transform(gcp)\n",
    "\n",
    "#     # apply alignment transform to the original\n",
    "#     img_transform_aligned = align_transform * img_transform\n",
    "\n",
    "#     # apply the transform and CRS to a new DataArray\n",
    "#     img_aligned = img.copy()\n",
    "#     img_aligned.rio.write_transform(img_transform_aligned, inplace=True)\n",
    "#     img_aligned.rio.write_crs(img.rio.crs, inplace=True)\n",
    "\n",
    "#     # Save output\n",
    "#     img_out_fn = os.path.join(align_cv_folder, os.path.basename(img_file).replace('.tiff', '_aligned.tiff'))\n",
    "#     img_aligned.rio.to_raster(img_out_fn)\n",
    "\n",
    "#     print('Aligned image saved to:', img_out_fn)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c4462d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gcp = pd.read_csv(\n",
    "#     gcp_list[3],\n",
    "#     sep=' ',\n",
    "#     header=None,\n",
    "#     skiprows=[0],\n",
    "#     engine='python',\n",
    "#     names=['pt_idx', 'Y', 'X', 'Z', 'Y_std', 'X_std', 'Z_std',\n",
    "#             'img_path', 'sample_col', 'sample_row', 'use_Y', 'use_X', 'use_Z', 'geometry', 'sample_col_undist', 'sample_row_undist']\n",
    "# )\n",
    "\n",
    "# # Reproject GCPs again\n",
    "# gcp['geometry'] = [Point(x, y) for x, y in gcp[['X', 'Y']].values]\n",
    "# gcp_gdf = gpd.GeoDataFrame(geometry=gcp['geometry'], crs=\"EPSG:4326\")\n",
    "# gcp_gdf = gcp_gdf.to_crs(\"EPSG:32619\")\n",
    "# gcp['X'] = gcp_gdf.geometry.x\n",
    "# gcp['Y'] = gcp_gdf.geometry.y\n",
    "# gcp['image_name'] = [os.path.basename(x) for x in gcp['img_path']]\n",
    "# gcp.rename(columns={\n",
    "#     'sample_col_undist': 'sample_col_undistorted',\n",
    "#     'sample_row_undist': 'sample_row_undistorted'\n",
    "# }, inplace=True)\n",
    "\n",
    "# gcp = gcp[['X', 'Y', 'Z', 'image_name', 'sample_col', 'sample_row', 'sample_col_undistorted', 'sample_row_undistorted']]\n",
    "# gcp_out = gcp_list[3].replace('.gcp', '.csv')\n",
    "# gcp.to_csv(gcp_out, sep=',', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f18d8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# open orthoimage for plotting\n",
    "ortho_file = os.path.join(os.getcwd(), 'inputs', '20251001_Soo_Model_5mm_Ground_Reflectance_UTM19N-fake.tif')\n",
    "ortho = rxr.open_rasterio(ortho_file).squeeze()\n",
    "ortho = ortho.data.astype(np.float32) # openCV only accepts up to 32-bit\n",
    "ortho[ortho==-9999] = 0\n",
    "\n",
    "# iterate over match files\n",
    "for match_txt in match_txt_list[0:1]:\n",
    "    match_txt_base = os.path.splitext(os.path.basename(match_txt).replace('run-',''))[0]\n",
    "\n",
    "    # parse the image and ortho pixel coordinates\n",
    "    match = pd.read_csv(match_txt, sep=' ', header=None, skiprows=[0])\n",
    "    image_match_pts = match.iloc[0:int(len(match)/2)][[0,1]].values\n",
    "    ortho_match_pts = match.iloc[int(len(match)/2):][[0,1]].values\n",
    "\n",
    "    # open the image\n",
    "    image_file = os.path.join(undistorted_folder, match_txt_base.split('__')[0] + '.tiff')\n",
    "    image = cv2.imread(image_file, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # align\n",
    "    M, inliers = cv2.estimateAffine2D(np.array(image_match_pts), np.array(ortho_match_pts))\n",
    "    \n",
    "\n",
    "\n",
    "# Plot GCP / match points\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(1, 2, figsize=(10,5))\n",
    "# ax[0].imshow(image, cmap='Grays_r')\n",
    "# ax[1].imshow(ortho, cmap='Grays_r')\n",
    "# for i in range(len(image_match)):\n",
    "#     ax[0].plot(image_match.iloc[i][0], image_match.iloc[i][1], '*', markersize=8,\n",
    "#                markerfacecolor=plt.cm.viridis(i/len(image_match)), markeredgecolor='w', markeredgewidth=0.3)\n",
    "#     ax[1].plot(ortho_match.iloc[i][0], ortho_match.iloc[i][1], '*', markersize=8,\n",
    "#                markerfacecolor=plt.cm.viridis(i/len(image_match)), markeredgecolor='w', markeredgewidth=0.3)\n",
    "# ax[1].set_xlim(ortho_match[0].min() - 15, ortho_match[0].max() + 15)\n",
    "# ax[1].set_ylim(ortho_match[1].max() + 15, ortho_match[1].min() - 15)\n",
    "# for axis in ax:\n",
    "#     axis.set_xticks([])\n",
    "#     axis.set_yticks([])\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e0ceae",
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = image.shape[:2]\n",
    "\n",
    "# Step 1: Transform source image corners\n",
    "corners = np.array([\n",
    "    [0, 0],\n",
    "    [w, 0],\n",
    "    [0, h],\n",
    "    [w, h]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Convert corners to homogeneous coords\n",
    "ones = np.ones((4, 1), dtype=np.float32)\n",
    "corners_hom = np.hstack([corners, ones])\n",
    "\n",
    "# Apply M to each corner\n",
    "transformed_corners = (M @ corners_hom.T).T\n",
    "\n",
    "# Step 2: Compute bounding box of warped image\n",
    "x_min, y_min = np.min(transformed_corners, axis=0)\n",
    "x_max, y_max = np.max(transformed_corners, axis=0)\n",
    "\n",
    "width = int(np.ceil(x_max - x_min))\n",
    "height = int(np.ceil(y_max - y_min))\n",
    "\n",
    "# Step 3: Adjust M to shift output image to (0, 0)\n",
    "translation = np.array([\n",
    "    [1, 0, -x_min],\n",
    "    [0, 1, -y_min]\n",
    "])\n",
    "\n",
    "M_adjusted = translation @ np.vstack([M, [0, 0, 1]])  # make M 3x3 for matrix mult\n",
    "M_adjusted = M_adjusted[:2, :]  # back to 2x3 for warpAffine\n",
    "\n",
    "# Step 4: Warp image with adjusted matrix\n",
    "warped = cv2.warpAffine(image, M_adjusted, (width, height), flags=cv2.INTER_LINEAR, borderValue=0)\n",
    "\n",
    "ortho = rxr.open_rasterio(ortho_file).squeeze()\n",
    "ortho = ortho.data.astype(np.float32) # openCV only accepts up to 32-bit\n",
    "ortho[ortho==-9999] = 0\n",
    "\n",
    "plt.imshow(warped)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37125e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add initial distortion coefficients\n",
    "# cam_list = sorted(glob(os.path.join(cam_folder, '*.tsai')))\n",
    "\n",
    "# for cam in tqdm(cam_list):\n",
    "#     with open(cam, 'r') as f:\n",
    "#         cam_lines = f.read().split('\\n')\n",
    "#     # remove empty lines\n",
    "#     cam_lines = [x for x in cam_lines if x!='']\n",
    "\n",
    "#     # replace the NULL with TSAI\n",
    "#     for i, line in enumerate(cam_lines):\n",
    "#         if 'NULL' in line:\n",
    "#             cam_lines[i] = 'TSAI'\n",
    "\n",
    "#     # add distortion coefficients\n",
    "#     cam_lines += [\n",
    "#         'k1 = -1e-6',\n",
    "#         'k2 = 1e-6',\n",
    "#         'p1 = 0',\n",
    "#         'p2 = 0',\n",
    "#         'k3 = 1e-6'\n",
    "#     ]\n",
    "\n",
    "#     cam_lines_string = '\\n'.join(cam_lines) + '\\n'\n",
    "    \n",
    "#     # write to file\n",
    "#     with open(cam, 'w') as f:\n",
    "#         f.write(cam_lines_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c0e951",
   "metadata": {},
   "source": [
    "## Run stereo correlation for dense matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75a59e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(init_stereo_folder, exist_ok=True)\n",
    "\n",
    "img_list = sorted(glob(os.path.join(undistorted_folder, '*.tiff')))\n",
    "cam_list = [glob(os.path.join(cam_folder, '*' + os.path.splitext(os.path.basename(x))[0]) + '*.tsai')[0]\n",
    "            for x in img_list]\n",
    "\n",
    "img_pairs = list(zip(img_list[0:-1], img_list[1:]))\n",
    "cam_pairs = list(zip(cam_list[0:-1], cam_list[1:]))\n",
    "\n",
    "for i in tqdm(range(0,len(img_pairs))):\n",
    "    img1, img2 = img_pairs[i]\n",
    "    cam1, cam2 = cam_pairs[i]\n",
    "\n",
    "    pair_prefix = os.path.join(\n",
    "        init_stereo_folder,\n",
    "        os.path.splitext(os.path.basename(img1))[0] + '__' + os.path.splitext(os.path.basename(img2))[0],\n",
    "        'run'\n",
    "        )\n",
    "\n",
    "    cmd = [\n",
    "        'parallel_stereo',\n",
    "        '--threads-singleprocess', '12',\n",
    "        '--threads-multiprocess', '12',\n",
    "        '--stop-point', '1', # stop after feature detection and matching\n",
    "        img1, img2,\n",
    "        cam1, cam2,\n",
    "        pair_prefix\n",
    "    ]\n",
    "    subprocess.run(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e70f5d",
   "metadata": {},
   "source": [
    "## Bundle adjust using dense matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7673cca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(ba_folder, exist_ok=True)\n",
    "\n",
    "cam_list = sorted(glob(os.path.join(cam_folder, '*.tsai')))\n",
    "img_list = [os.path.join(new_img_folder, os.path.basename(x).replace('.tsai','.tiff')) \n",
    "            for x in cam_list]\n",
    "\n",
    "# copy dense matches from stereo to bundle_adjust folder\n",
    "match_list = glob(os.path.join(init_stereo_folder, '*', '*.match'))\n",
    "print(f'Copying {len(match_list)} matches from stereo to the bundle adjust folder')\n",
    "for match in tqdm(match_list):\n",
    "    match_out = os.path.join(ba_folder, os.path.basename(match))\n",
    "    _ = shutil.copy2(match, match_out)\n",
    "\n",
    "cmd = [\n",
    "    'parallel_bundle_adjust',\n",
    "    '-t', 'pinhole',\n",
    "    '--threads', '12',\n",
    "    '--num-iterations', '2000',\n",
    "    '--num-passes', '2',\n",
    "    # create new camera files\n",
    "    '--inline-adjustments',\n",
    "    # more confident in the camera positions\n",
    "    # '--camera-position-weight', '5',\n",
    "    # use the matches from stereo\n",
    "    '--force-reuse-match-files',\n",
    "    # solve intrinsics\n",
    "    # '--solve-intrinsics',\n",
    "    # '--intrinsics-to-share', 'none',\n",
    "    # '--intrinsics-to-float', 'all',\n",
    "    '--heights-from-dem', refdem_file,\n",
    "    '--heights-from-dem-uncertainty', '0.02',\n",
    "    '--remove-outliers-params', \"75.0 3.0 20 25\",\n",
    "    '-o', os.path.join(ba_folder, 'run'),\n",
    "] + img_list + cam_list\n",
    "subprocess.run(cmd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778f89c2",
   "metadata": {},
   "source": [
    "## Initial orthorectification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5773639a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(init_ortho_folder, exist_ok=True)\n",
    "\n",
    "img_list = sorted(glob(os.path.join(undistorted_folder, '*.tiff')))\n",
    "cam_list = sorted(glob(os.path.join(ba_folder, '*.tsai')))\n",
    "\n",
    "for img, cam in tqdm(list(zip(img_list, cam_list))):\n",
    "    img_out_fn = os.path.join(init_ortho_folder, os.path.splitext(os.path.basename(img))[0] + '_map.tiff')\n",
    "    cmd = [\n",
    "        'mapproject',\n",
    "        '--tr', '0.005',\n",
    "        '--threads', '12',\n",
    "        refdem_file, img, cam, img_out_fn\n",
    "    ]\n",
    "    subprocess.run(cmd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6a6dc2",
   "metadata": {},
   "source": [
    "## Final stereo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6412e3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(final_stereo_folder, exist_ok=True)\n",
    "\n",
    "img_list = sorted(glob(os.path.join(init_ortho_folder, '*.tiff')))\n",
    "cam_list = [glob(os.path.join(ba_folder, '*' + os.path.splitext(os.path.basename(x))[0].replace('_map','')) + '*.tsai')[0]\n",
    "            for x in img_list]\n",
    "\n",
    "img_pairs = list(zip(img_list[0:-1], img_list[1:]))\n",
    "cam_pairs = list(zip(cam_list[0:-1], cam_list[1:]))\n",
    "\n",
    "for i in tqdm(range(0,len(img_pairs))):\n",
    "    img1, img2 = img_pairs[i]\n",
    "    cam1, cam2 = cam_pairs[i]\n",
    "\n",
    "    pair_prefix = os.path.join(\n",
    "        final_stereo_folder,\n",
    "        os.path.splitext(os.path.basename(img1))[0] + '__' + os.path.splitext(os.path.basename(img2))[0],\n",
    "        'run'\n",
    "        )\n",
    "\n",
    "    cmd = [\n",
    "        'parallel_stereo',\n",
    "        '--threads-singleprocess', '12',\n",
    "        '--threads-multiprocess', '12',\n",
    "        img1, img2,\n",
    "        cam1, cam2,\n",
    "        pair_prefix,\n",
    "        refdem_file\n",
    "    ]\n",
    "    subprocess.run(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd351ec",
   "metadata": {},
   "source": [
    "## Rasterize point clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e63a1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rasterize the point clouds\n",
    "pc_files = sorted(glob(os.path.join(final_stereo_folder, '*', '*-PC.tif')))\n",
    "print('Rasterizing the point clouds...')\n",
    "for pc in tqdm(pc_files):\n",
    "    cmd = [\n",
    "        'point2dem',\n",
    "        '--threads', '12',\n",
    "        '--tr', '0.01',\n",
    "        pc\n",
    "    ]\n",
    "    subprocess.run(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c9bbe9",
   "metadata": {},
   "source": [
    "## Mosaic DEMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5a4f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_fns = sorted(glob(os.path.join(final_stereo_folder, '*', '*DEM.tif')))\n",
    "print('Creating mosaics of DEM using blended, median, NMAD, and count operators')\n",
    "for method in tqdm(['median', 'nmad', 'count']):\n",
    "    dem_fn = os.path.join(final_stereo_folder, f'DEM_mosaic_{method}.tif')\n",
    "    cmd = [\n",
    "        'dem_mosaic',\n",
    "        '--threads', '12',\n",
    "        '-o', dem_fn\n",
    "    ] + dem_fns\n",
    "    if method != 'blended':\n",
    "        cmd += [f\"--{method}\"]\n",
    "    subprocess.run(cmd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4260585d",
   "metadata": {},
   "source": [
    "## Align DEM mosaic with reference DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21af819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_fn = os.path.join(final_stereo_folder, 'DEM_mosaic_median.tif')\n",
    "os.makedirs(dem_align_folder, exist_ok=True)\n",
    "\n",
    "cmd = [\n",
    "    'pc_align',\n",
    "    '--threads', '12',\n",
    "    '--max-displacement', '3',\n",
    "    '--save-transformed-source-points',\n",
    "    refdem_file, dem_fn,\n",
    "    '-o', os.path.join(dem_align_folder, 'run')\n",
    "]\n",
    "subprocess.run(cmd)\n",
    "\n",
    "# Rasterize the aligned point cloud\n",
    "pc_aligned_fn = os.path.join(dem_align_folder, 'run-trans_source.tif')\n",
    "cmd = [\n",
    "    'point2dem',\n",
    "    '--threads', '12',\n",
    "    '--tr', '0.01',\n",
    "    pc_aligned_fn\n",
    "]\n",
    "subprocess.run(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f07b0a",
   "metadata": {},
   "source": [
    "## Align cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc4125a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(cam_align_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "def transform_pinhole_cameras(camera_file, transform_file, out_folder):\n",
    "    # Read the camera file\n",
    "    with open(camera_file, 'r') as f:\n",
    "        camera_lines = f.read().split('\\n')\n",
    "    # get the camera center and rotation\n",
    "    camera_C_line = [x for x in camera_lines if 'C =' in x][0]\n",
    "    camera_C = np.array([float(x) for x in camera_C_line.split(' = ')[1].split(' ')])\n",
    "    camera_R_line = [x for x in camera_lines if 'R = ' in x][0]\n",
    "    camera_R = np.array([float(x) for x in camera_R_line.split(' = ')[1].split(' ')]).reshape(3,3)\n",
    "\n",
    "    # Read the transform\n",
    "    with open(transform_file, 'r') as f:\n",
    "        transform_lines = f.read()\n",
    "    # split by lines and spaces, convert to float, and reshape into 4x4\n",
    "    transform_matrix = np.array([\n",
    "        list(map(float, line.split()))\n",
    "        for line in transform_lines.strip().split('\\n')\n",
    "    ])\n",
    "\n",
    "    # Extract R and T from transform\n",
    "    transform_R = transform_matrix[:3, :3]\n",
    "    transform_T = transform_matrix[:3, 3]\n",
    "\n",
    "    # Apply the transformation to camera\n",
    "    camera_C_adj = transform_R @ camera_C + transform_T\n",
    "    camera_R_adj = transform_R @ camera_R\n",
    "\n",
    "    # Update the camera\n",
    "    for i, line in enumerate(camera_lines):\n",
    "        if 'C = ' in line:\n",
    "            camera_C_adj_string = ' '.join(list(camera_C_adj.astype(str)))\n",
    "            camera_lines[i] = f\"C = {camera_C_adj_string}\"\n",
    "        elif 'R = ' in line:\n",
    "            camera_R_adj_string = ' '.join(list(camera_R_adj.ravel().astype(str)))\n",
    "            camera_lines[i] = f\"R = {camera_R_adj_string}\"\n",
    "\n",
    "    \n",
    "    # Save to file\n",
    "    camera_lines_string = '\\n'.join(camera_lines)\n",
    "    camera_out_file = os.path.join(out_folder, os.path.basename(camera_file))\n",
    "    with open(camera_out_file, 'w') as f:\n",
    "        f.write(camera_lines_string)\n",
    "    print('Transformed camera saved to file:', camera_out_file)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "cam_list = sorted(glob(os.path.join(ba_folder, '*.tsai')))\n",
    "transform_fn = os.path.join(dem_align_folder, 'run-transform.txt')\n",
    "\n",
    "for cam in tqdm(cam_list):\n",
    "    transform_pinhole_cameras(cam, transform_fn, cam_align_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ac3224",
   "metadata": {},
   "source": [
    "## Mapproject images onto the reference DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0038a3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(final_ortho_folder, exist_ok=True)\n",
    "\n",
    "img_list = sorted(glob(os.path.join(undistorted_folder, '*.tiff')))\n",
    "cam_list = sorted(glob(os.path.join(cam_align_folder, '*.tsai')))\n",
    "\n",
    "for img, cam in tqdm(list(zip(img_list, cam_list))):\n",
    "    img_out_fn = os.path.join(final_ortho_folder, os.path.splitext(os.path.basename(img))[0] + '_map.tiff')\n",
    "    cmd = [\n",
    "        'mapproject',\n",
    "        '--tr', '0.005',\n",
    "        '--threads', '12',\n",
    "        refdem_file, img, cam, img_out_fn\n",
    "    ]\n",
    "    subprocess.run(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1b9b1d",
   "metadata": {},
   "source": [
    "## Mosaic mapprojected images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953c76ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = sorted(glob(os.path.join(final_ortho_folder, '*_map.tiff')))\n",
    "mosaic_fn = os.path.join(final_ortho_folder, 'orthomosaic.tif')\n",
    "cmd = [\n",
    "    'image_mosaic',\n",
    "    '--threads', '12',\n",
    "    '-o', mosaic_fn\n",
    "] + img_list\n",
    "subprocess.run(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e062a81a",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79100e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ortho image and DEM mosaics\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "\n",
    "fig_fn = os.path.join(out_folder, 'result.jpg')\n",
    "\n",
    "# Load the input files\n",
    "ortho_files = sorted(glob(os.path.join(final_ortho_folder, '*_map.tiff')))\n",
    "\n",
    "dem_fn = os.path.join(dem_align_folder, 'run-trans_source-DEM.tif')\n",
    "dem = rxr.open_rasterio(dem_fn).squeeze()\n",
    "crs = dem.rio.crs\n",
    "dem = xr.where(dem < -100, np.nan, dem)\n",
    "dem = dem.rio.write_crs(crs)\n",
    "refdem = rxr.open_rasterio(refdem_file).squeeze()\n",
    "refdem = refdem.rio.reproject_match(dem)\n",
    "refdem = xr.where(refdem < -100, np.nan, refdem)\n",
    "\n",
    "plt.rcParams.update({'font.sans-serif': 'Verdana', 'font.size': 12})\n",
    "fig, ax = plt.subplots(1, 3, figsize=(18,8))\n",
    "# Ortho\n",
    "for ortho_file in ortho_files:\n",
    "    ortho = rxr.open_rasterio(ortho_file).squeeze()\n",
    "    ortho = xr.where(ortho < -1e3, np.nan, ortho)\n",
    "    ax[0].imshow(\n",
    "        ortho, \n",
    "        cmap='Grays_r',\n",
    "        extent=(min(ortho.x), max(ortho.x), min(ortho.y), max(ortho.y))\n",
    "        )\n",
    "ax[0].set_title('IR image mosaic')\n",
    "# DEM\n",
    "im = ax[1].imshow(\n",
    "    dem, \n",
    "    cmap='terrain', \n",
    "    extent=(min(dem.x), max(dem.x), min(dem.y), max(dem.y), 'meters')\n",
    "    )\n",
    "cb = fig.colorbar(im, shrink=0.5)\n",
    "ax[1].set_title('DSM mosaic')\n",
    "# DEM - refdem\n",
    "im = ax[2].imshow(\n",
    "    dem - refdem, \n",
    "    cmap='coolwarm_r',\n",
    "    clim=(-1,1),\n",
    "    extent=(min(dem.x), max(dem.x), min(dem.y), max(dem.y))\n",
    "    )\n",
    "cb = fig.colorbar(im, shrink=0.5, label='meters')\n",
    "ax[2].set_title('Lidar - DSM')\n",
    "\n",
    "ax[0].set_xlim(ax[1].set_xlim())\n",
    "ax[0].set_ylim(ax[1].get_ylim())\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(fig_fn, dpi=300, bbox_inches='tight')\n",
    "print('Figure saved to file:', fig_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3105c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soo_locs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
