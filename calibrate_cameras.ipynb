{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2c9d518",
   "metadata": {},
   "source": [
    "# Calibrate cameras, create initial orthoimage and partial DSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aac52a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "import shutil\n",
    "import ast\n",
    "# Ignore warnings (rasterio throws a warning whenever an image is not georeferenced. Annoying in this case.)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Locate image files\n",
    "data_folder = '/Users/rdcrlrka/Research/Soo_locks'\n",
    "image_folder = os.path.join(data_folder, '20251001_imagery', 'frames_IR')\n",
    "image_list = sorted(glob(os.path.join(image_folder, '*.tiff')))\n",
    "print(f\"{len(image_list)} images located\")\n",
    "\n",
    "# Grab other input files\n",
    "refdem_file = os.path.join(os.getcwd(), '..', 'inputs', '20251001_Soo_Model_1cm_mean_UTM19N-fake_filled_cropped.tif')\n",
    "gcp_folder = os.path.join(os.getcwd(), '..', 'inputs', 'gcp')\n",
    "cams_file = os.path.join(os.getcwd(), '..', 'inputs', 'cams_lonlat-fake.txt')\n",
    "\n",
    "# Define output folders\n",
    "out_folder = image_folder + '_proc_out'\n",
    "os.makedirs(out_folder, exist_ok=True)\n",
    "new_image_folder = os.path.join(out_folder, 'single_band_images')\n",
    "undistorted_folder = os.path.join(out_folder, 'undistorted_images_cams')\n",
    "init_ortho_folder = os.path.join(out_folder, 'init_ortho')\n",
    "init_stereo_folder = os.path.join(out_folder, 'init_stereo')\n",
    "ba_folder = os.path.join(out_folder, 'bundle_adjust')\n",
    "final_ortho_folder = os.path.join(out_folder, 'final_ortho')\n",
    "final_stereo_folder = os.path.join(out_folder, 'final_stereo')\n",
    "full_cam_folder = os.path.join(out_folder, 'full_optimized_cams')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c8f447",
   "metadata": {},
   "source": [
    "## Merge GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef6f860",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcp_merged_file = os.path.join(gcp_folder, 'GCP_merged.csv')\n",
    "if not os.path.exists(gcp_merged_file):\n",
    "\n",
    "    gcp_list = sorted(glob(os.path.join(gcp_folder, '*.gcp')))\n",
    "    df_list = []\n",
    "    for gcp_file in gcp_list:\n",
    "        df = pd.read_csv(\n",
    "            gcp_file,\n",
    "            sep=',',\n",
    "            header=None,\n",
    "            skiprows=[0],\n",
    "            names=[\n",
    "                'point_index', 'lat', 'lon', 'Z', 'lat_sigma', 'lon_sigma', 'Z_sigma', \n",
    "                'image_path', 'col_sample', 'row_sample', 'use_lat', 'use_lon']\n",
    "        )\n",
    "        df_list += [df]\n",
    "\n",
    "    dfs = pd.concat(df_list).reset_index(drop=True)\n",
    "\n",
    "    # reproject to UTM zone 19N\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        dfs,\n",
    "        geometry=[Point(x,y) for x,y in dfs[['lon', 'lat']].values],\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "    gdf = gdf.to_crs(\"EPSG:32619\")\n",
    "    gdf['X'] = [x.coords.xy[0][0] for x in gdf['geometry']]\n",
    "    gdf['Y'] = [x.coords.xy[1][0] for x in gdf['geometry']]\n",
    "\n",
    "    # use just the image file name\n",
    "    gdf['image_name'] = [os.path.basename(x) for x in gdf['image_path']]\n",
    "\n",
    "    # select relevant columns\n",
    "    gdf = gdf[['image_name', 'X', 'Y', 'Z', 'col_sample', 'row_sample']]\n",
    "\n",
    "    # save to file\n",
    "    gdf.to_csv(gcp_merged_file, sep=',', index=False)\n",
    "    print('Saved merged GCP:', gcp_merged_file)\n",
    "else:\n",
    "    print('Merged GCP already exists in file, skipping merge.')\n",
    "\n",
    "\n",
    "# Reproject from UTM zone 19 N to ECEF for use in ASP\n",
    "gcp_merged_ecef_file = os.path.join(gcp_folder, 'GCP_merged_ECEF.csv')\n",
    "if not os.path.exists(gcp_merged_ecef_file):\n",
    "    # Load the merged file\n",
    "    gcp_merged = pd.read_csv(gcp_merged_file, sep=',')\n",
    "\n",
    "    # Reproject from UTM to ECEF\n",
    "    geom = [Point(x,y,z) for x,y,z in gcp_merged[['X', 'Y', 'Z']].values]\n",
    "    gdf = gpd.GeoDataFrame(geometry=geom, crs=\"EPSG:32619\")\n",
    "    gdf = gdf.to_crs(\"EPSG:4978\")\n",
    "    gcp_merged['X'] = [x.x for x in gdf['geometry']]\n",
    "    gcp_merged['Y'] = [x.y for x in gdf['geometry']]\n",
    "    gcp_merged['Z'] = [x.z for x in gdf['geometry']]\n",
    "\n",
    "    # Save to file\n",
    "    gcp_merged.to_csv(gcp_merged_ecef_file, sep=',', index=False)\n",
    "    print('Saved merged GCP in ECEF coordinates:', gcp_merged_ecef_file)\n",
    "else:\n",
    "    print('Merged GCP in ECEF coordinates already exists in file, skipping reprojection.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c79d1b",
   "metadata": {},
   "source": [
    "## Convert images to single band in case they're RGB\n",
    "\n",
    "A couple IR images (near the windows) were captured in RGB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d63e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(new_image_folder, exist_ok=True)\n",
    "\n",
    "# iterate over images\n",
    "print('Saving single-band images to:', new_image_folder)\n",
    "for image_file in tqdm(image_list):\n",
    "    # convert images to single band\n",
    "    out_fn = os.path.join(new_image_folder, os.path.basename(image_file))\n",
    "    if os.path.exists(out_fn):\n",
    "        continue\n",
    "    cmd = [\n",
    "        \"gdal_translate\",\n",
    "        \"-b\", \"1\",\n",
    "        image_file, out_fn\n",
    "    ]\n",
    "    subprocess.run(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105faf4f",
   "metadata": {},
   "source": [
    "## Calibrate cameras using GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c64d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tsai(tsai_dict, filename):\n",
    "    \"\"\"\n",
    "    Save a TSAI (.tsai) pinhole camera file from a dictionary.\n",
    "    \"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(\"VERSION_4\\n\")\n",
    "        f.write(\"PINHOLE\\n\")\n",
    "        f.write(f\"fu = {tsai_dict['fu']}\\n\")\n",
    "        f.write(f\"fv = {tsai_dict['fv']}\\n\")\n",
    "        f.write(f\"cu = {tsai_dict['cu']}\\n\")\n",
    "        f.write(f\"cv = {tsai_dict['cv']}\\n\")\n",
    "        f.write(f\"u_direction = {' '.join(map(str, tsai_dict['u_direction']))}\\n\")\n",
    "        f.write(f\"v_direction = {' '.join(map(str, tsai_dict['v_direction']))}\\n\")\n",
    "        f.write(f\"w_direction = {' '.join(map(str, tsai_dict['w_direction']))}\\n\")\n",
    "        f.write(f\"C = {' '.join(map(str, tsai_dict['C']))}\\n\")\n",
    "        f.write(\"R = \" + \" \".join(map(str, tsai_dict['R'].flatten())) + \"\\n\")\n",
    "        f.write(f\"pitch = {tsai_dict['pitch']}\\n\")\n",
    "        # Add small distortion for bundle adjust\n",
    "        f.write(\"TSAI\\n\")\n",
    "        f.write(\"k1 = -1e-6\\nk2 = 1e-6\\np1 = 0\\np2 = 0\\nk3 = 1e-6\\n\")\n",
    "\n",
    "\n",
    "def calibrate_cameras(image_files, gcp_file, output_folder=None, file_prefix=None, plot_results=True):\n",
    "    object_points_list = []\n",
    "    image_points_list = []\n",
    "    image_size = None\n",
    "\n",
    "    # --- Load merged GCP ---\n",
    "    gcp = pd.read_csv(gcp_file, sep=',')    \n",
    "\n",
    "    # --- Compile GCP (object) and image (pixel) points --- \n",
    "    for image_file in image_files:\n",
    "        # Subset GCP to image\n",
    "        gcp_image = gcp.loc[gcp['image_name']==os.path.basename(image_file)]\n",
    "\n",
    "        # Object and image points\n",
    "        obj_pts = gcp_image[['X','Y','Z']].values.astype(np.float32)\n",
    "        image_pts = gcp_image[['col_sample','row_sample']].values.astype(np.float32)\n",
    "        obj_pts = obj_pts.reshape(-1,1,3)\n",
    "        image_pts = image_pts.reshape(-1,1,2)\n",
    "\n",
    "        object_points_list.append(obj_pts)\n",
    "        image_points_list.append(image_pts)\n",
    "\n",
    "        # get image size\n",
    "        if image_size is None:\n",
    "            image = cv2.imread(image_file, cv2.IMREAD_GRAYSCALE)\n",
    "            image_size = (image.shape[1], image.shape[0])\n",
    "\n",
    "    if len(object_points_list) == 0:\n",
    "        raise ValueError(\"No valid images for calibration\")\n",
    "    \n",
    "    # --- Subtract the mean of all object points for better calculation ---\n",
    "    all_obj_pts = np.vstack([op.reshape(-1,3) for op in object_points_list])\n",
    "    object_points_mean = all_obj_pts.mean(axis=0)\n",
    "    object_points_list = [x - object_points_mean for x in object_points_list]\n",
    "\n",
    "    # --- Initialize intrinsics --- \n",
    "    fx = fy = 2000\n",
    "    cx = image_size[0] / 2\n",
    "    cy = image_size[1] / 2\n",
    "    K_init = np.array([\n",
    "        [fx,0,cx],\n",
    "        [0,fy,cy],\n",
    "        [0,0,1]\n",
    "        ], dtype=np.float64)\n",
    "    dist_init = np.zeros(8)\n",
    "    flags = (\n",
    "        cv2.CALIB_USE_INTRINSIC_GUESS\n",
    "        | cv2.CALIB_FIX_PRINCIPAL_POINT \n",
    "        | cv2.CALIB_ZERO_TANGENT_DIST\n",
    "        )\n",
    "\n",
    "    # --- Calibrate cameras ---\n",
    "    rms, K, dist, rvecs, tvecs = cv2.calibrateCamera(\n",
    "        object_points_list,\n",
    "        image_points_list,\n",
    "        image_size,\n",
    "        K_init,\n",
    "        dist_init,\n",
    "        flags=flags\n",
    "    )\n",
    "\n",
    "    print(\"Shared calibration done\")\n",
    "    print(\"RMS reprojection error:\", rms)\n",
    "    print(\"Camera matrix K:\\n\", K)\n",
    "    print(\"Distortion coefficients:\", dist.ravel())\n",
    "\n",
    "    # --- Calculate adjusted camera matrix ---\n",
    "    w,h = image_size\n",
    "    K_full, _ = cv2.getOptimalNewCameraMatrix(K, dist, (w,h), 1, (w, h))\n",
    "\n",
    "    # --- Save camera calibration parameters ---\n",
    "    calib_file = os.path.join(output_folder, file_prefix + 'camera_calibration_params.csv')\n",
    "    calib_df = pd.DataFrame({\n",
    "        'image_name': image_files,\n",
    "        'K': [[float(x) for x in K.ravel()]]*len(image_files),\n",
    "        'K_full': [[float(x) for x in K_full.ravel()]]*len(image_files),\n",
    "        'distortion_coefficients': [[float(x) for x in dist.ravel()]]*len(image_files),\n",
    "        'RMS': [rms]*len(image_files)\n",
    "    })\n",
    "    calib_df.to_csv(calib_file, index=False)\n",
    "    print(\"Saved calibration params:\", calib_file)\n",
    "\n",
    "    # --- Save undistorted images, GCP, and camera extrinsics ---\n",
    "    print('Estimating individual image extrinsics')\n",
    "    for i, image_file in enumerate(tqdm(image_files)):\n",
    "        # Undistort image\n",
    "        image_undistorted_file = os.path.join(\n",
    "            output_folder, \n",
    "            os.path.splitext(os.path.basename(image_file))[0] + '_undistorted.tiff'\n",
    "            )\n",
    "        image = cv2.imread(image_file, cv2.IMREAD_GRAYSCALE)\n",
    "        # Save one cropped and one not cropped\n",
    "        image_undistorted = cv2.undistort(image, K, dist, None, K)\n",
    "        cv2.imwrite(image_undistorted_file, image_undistorted)\n",
    "        image_undistorted_nocrop = cv2.undistort(image, K, dist, None, K_full)\n",
    "        cv2.imwrite(image_undistorted_file.replace('.tiff', '_nocrop.tiff'), image_undistorted_nocrop)\n",
    "\n",
    "        # Undistort GCP pixel coordinates\n",
    "        gcp_image = gcp.loc[gcp['image_name']==os.path.basename(image_file)]\n",
    "        image_pts = gcp_image[['col_sample','row_sample']].values.astype(np.float32)\n",
    "        undistorted_pts = cv2.undistortPoints(image_pts, K, dist, P=K).reshape(-1, 2)\n",
    "        gcp_image['col_sample_undistorted'] = undistorted_pts[:, 0]\n",
    "        gcp_image['row_sample_undistorted'] = undistorted_pts[:, 1]\n",
    "        # reproject to lat-lon\n",
    "        gcp_reformat = gcp_image.copy()\n",
    "        gcp_reformat['geometry'] = [Point(x,y) for x,y in gcp_image[['X','Y']].values]\n",
    "        gcp_gdf = gpd.GeoDataFrame(geometry=gcp_reformat['geometry'], crs='EPSG:4978')\n",
    "        gcp_gdf = gcp_gdf.to_crs(\"EPSG:4326\")\n",
    "        gcp_reformat['lon'] = [x.coords.xy[0][0] for x in gcp_gdf['geometry']]\n",
    "        gcp_reformat['lat'] = [x.coords.xy[1][0] for x in gcp_gdf['geometry']]\n",
    "        # update image names\n",
    "        gcp_reformat['image_name'] = [x.replace('.tiff','_undistorted.tiff') for x in gcp_reformat['image_name']]\n",
    "        # add other relevant columns\n",
    "        gcp_reformat[['lat_std', 'lon_std', 'Z_std']] = 0.2, 0.2, 0.2\n",
    "        gcp_reformat[['use_lat', 'use_lon']] = 1, 1\n",
    "        # reorder and select appropriate columns\n",
    "        gcp_reformat = gcp_reformat[[\n",
    "            'lat', 'lon', 'Z', 'lat_std', 'lon_std', 'Z_std', \n",
    "            'image_name', 'col_sample_undistorted', 'row_sample_undistorted',\n",
    "            'use_lat', 'use_lon'\n",
    "            ]]\n",
    "        gcp_reformat.reset_index(drop=True, inplace=True)\n",
    "        # save to file\n",
    "        gcp_undistorted_file = os.path.join(\n",
    "            output_folder, \n",
    "            os.path.splitext(os.path.basename(image_file))[0] + '_undistorted.gcp'\n",
    "            )\n",
    "        gcp_reformat.to_csv(\n",
    "            gcp_undistorted_file, \n",
    "            sep=' ',\n",
    "            index=True,\n",
    "            header=False\n",
    "            )\n",
    "\n",
    "        # Save camera extrinsics as TSAI camera model\n",
    "        # convert rotation matrix from world -> camera to camera -> world\n",
    "        R_wc = cv2.Rodrigues(rvecs[i])[0]\n",
    "        R_cw = R_wc.T\n",
    "        # calculate camera center\n",
    "        C = -R_cw @ tvecs[i].reshape(3) + object_points_mean.reshape(3)\n",
    "        # compile in dictionary\n",
    "        tsai_dict = {\n",
    "            'fu': K[0,0],\n",
    "            'fv': K[1,1],\n",
    "            'cu': K[0,2],\n",
    "            'cv': K[1,2],\n",
    "            'u_direction': [1,0,0],\n",
    "            'v_direction': [0,1,0],\n",
    "            'w_direction': [0,0,1],\n",
    "            'C': C,\n",
    "            'R': R_cw,\n",
    "            'pitch': 1,\n",
    "        }\n",
    "        # save to file\n",
    "        tsai_file = os.path.join(\n",
    "            output_folder, \n",
    "            os.path.splitext(os.path.basename(image_file))[0] + '_undistorted.tsai'\n",
    "            )\n",
    "        save_tsai(tsai_dict, tsai_file)\n",
    "\n",
    "        if plot_results:\n",
    "            fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
    "            ax[0].imshow(image, cmap='Grays_r')\n",
    "            ax[0].plot(\n",
    "                gcp_image['col_sample'], gcp_image['row_sample'], 'xr',\n",
    "                markersize=5, linewidth=1.5\n",
    "                )\n",
    "            ax[0].set_title('Original')\n",
    "            ax[1].imshow(image_undistorted, cmap='gray')\n",
    "            ax[1].plot(\n",
    "                gcp_image['col_sample_undistorted'], gcp_image['row_sample_undistorted'], 'xr',\n",
    "                markersize=5, linewidth=1.5\n",
    "                )\n",
    "            ax[1].set_title('Undistorted')\n",
    "            for axis in ax:\n",
    "                axis.set_xticks([]), axis.set_yticks([])\n",
    "            plt.tight_layout()\n",
    "            # save to file\n",
    "            fig_file = os.path.join(output_folder, os.path.splitext(os.path.basename(image_file))[0] + '_undistorted.png')\n",
    "            fig.savefig(fig_file, dpi=300, bbox_inches='tight')\n",
    "            # print('Saved results figure:', fig_file)\n",
    "            plt.close()\n",
    "\n",
    "    return\n",
    "\n",
    "os.makedirs(undistorted_folder, exist_ok=True)\n",
    "\n",
    "# GROUP 1\n",
    "print('\\nGROUP 1: ch01-08\\n----------')\n",
    "image_list = sorted(glob(os.path.join(new_image_folder, '*.tiff')))[0:8]\n",
    "# calculate shared calibration\n",
    "print('Optimizing shared camera intrinsics using GCP...')\n",
    "calibrate_cameras(image_list, gcp_merged_ecef_file, undistorted_folder, file_prefix='group1-')\n",
    "\n",
    "# GROUP 2\n",
    "print('\\nGROUP 2: ch09-16\\n----------')\n",
    "image_list = sorted(glob(os.path.join(new_image_folder, '*.tiff')))[8:]\n",
    "# calculate shared calibration\n",
    "print('Optimizing shared camera intrinsics using GCP...')\n",
    "calibrate_cameras(image_list, gcp_merged_ecef_file, undistorted_folder, file_prefix='group2-')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec464908",
   "metadata": {},
   "source": [
    "## Initial orthorectification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf51adfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(init_ortho_folder, exist_ok=True)\n",
    "\n",
    "image_list = sorted(glob(os.path.join(undistorted_folder, '*_undistorted.tiff')))\n",
    "cam_list = sorted(glob(os.path.join(undistorted_folder, '*_undistorted.tsai')))\n",
    "\n",
    "# Mapproject\n",
    "for image_file, cam_file in zip(image_list, cam_list):\n",
    "    image_out_file = os.path.join(init_ortho_folder, os.path.basename(image_file).replace('.tiff', '_map.tiff'))\n",
    "    cmd = [\n",
    "        'mapproject',\n",
    "        '--threads', '12',\n",
    "        '--nodata-value', '0',\n",
    "        '--tr', '0.003',\n",
    "        refdem_file, image_file, cam_file, image_out_file\n",
    "    ]\n",
    "    subprocess.run(cmd)\n",
    "\n",
    "# Mosaic orthoimages\n",
    "print('\\nMosaicking orthoimages')\n",
    "image_list = sorted(glob(os.path.join(init_ortho_folder, '*.tiff')))\n",
    "mosaic_file = os.path.join(init_ortho_folder, f'orthomosaic.tif')\n",
    "fnc = shutil.which('gdal_merge.py')\n",
    "cmd = [\n",
    "    'python', fnc,\n",
    "    '-o', mosaic_file,\n",
    "    '-n', '0',\n",
    "    '-a_nodata', '-9999'\n",
    "] + image_list\n",
    "subprocess.run(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3910bacc",
   "metadata": {},
   "source": [
    "## Run stereo preprocessing to create dense match files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df298f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_stereo_folder = os.path.join(out_folder, 'init_stereo')\n",
    "os.makedirs(init_stereo_folder, exist_ok=True)\n",
    "\n",
    "image_list = sorted(glob(os.path.join(undistorted_folder, '*_undistorted.tiff')))\n",
    "cam_list = sorted(glob(os.path.join(undistorted_folder, '*_undistorted.tsai')))\n",
    "\n",
    "# Set up image pairs\n",
    "image1_list, image2_list = image_list[0:-1], image_list[1:]\n",
    "cam1_list, cam2_list = cam_list[0:-1], cam_list[1:]\n",
    "\n",
    "# skip the 8/9 cams pair (different intrinsics solving during bundle adjust)\n",
    "iskip = [i for i in range(0,len(image1_list)) if 'ch08' in image1_list[i]][0]\n",
    "image1_list = image1_list[0:iskip] + image1_list[iskip+1:]\n",
    "image2_list = image2_list[0:iskip] + image2_list[iskip+1:]\n",
    "cam1_list = cam1_list[0:iskip] + cam1_list[iskip+1:]\n",
    "cam2_list = cam2_list[0:iskip] + cam2_list[iskip+1:]\n",
    "\n",
    "# Iterate over pairs\n",
    "for i in tqdm(range(len(image1_list))):\n",
    "    image1, image2 = image1_list[i], image2_list[i]\n",
    "    cam1, cam2 = cam1_list[i], cam2_list[i]\n",
    "\n",
    "    pair_prefix = os.path.join(\n",
    "        init_stereo_folder,\n",
    "        os.path.splitext(os.path.basename(image1))[0] + '__' + os.path.splitext(os.path.basename(image2))[0],\n",
    "        'run'\n",
    "        )\n",
    "    \n",
    "    cmd = [\n",
    "        'parallel_stereo',\n",
    "        '--threads-singleprocess', '12',\n",
    "        '--threads-multiprocess', '12',\n",
    "        '--stop-point', '1',\n",
    "        image1, image2,\n",
    "        cam1, cam2,\n",
    "        pair_prefix,\n",
    "    ]\n",
    "    subprocess.run(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d9a851",
   "metadata": {},
   "source": [
    "## Bundle adjust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98bd743",
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_folder = os.path.join(out_folder, 'bundle_adjust')\n",
    "os.makedirs(ba_folder, exist_ok=True)\n",
    "\n",
    "image_list = sorted(glob(os.path.join(undistorted_folder, '*_undistorted.tiff')))\n",
    "cam_list = sorted(glob(os.path.join(undistorted_folder, '*_undistorted.tsai')))\n",
    "\n",
    "# Copy dense matches to bundle adjust folder\n",
    "match_list = sorted(glob(os.path.join(init_stereo_folder, '*', '*.match')))\n",
    "for match_file in match_list:\n",
    "    # get image pair\n",
    "    pair = os.path.dirname(match_file).split('/')[-1]\n",
    "    # check which group it's in\n",
    "    first_channel = pair.split('ch')[1][0:2]\n",
    "    group = 1 if float(first_channel) < 9 else 2\n",
    "    # define output file\n",
    "    match_out_file = os.path.join(\n",
    "        ba_folder, \n",
    "        f'run_group{group}-{pair}' + '.match'\n",
    "        )\n",
    "    # copy\n",
    "    _ = shutil.copy2(match_file, match_out_file)\n",
    "\n",
    "# GROUP 1\n",
    "print('\\nGROUP 1: ch01-08\\n----------')\n",
    "image_list_group1 = image_list[0:8]\n",
    "cam_list_group1 = cam_list[0:8]\n",
    "# Run bundle adjust\n",
    "cmd = [\n",
    "    'parallel_bundle_adjust',\n",
    "    '--threads', '12',\n",
    "    '--num-iterations', '2000',\n",
    "    '--num-passes', '2',\n",
    "    '--inline-adjustments',\n",
    "    '--force-reuse-match-files',\n",
    "    '--heights-from-dem', refdem_file,\n",
    "    '--heights-from-dem-uncertainty', '0.01',\n",
    "    '--solve-intrinsics',\n",
    "    '--intrinsics-to-share', 'optical_center,other_intrinsics',\n",
    "    '--intrinsics-to-float', 'all',\n",
    "    # '--fixed-distortion-indices', '2,3',\n",
    "    '-o', os.path.join(ba_folder, 'run_group1')\n",
    "] + image_list_group1 + cam_list_group1\n",
    "subprocess.run(cmd)\n",
    "\n",
    "# GROUP 2\n",
    "print('\\nGROUP 2: ch09-16\\n----------')\n",
    "image_list_group2 = image_list[8:]\n",
    "cam_list_group2 = cam_list[8:]\n",
    "# Run bundle adjust\n",
    "cmd = [\n",
    "    'parallel_bundle_adjust',\n",
    "    '--threads', '12',\n",
    "    '--num-iterations', '2000',\n",
    "    '--num-passes', '2',\n",
    "    '--inline-adjustments',\n",
    "    '--force-reuse-match-files',\n",
    "    '--heights-from-dem', refdem_file,\n",
    "    '--heights-from-dem-uncertainty', '0.01',\n",
    "    '--solve-intrinsics',\n",
    "    '--intrinsics-to-share', 'optical_center,other_intrinsics',\n",
    "    '--intrinsics-to-float', 'all',\n",
    "    # '--fixed-distortion-indices', '2,3',\n",
    "    '-o', os.path.join(ba_folder, 'run_group2')\n",
    "] + image_list_group2 + cam_list_group2\n",
    "subprocess.run(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c37556",
   "metadata": {},
   "source": [
    "## Modify optimized cameras to include full image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ef8832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_tsai_intrinsics_to_full_fov(\n",
    "    calib_csv_list,\n",
    "    ba_cam_folder,\n",
    "    output_cam_folder,\n",
    "):\n",
    "    os.makedirs(output_cam_folder, exist_ok=True)\n",
    "    cam_list = sorted(glob(os.path.join(ba_cam_folder, '*.tsai')))\n",
    "\n",
    "    for calib_file in calib_csv_list:\n",
    "        print('Processing:',calib_file)\n",
    "        calib = pd.read_csv(calib_file)\n",
    "        calib[\"K\"] = calib[\"K\"].apply(lambda s: np.array(ast.literal_eval(s)))\n",
    "        calib[\"K_full\"] = calib[\"K_full\"].apply(lambda s: np.array(ast.literal_eval(s)))\n",
    "        calib[\"distortion_coefficients\"] = calib[\"distortion_coefficients\"].apply(\n",
    "            lambda s: np.array(ast.literal_eval(s))\n",
    "        )\n",
    "\n",
    "        for _, row in tqdm(calib.iterrows(), total=len(calib)):\n",
    "            image_file = row[\"image_name\"]\n",
    "            image_base = os.path.splitext(os.path.basename(image_file))[0]\n",
    "\n",
    "            # Find matching .tsai camera file\n",
    "            cam_matches = [x for x in cam_list if image_base in os.path.basename(x)]\n",
    "            if not cam_matches:\n",
    "                print(f\"[WARN] No camera found for {image_base}\")\n",
    "                continue\n",
    "            cam_file = cam_matches[0]\n",
    "\n",
    "            # Read the optimized camera intrinsics from .tsai\n",
    "            with open(cam_file, \"r\") as f:\n",
    "                cam_lines = [l.strip() for l in f.readlines() if l.strip()]\n",
    "\n",
    "            fu = fv = cu = cv = None\n",
    "            for line in cam_lines:\n",
    "                if line.startswith(\"fu\"):\n",
    "                    fu = float(line.split()[-1])\n",
    "                elif line.startswith(\"fv\"):\n",
    "                    fv = float(line.split()[-1])\n",
    "                elif line.startswith(\"cu\"):\n",
    "                    cu = float(line.split()[-1])\n",
    "                elif line.startswith(\"cv\"):\n",
    "                    cv = float(line.split()[-1])\n",
    "\n",
    "            if None in (fu, fv, cu, cv):\n",
    "                print(f\"[WARN] Missing intrinsic values in {cam_file}\")\n",
    "                continue\n",
    "\n",
    "            # Construct intrinsic matrices\n",
    "            K_opt = np.array([[fu, 0, cu],\n",
    "                              [0, fv, cv],\n",
    "                              [0, 0, 1]])\n",
    "            K_crop = row[\"K\"].reshape(3, 3)\n",
    "            K_full = row[\"K_full\"].reshape(3, 3)\n",
    "\n",
    "            # Compute transform crop -> full\n",
    "            H = K_full @ np.linalg.inv(K_crop)\n",
    "\n",
    "            # Map optimized intrinsics into full-FOV coordinate system\n",
    "            K_opt_full = H @ K_opt\n",
    "            K_opt_full /= K_opt_full[2, 2]\n",
    "\n",
    "            fu_full = K_opt_full[0, 0]\n",
    "            fv_full = K_opt_full[1, 1]\n",
    "            cu_full = K_opt_full[0, 2]\n",
    "            cv_full = K_opt_full[1, 2]\n",
    "\n",
    "            # Update lines\n",
    "            updated_lines = []\n",
    "            for line in cam_lines:\n",
    "                if line.startswith(\"fu\"):\n",
    "                    updated_lines.append(f\"fu = {fu_full}\")\n",
    "                elif line.startswith(\"fv\"):\n",
    "                    updated_lines.append(f\"fv = {fv_full}\")\n",
    "                elif line.startswith(\"cu\"):\n",
    "                    updated_lines.append(f\"cu = {cu_full}\")\n",
    "                elif line.startswith(\"cv\"):\n",
    "                    updated_lines.append(f\"cv = {cv_full}\")\n",
    "                else:\n",
    "                    updated_lines.append(line)\n",
    "\n",
    "            # Write out new camera file\n",
    "            cam_out_file = os.path.join(\n",
    "                output_cam_folder, os.path.basename(cam_file).replace(\".tsai\", \"_full.tsai\")\n",
    "            )\n",
    "            with open(cam_out_file, \"w\") as f:\n",
    "                f.write(\"\\n\".join(updated_lines) + \"\\n\")\n",
    "\n",
    "\n",
    "calib_list = sorted(glob(os.path.join(undistorted_folder, '*camera_calibration_params.csv')))\n",
    "update_tsai_intrinsics_to_full_fov(calib_list, ba_folder, full_cam_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39935435",
   "metadata": {},
   "source": [
    "## Final orthorectification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9facfc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(final_ortho_folder, exist_ok=True)\n",
    "\n",
    "image_list = sorted(glob(os.path.join(undistorted_folder, '*_undistorted_nocrop.tiff')))\n",
    "cam_list = sorted(glob(os.path.join(full_cam_folder, '*.tsai')))\n",
    "\n",
    "# Mapproject\n",
    "for image_file, cam_file in zip(image_list, cam_list):\n",
    "    image_out_file = os.path.join(final_ortho_folder, os.path.basename(image_file).replace('.tiff', '_map.tiff'))\n",
    "    cmd = [\n",
    "        'mapproject',\n",
    "        '--threads', '12',\n",
    "        '--nodata-value', '0',\n",
    "        '--tr', '0.003',\n",
    "        refdem_file, image_file, cam_file, image_out_file\n",
    "    ]\n",
    "    subprocess.run(cmd)\n",
    "\n",
    "# Mosaic orthoimages\n",
    "print('\\nMosaicking orthoimages')\n",
    "image_list = sorted(glob(os.path.join(final_ortho_folder, '*.tiff')))\n",
    "mosaic_file = os.path.join(final_ortho_folder, f'orthomosaic.tif')\n",
    "fnc = shutil.which('gdal_merge.py')\n",
    "cmd = [\n",
    "    'python', fnc,\n",
    "    '-o', mosaic_file,\n",
    "    '-n', '0',\n",
    "    '-a_nodata', '-9999'\n",
    "] + image_list\n",
    "subprocess.run(cmd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03085baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_folder = os.path.join(out_folder, 'testing')\n",
    "os.makedirs(test_folder, exist_ok=True)\n",
    "\n",
    "# Open the calibration file\n",
    "calib_file = os.path.join(undistorted_folder, 'group1-camera_calibration_params.csv')\n",
    "calib = pd.read_csv(calib_file)\n",
    "# convert to arrays\n",
    "calib[\"K\"] = calib[\"K\"].apply(lambda s: np.array(ast.literal_eval(s)))\n",
    "calib[\"K_full\"] = calib[\"K_full\"].apply(lambda s: np.array(ast.literal_eval(s)))\n",
    "calib['distortion_coefficients'] = calib[\"distortion_coefficients\"].apply(lambda s: np.array(ast.literal_eval(s)))\n",
    "\n",
    "# Open the image\n",
    "image_file = calib.iloc[0]['image_name']\n",
    "image = cv2.imread(image_file, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Read the params\n",
    "K_crop = calib.iloc[0]['K'].reshape(3,3)\n",
    "K_full = calib.iloc[0]['K_full'].reshape(3,3)\n",
    "dist = calib.iloc[0]['distortion_coefficients'].reshape(-1,1)\n",
    "h,w = image.shape\n",
    "\n",
    "# Adjust focal length in the TSAI camera\n",
    "cam_file = glob(os.path.join(ba_folder, '*' + os.path.splitext(os.path.basename(image_file))[0] + '*.tsai'))[0]\n",
    "with open(cam_file, 'r') as f:\n",
    "    cam_lines = f.read().split('\\n')\n",
    "cam_lines = [x for x in cam_lines if x!='']\n",
    "for line in cam_lines:\n",
    "    if 'fu' in line:\n",
    "        fu = float(line.split(' ')[-1])\n",
    "    if 'fv' in line:\n",
    "        fv = float(line.split(' ')[-1])\n",
    "    if 'cu' in line:\n",
    "        cu = float(line.split(' ')[-1])\n",
    "    if 'cv' in line:\n",
    "        cv = float(line.split(' ')[-1])\n",
    "\n",
    "# Construct optimized K from bundle adjust\n",
    "K_opt = np.array([\n",
    "    [fu, 0, cu],\n",
    "    [0, fv, cv],\n",
    "    [0, 0, 1]\n",
    "    ])\n",
    "\n",
    "# Calculate transform from cropped -> full undistorted image frame\n",
    "H = K_full @ np.linalg.inv(K_crop)\n",
    "\n",
    "# Map optimized intrinsics into full image coordinate system\n",
    "K_opt_full = H @ K_opt\n",
    "K_opt_full /= K_opt_full[2, 2]  # normalize\n",
    "fu_full = K_opt_full[0, 0]\n",
    "fv_full = K_opt_full[1, 1]\n",
    "cu_full = K_opt_full[0, 2]\n",
    "cv_full = K_opt_full[1, 2]\n",
    "\n",
    "print(fu_full, fv_full, cu_full, cv_full)\n",
    "\n",
    "# Write to file\n",
    "cam_out_file = os.path.join(test_folder, os.path.basename(cam_file).replace('.tsai', '_full.tsai'))\n",
    "for i, line in enumerate(cam_lines):\n",
    "    if 'fu' in line:\n",
    "        cam_lines[i] = f'fu = {fu_full}'\n",
    "    if 'fv' in line:\n",
    "        cam_lines[i] = f'fv = {fv_full}'\n",
    "    if 'cu' in cam_lines:\n",
    "        cam_lines[i] = f'cu = {cu_full}'\n",
    "    if 'cv' in cam_lines:\n",
    "        cam_lines[i] = f'cv = {cu_full}'\n",
    "cam_lines_merged = '\\n'.join(cam_lines) + '\\n'\n",
    "with open(cam_out_file, 'w') as f:\n",
    "    f.write(cam_lines_merged)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soo_locs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
