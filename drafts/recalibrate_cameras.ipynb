{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55d91ffa",
   "metadata": {},
   "source": [
    "# Re-calibrate cameras after movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b09650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import ast\n",
    "import numpy as np\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import MultiPolygon, Point\n",
    "\n",
    "data_folder = '/Users/rdcrlrka/Research/Soo_locks'\n",
    "og_image_list = sorted(glob(os.path.join(data_folder, 'camera_calibration', 'single_band_images', '*.tiff')))\n",
    "new_image_list = sorted(glob(os.path.join(data_folder, 'camera_calibration', 'images20251021', '*.tiff')))\n",
    "print(f\"Found {len(og_image_list)} images coincident and {len(new_image_list)} images not coincident with lidar.\")\n",
    "\n",
    "# Grab other input files\n",
    "gcp_file = os.path.join(os.getcwd(), '..', '..', 'inputs', 'gcp', 'GCP_merged_stable.gpkg')\n",
    "refdem_file = os.path.join(os.getcwd(), '..', '..', 'inputs', 'lidar_DSM_filled_cropped.tif')\n",
    "refl_file = os.path.join(os.getcwd(), '..', '..', 'inputs', '20251001_Soo_Model_1cm_Intensity_UTM19N-fake.tif')\n",
    "calib_file = os.path.join(data_folder, 'camera_calibration', 'calibration_params', 'calibration_parameters_merged.csv')\n",
    "water_mask_file = os.path.join(data_folder, 'inputs', 'water_mask.gpkg')\n",
    "\n",
    "# Load merged camera calibration parameters\n",
    "calib = pd.read_csv(calib_file)\n",
    "for k in ['K', 'D', 'K_full', 'R_rectified', 't_rectified']:\n",
    "    calib[k] = calib[k].apply(ast.literal_eval)\n",
    "calib.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462ccd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Apply calibration to original image as a check ---\n",
    "def apply_calibration(image_file, calib_params, dem_file):\n",
    "    # extract calibration params\n",
    "    K, D, K_full, R_rectified, t_rectified = calib_params\n",
    "\n",
    "    # load image\n",
    "    image = cv2.imread(image_file, cv2.IMREAD_GRAYSCALE)\n",
    "    h, w = image.shape[:2]\n",
    "    dim = (int(w), int(h))\n",
    "\n",
    "    # undistort\n",
    "    map1, map2 = cv2.fisheye.initUndistortRectifyMap(K, D, np.eye(3), K_full, dim, cv2.CV_32FC1)\n",
    "    undistorted = cv2.remap(image, map1, map2, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT)\n",
    "\n",
    "    # Mask invalid pixels\n",
    "    mask = np.ones((h, w), dtype=np.uint8) * 255\n",
    "    mask_undistorted = cv2.remap(mask, map1, map2, interpolation=cv2.INTER_NEAREST)\n",
    "    valid_mask = mask_undistorted > 0\n",
    "    undistorted = undistorted.astype(np.float32)\n",
    "    undistorted[~valid_mask] = np.nan\n",
    "\n",
    "    # Orthorectification using DEM\n",
    "    # load DEM\n",
    "    dem = rxr.open_rasterio(dem_file).squeeze()\n",
    "    dem = xr.where(dem==-9999, np.nan, dem)\n",
    "    # Build world coordinates for valid DEM pixels\n",
    "    dem_z = dem.data\n",
    "    X, Y = np.meshgrid(dem.x.data, dem.y.data)\n",
    "    valid_dem_mask = np.isfinite(dem_z)\n",
    "    world_pts = np.stack([X[valid_dem_mask], Y[valid_dem_mask], dem_z[valid_dem_mask]], axis=-1)\n",
    "\n",
    "    # Project valid DEM points\n",
    "    img_pts, _ = cv2.projectPoints(world_pts, cv2.Rodrigues(R_rectified)[0], t_rectified, K_full, np.zeros(5))\n",
    "    map_x = np.full_like(dem_z, np.nan, dtype=np.float32)\n",
    "    map_y = np.full_like(dem_z, np.nan, dtype=np.float32)\n",
    "    map_x[valid_dem_mask] = img_pts[:, 0, 0]\n",
    "    map_y[valid_dem_mask] = img_pts[:, 0, 1]\n",
    "\n",
    "    # Remap undistorted image to DEM grid\n",
    "    ortho = np.full_like(dem_z, np.nan, dtype=np.float32)\n",
    "    in_bounds = (\n",
    "        (map_x >= 0) & (map_x < undistorted.shape[1]) &\n",
    "        (map_y >= 0) & (map_y < undistorted.shape[0])\n",
    "    )\n",
    "    sampled = cv2.remap(\n",
    "        undistorted, \n",
    "        map_x.astype(np.float32), \n",
    "        map_y.astype(np.float32),\n",
    "        interpolation=cv2.INTER_LINEAR\n",
    "        )\n",
    "    ortho[in_bounds] = sampled[in_bounds]\n",
    "    ortho = np.where(np.isnan(dem_z), np.nan, ortho)\n",
    "\n",
    "    # Convert to DataArray\n",
    "    ortho_xr = xr.DataArray(\n",
    "        data=ortho,\n",
    "        dims=('y', 'x'),\n",
    "        coords={'x': dem.x.data, 'y': dem.y.data}\n",
    "    )\n",
    "\n",
    "    # Drop empty rows/cols\n",
    "    ortho_xr = ortho_xr.dropna(dim='x', how='all').dropna(dim='y', how='all')\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10,5))\n",
    "    ax[0].imshow(image, cmap='Grays_r')\n",
    "    ax[1].imshow(\n",
    "        ortho_xr.data, cmap='Grays_r',\n",
    "        extent=(min(ortho_xr.x), max(ortho_xr.x), min(ortho_xr.y), max(ortho_xr.y))\n",
    "        )\n",
    "    plt.show()\n",
    "\n",
    "params = [np.array(x) for x in calib.iloc[0][['K', 'D', 'K_full', 'R_rectified', 't_rectified']].values]\n",
    "apply_calibration(\n",
    "    og_image_list[0],\n",
    "    params,\n",
    "    refdem_file\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb284fc",
   "metadata": {},
   "source": [
    "## Adjust center points in new images via feature matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7ab8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def undistort_image(img, K, D, K_full):\n",
    "    # Undistort\n",
    "    h,w = img.shape\n",
    "    map1, map2 = cv2.fisheye.initUndistortRectifyMap(K, D, np.eye(3), K_full, (w,h), cv2.CV_32FC1)\n",
    "    img_undistorted = cv2.remap(img, map1, map2, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT)\n",
    "\n",
    "    # Mask invalid pixels\n",
    "    # mask = np.ones((h, w), dtype=np.uint8) * 255\n",
    "    # mask_undistorted = cv2.remap(mask, map1, map2, interpolation=cv2.INTER_NEAREST)\n",
    "    # valid_mask = mask_undistorted > 0\n",
    "    # img_undistorted = img_undistorted.astype(np.float32)\n",
    "    # img_undistorted[~valid_mask] = np.nan\n",
    "\n",
    "    return img_undistorted\n",
    "\n",
    "\n",
    "def filter_mask_matches(matches, kp1, K, R, t, mask_geom, z0=-8):\n",
    "    ikeep = []\n",
    "    \n",
    "    # Calculate matrix inverses\n",
    "    K_inv = np.linalg.inv(K)\n",
    "    R_inv = R.T\n",
    "    C = -R_inv @ t  # camera center in world coords\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6,8))\n",
    "    for geom in mask_geom.geoms:\n",
    "        ax.plot(geom.exterior.coords.xy[0], geom.exterior.coords.xy[1], '-k')\n",
    "\n",
    "\n",
    "    for i, match in enumerate(matches):\n",
    "        # Pixel coordinates (u, v)\n",
    "        u, v = kp1[match.queryIdx].pt\n",
    "        pixel = np.array([[u], [v], [1.0]])  # shape (3,1)\n",
    "\n",
    "        # Direction of viewing ray in world coords\n",
    "        ray_dir = R_inv @ (K_inv @ pixel)\n",
    "        ray_dir = ray_dir.flatten()\n",
    "        ray_dir /= np.linalg.norm(ray_dir)\n",
    "\n",
    "        # Intersect with ground z = z0\n",
    "        lam = (z0 - C[2, 0]) / ray_dir[2]\n",
    "        X = C.flatten() + lam * ray_dir\n",
    "        xw, yw, zw = X\n",
    "\n",
    "        # Check for intersection with mask geometry\n",
    "        pt_world = Point(xw, yw)\n",
    "        if mask_geom.intersects(pt_world):\n",
    "            continue\n",
    "        ikeep.append(i)\n",
    "\n",
    "        ax.plot(xw,yw,'.m')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Filter matches\n",
    "    matches_filtered = [matches[i] for i in ikeep]\n",
    "\n",
    "    return matches_filtered\n",
    "\n",
    "\n",
    "def solve_new_position(\n",
    "        img1_file: str = None, \n",
    "        img2_file: str = None, \n",
    "        img1_camera_params: list[np.array] = None,\n",
    "        water_mask_geom = None,\n",
    "        distance_threshold: int = 70\n",
    "        ):\n",
    "    # Load images\n",
    "    img1 = cv2.imread(img1_file, cv2.IMREAD_GRAYSCALE)\n",
    "    img2 = cv2.imread(img2_file, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Construct image 1 camera parameters\n",
    "    K, D, K_full, Rvec, tvec = img1_camera_params\n",
    "\n",
    "    # Convert R vector to matrix\n",
    "    R1, _ = cv2.Rodrigues(np.array(Rvec))\n",
    "    t1 = np.array(tvec).reshape(3, 1) # make sure shape is correct\n",
    "\n",
    "    # Undistort images\n",
    "    img1_und = undistort_image(img1, K, D, K_full)\n",
    "    img2_und = undistort_image(img2, K, D, K_full)\n",
    "    \n",
    "    # Detect and match features \n",
    "    orb = cv2.ORB_create() \n",
    "    kp1, des1 = orb.detectAndCompute(img1_und,None) \n",
    "    kp2, des2 = orb.detectAndCompute(img2_und,None)\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True) \n",
    "    matches = bf.match(des1, des2)\n",
    "\n",
    "    # Filter matches over water/ice\n",
    "    matches_filtered = filter_mask_matches(matches, kp1, K_full, R1, t1, water_mask_geom)\n",
    "    print(len(matches), \"initial matches\")\n",
    "    print(len(matches_filtered), \"remaining matches after filtering those over water/ice\")\n",
    "\n",
    "    # Filter by distance\n",
    "    print('Median match distance = ', np.nanmedian(np.array([x.distance for x in matches_filtered])))\n",
    "    matches_filtered = sorted(matches_filtered, key = lambda x:x.distance)\n",
    "    matches_filtered = [m for m in matches_filtered if m.distance < distance_threshold]\n",
    "    print(len(matches_filtered), \"remaining matches after distance filtering\")\n",
    "\n",
    "    # Draw first 10 matches.\n",
    "    plt.figure(figsize=(10,6))\n",
    "    img3 = cv2.drawMatches(\n",
    "        img1_und, kp1, img2_und, kp2, matches_filtered[:10], None,\n",
    "        matchesThickness=5, \n",
    "        flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS\n",
    "        )\n",
    "    plt.imshow(img3),plt.show()\n",
    "    \n",
    "    if len(matches_filtered) < 8:\n",
    "        raise RuntimeError(\"Not enough matches left after filtering to estimate pose.\")\n",
    "\n",
    "    # Extract matched points (from undistorted images)\n",
    "    pts1 = np.float32([kp1[m.queryIdx].pt for m in matches_filtered])\n",
    "    pts2 = np.float32([kp2[m.trainIdx].pt for m in matches_filtered])\n",
    "\n",
    "    # Calculate Essential Matrix\n",
    "    E, _ = cv2.findEssentialMat(pts1, pts2, K_full, method=cv2.RANSAC, prob=0.999, threshold=1.0)\n",
    "    if E is None:\n",
    "        raise RuntimeError(\"Essential matrix could not be computed â€” insufficient inliers or poor geometry.\")\n",
    "\n",
    "    # Recover relative rotation and translation\n",
    "    _, R_rel, t_rel, _ = cv2.recoverPose(E, pts1, pts2, K_full)\n",
    "\n",
    "    # Construct the second camera\n",
    "    R2 = R_rel @ R1\n",
    "    tvec2 = t1 + R1.T @ t_rel  # if both cameras share the same world coordinate frame\n",
    "\n",
    "    # Convert R matrix to vector\n",
    "    rvec2, _ = cv2.Rodrigues(R2)\n",
    "\n",
    "    return rvec2, tvec2\n",
    "\n",
    "\n",
    "def orthorectify(image_file, dem_file, Rvec, tvec, K, D, K_full):\n",
    "    # Undistort the image\n",
    "    image = cv2.imread(image_file, cv2.IMREAD_GRAYSCALE)\n",
    "    img_undistorted = undistort_image(image, K, D, K_full)\n",
    "\n",
    "    # Load DEM\n",
    "    dem = rxr.open_rasterio(dem_file).squeeze()\n",
    "    dem = xr.where(dem==-9999, np.nan, dem)\n",
    "   \n",
    "    # Build world coordinates for valid DEM pixels\n",
    "    dem_z = dem.data\n",
    "    X, Y = np.meshgrid(dem.x.data, dem.y.data)\n",
    "    valid_dem_mask = np.isfinite(dem_z)\n",
    "    world_pts = np.stack([X[valid_dem_mask], Y[valid_dem_mask], dem_z[valid_dem_mask]], axis=-1)\n",
    "\n",
    "    # Project valid DEM points\n",
    "    img_pts, _ = cv2.projectPoints(world_pts, cv2.Rodrigues(Rvec)[0], tvec, K_full, np.zeros(5))\n",
    "    map_x = np.full_like(dem_z, np.nan, dtype=np.float32)\n",
    "    map_y = np.full_like(dem_z, np.nan, dtype=np.float32)\n",
    "    map_x[valid_dem_mask] = img_pts[:, 0, 0]\n",
    "    map_y[valid_dem_mask] = img_pts[:, 0, 1]\n",
    "\n",
    "    # Remap undistorted image to DEM grid\n",
    "    ortho = np.full_like(dem_z, np.nan, dtype=np.float32)\n",
    "    in_bounds = (\n",
    "        (map_x >= 0) & (map_x < img_undistorted.shape[1]) &\n",
    "        (map_y >= 0) & (map_y < img_undistorted.shape[0])\n",
    "    )\n",
    "    sampled = cv2.remap(\n",
    "        img_undistorted, \n",
    "        map_x.astype(np.float32), \n",
    "        map_y.astype(np.float32),\n",
    "        interpolation=cv2.INTER_LINEAR\n",
    "        )\n",
    "    ortho[in_bounds] = sampled[in_bounds]\n",
    "    ortho = np.where(np.isnan(dem_z), np.nan, ortho)\n",
    "\n",
    "    # Convert to DataArray\n",
    "    ortho_xr = xr.DataArray(\n",
    "        data=ortho,\n",
    "        dims=('y', 'x'),\n",
    "        coords={'x': dem.x.data, 'y': dem.y.data}\n",
    "    )\n",
    "\n",
    "    # Drop empty rows/cols\n",
    "    ortho_xr = ortho_xr.dropna(dim='x', how='all').dropna(dim='y', how='all')\n",
    "\n",
    "    return ortho_xr\n",
    "\n",
    "\n",
    "water_mask = gpd.read_file(water_mask_file)\n",
    "water_geom = MultiPolygon(water_mask['geometry'].values)\n",
    "\n",
    "ch_idx = 5\n",
    "calib_list = [\n",
    "    calib.iloc[ch_idx]['K'], \n",
    "    calib.iloc[ch_idx]['D'], \n",
    "    calib.iloc[ch_idx]['K_full'], \n",
    "    calib.iloc[ch_idx]['R_rectified'], \n",
    "    calib.iloc[ch_idx]['t_rectified']\n",
    "    ]\n",
    "calib_list = [np.array(x) for x in calib_list]\n",
    "\n",
    "rvec2, tvec2 = solve_new_position(\n",
    "        og_image_list[ch_idx], \n",
    "        new_image_list[ch_idx], \n",
    "        calib_list,\n",
    "        water_geom\n",
    "        )\n",
    "\n",
    "ortho2 = orthorectify(\n",
    "    new_image_list[ch_idx], refdem_file, rvec2, tvec2, \n",
    "    np.array(calib.iloc[ch_idx]['K']), np.array(calib.iloc[ch_idx]['D']), np.array(calib.iloc[ch_idx]['K_full']), \n",
    ")\n",
    "\n",
    "ortho2.plot(cmap='Grays_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46eb701a",
   "metadata": {},
   "source": [
    "## Try cropping to a small area around each GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89dbb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load merged GCP\n",
    "gcp = gpd.read_file(gcp_file, layer='gcp_merged')\n",
    "gcp = gcp.dropna().reset_index(drop=True)\n",
    "gcp['channel'] = [f\"ch{x}\" if x >= 10 else f\"ch0{x}\" for x in gcp['channel']]\n",
    "\n",
    "for img1_file in og_image_list[0:1]:\n",
    "\n",
    "    # Get second image file name\n",
    "    ch = f\"ch{os.path.basename(img1_file).split('ch')[1][0:2]}\"\n",
    "    img2_file = [x for x in new_image_list if ch in os.path.basename(x)][0]\n",
    "\n",
    "    # Load images\n",
    "    img1 = cv2.imread(img1_file, cv2.IMREAD_GRAYSCALE)\n",
    "    img2 = cv2.imread(img2_file, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Get camera intrinsics\n",
    "    img_calib = calib.loc[calib['channel']==ch]\n",
    "    K, D, K_full = img_calib[['K', 'D', 'K_full']].values[0]\n",
    "    K, D, K_full = [np.array(x) for x in (K,D,K_full)]\n",
    "\n",
    "    # Iterate over GCP\n",
    "    world_pts = []\n",
    "    img_pts2 = []\n",
    "    gcp_img1 = gcp.loc[gcp['channel']==ch]\n",
    "    for i,gcp_row in gcp_img1.iterrows():\n",
    "        col_sample, row_sample = gcp_row[['col_sample', 'row_sample']].values\n",
    "\n",
    "        # crop images to col_sample, row_sample + a buffer\n",
    "        px_buffer = 70\n",
    "        col_range = int(np.round(col_sample)-px_buffer), int(np.round(col_sample)+px_buffer)\n",
    "        row_range = int(np.round(row_sample)-px_buffer), int(np.round(row_sample)+px_buffer)\n",
    "        img1_crop = img1[row_range[0]:row_range[1], col_range[0]:col_range[1]]\n",
    "        img2_crop = img2[row_range[0]:row_range[1], col_range[0]:col_range[1]]\n",
    "\n",
    "        # detect and match features\n",
    "        orb = cv2.ORB_create() \n",
    "        kp1, des1 = orb.detectAndCompute(img1_crop,None) \n",
    "        kp2, des2 = orb.detectAndCompute(img2_crop,None)        \n",
    "        bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True) \n",
    "        try:\n",
    "            matches = bf.match(des1, des2)\n",
    "        except:\n",
    "            continue\n",
    "        if len(matches) < 4:\n",
    "            continue\n",
    "\n",
    "        # Plot good matches\n",
    "        fig, ax = plt.subplots(1,2)\n",
    "        ax[0].imshow(img1_crop, cmap='Grays_r')\n",
    "        ax[1].imshow(img2_crop, cmap='Grays_r')\n",
    "        for i, match in enumerate(matches):\n",
    "            point1 = kp1[match.queryIdx].pt\n",
    "            point2 = kp2[match.trainIdx].pt\n",
    "            ax[0].plot(point1[0], point1[1], '.', color=plt.cm.viridis(i/len(matches)))\n",
    "            ax[1].plot(point2[0], point2[1], '.', color=plt.cm.viridis(i/len(matches)))\n",
    "        plt.show()\n",
    "\n",
    "        # Calculate average translation\n",
    "        displacements = [np.array(kp2[m.trainIdx].pt) - np.array(kp1[m.queryIdx].pt) for m in matches]\n",
    "        dx, dy = np.mean(displacements, axis=0)\n",
    "\n",
    "        # Convert back to full image coordinates\n",
    "        cx = col_range[0] + px_buffer\n",
    "        cy = row_range[0] + px_buffer\n",
    "        pt2 = np.array([cx + dx, cy + dy])\n",
    "        \n",
    "        # Append to lists\n",
    "        img_pts2.append(pt2)\n",
    "        world_pts.append([gcp_row['X'], gcp_row['Y'], gcp_row['Z']])\n",
    "        \n",
    "    # Convert to numpy arrays\n",
    "    world_pts = np.array(world_pts, dtype=np.float32)\n",
    "    img_pts2 = np.array(img_pts2, dtype=np.float32)\n",
    "\n",
    "    # Solve for new camera pose\n",
    "    success, rvec2, tvec2 = cv2.solvePnP(world_pts, img_pts2, K_full, distCoeffs=D)\n",
    "    print(\"Success:\", success)\n",
    "\n",
    "    # orthorectify with new matrices\n",
    "    ortho2 = orthorectify(img2_file, refdem_file, rvec2, tvec2, K, D, K_full)\n",
    "\n",
    "ortho2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c533655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_reflector_center(patch, threshold=200):\n",
    "    \"\"\"\n",
    "    Detect bright circular reflector in a patch using threshold + contour centroid.\n",
    "    Returns coordinates relative to patch or None if not found.\n",
    "    \"\"\"\n",
    "    _, binary = cv2.threshold(patch, threshold, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(contours) == 0:\n",
    "        return None\n",
    "    \n",
    "    print('Initial contours =', len(contours))\n",
    "    # Filter by area\n",
    "    valid_contours = [c for c in contours if cv2.contourArea(c) > 0]\n",
    "    if len(valid_contours) == 0:\n",
    "        return None\n",
    "    print('Valid contours =', len(valid_contours))\n",
    "\n",
    "    # Filter by circularity\n",
    "    valid_circular_contours = []\n",
    "    for c in valid_contours:\n",
    "        area = cv2.contourArea(c)\n",
    "        perimeter = cv2.arcLength(c, True)\n",
    "        circularity = 4 * np.pi * area / (perimeter**2)\n",
    "        if circularity > 0.5:\n",
    "            valid_circular_contours += [c]\n",
    "    if len(valid_circular_contours) == 0:\n",
    "        return None\n",
    "    print('Valid, circular contours =', len(valid_circular_contours))\n",
    "\n",
    "    # Use longest contour\n",
    "    imax = np.argmax([cv2.arcLength(c,True) for x in valid_circular_contours])\n",
    "    c_max = valid_circular_contours[imax]\n",
    "\n",
    "    M = cv2.moments(c_max)\n",
    "    if M['m00'] == 0:\n",
    "        return None\n",
    "    cx = M['m10'] / M['m00']\n",
    "    cy = M['m01'] / M['m00']\n",
    "\n",
    "    fig, ax = plt.subplots(1,1, figsize=(6,3))\n",
    "    ax.imshow(patch, cmap='gray')\n",
    "    for c in contours:\n",
    "        c = np.array([x[0] for x in c])\n",
    "        ax.plot(c[:,0], c[:,1], '-m', linewidth=0.5)\n",
    "    for c in valid_contours:\n",
    "        c = np.array([x[0] for x in c])\n",
    "        ax.plot(c[:,0], c[:,1], '-b', linewidth=0.5)\n",
    "    c_max = np.array([x[0] for x in c_max])\n",
    "    ax.plot(c_max[:,0], c_max[:,1], '-', color='yellow', linewidth=2)\n",
    "    ax.plot(cx, cy, 'ro', markersize=8)\n",
    "    plt.show()\n",
    "    \n",
    "    return np.array([cx, cy])\n",
    "\n",
    "\n",
    "def solve_camera_pose_from_reflectors(\n",
    "        img1_file, \n",
    "        img2_file, \n",
    "        calib_row,\n",
    "        gcp_df,\n",
    "        px_buffer=200,\n",
    "        threshold=200,\n",
    "    ):\n",
    "    # Load images\n",
    "    img1 = cv2.imread(img1_file, cv2.IMREAD_GRAYSCALE)\n",
    "    img2 = cv2.imread(img2_file, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Camera intrinsics\n",
    "    K, D, K_full = np.array(calib_row['K']), np.array(calib_row['D']), np.array(calib_row['K_full'])\n",
    "\n",
    "    world_pts = []\n",
    "    img_pts2 = []\n",
    "\n",
    "    for i, gcp_row in gcp_df.iterrows():\n",
    "        row_sample, col_sample = gcp_row[['row_sample','col_sample']].values\n",
    "\n",
    "        # crop around GCP\n",
    "        col_range = np.array([int(np.round(col_sample)-px_buffer), int(np.round(col_sample)+px_buffer)])\n",
    "        row_range = np.array([int(np.round(row_sample)-px_buffer), int(np.round(row_sample)+px_buffer)])\n",
    "        col_range = np.sort(np.clip([int(col_sample - px_buffer), int(col_sample + px_buffer)], 0, img1.shape[1]-1))\n",
    "        row_range = np.sort(np.clip([int(row_sample - px_buffer), int(row_sample + px_buffer)], 0, img1.shape[0]-1))\n",
    "        img1_crop = img1[row_range[0]:row_range[1], col_range[0]:col_range[1]]\n",
    "        img2_crop = img2[row_range[0]:row_range[1], col_range[0]:col_range[1]]\n",
    "        \n",
    "        # detect reflector centroids\n",
    "        center1 = detect_reflector_center(img1_crop, threshold)\n",
    "        center2 = detect_reflector_center(img2_crop, threshold)\n",
    "\n",
    "        if center1 is None or center2 is None:\n",
    "            continue  # skip if not found\n",
    "            \n",
    "        # Full image coordinates in img2\n",
    "        pt2_full = np.array([col_range[0], row_range[0]]) + center2\n",
    "\n",
    "        # Append to lists\n",
    "        img_pts2.append(pt2_full)\n",
    "        world_pts.append([gcp_row['X'], gcp_row['Y'], gcp_row['Z']])\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    if len(world_pts) < 4:\n",
    "        raise RuntimeError(\"Not enough GCPs detected to solve for camera pose.\")\n",
    "    world_pts = np.array(world_pts, dtype=np.float32)\n",
    "    img_pts2 = np.array(img_pts2, dtype=np.float32)\n",
    "\n",
    "    # Solve for camera 2 pose\n",
    "    success, rvec2, tvec2 = cv2.solvePnP(\n",
    "        world_pts,\n",
    "        img_pts2,\n",
    "        K_full,\n",
    "        distCoeffs=D\n",
    "    )\n",
    "    if not success:\n",
    "        raise RuntimeError(\"solvePnP failed\")\n",
    "\n",
    "    return rvec2, tvec2\n",
    "\n",
    "# Load merged GCP\n",
    "gcp = gpd.read_file(gcp_file, layer='gcp_merged')\n",
    "gcp = gcp.dropna().reset_index(drop=True)\n",
    "gcp['channel'] = [f\"ch{x}\" if x >= 10 else f\"ch0{x}\" for x in gcp['channel']]\n",
    "\n",
    "for i,img1_file in enumerate(og_image_list[1:2]):\n",
    "    ch = f\"ch{os.path.basename(img1_file).split('ch')[1][0:2]}\"\n",
    "    img2_file = [x for x in new_image_list if ch in os.path.basename(x)][0]\n",
    "    calib_row = calib.loc[calib['channel'] == ch].iloc[0]\n",
    "    gcp_df = gcp.loc[gcp['channel']==ch]\n",
    "    \n",
    "    rvec2, tvec2 = solve_camera_pose_from_reflectors(\n",
    "        img1_file, \n",
    "        img2_file, \n",
    "        calib_row,\n",
    "        gcp_df,\n",
    "        px_buffer=70,\n",
    "        threshold=200,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8136f8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soo_locks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
