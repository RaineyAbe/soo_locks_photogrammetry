{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1286680b",
   "metadata": {},
   "source": [
    "# Testing ortho workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e408ae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import cv2\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import subprocess\n",
    "import multiprocessing\n",
    "import shutil\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "import rasterio as rio\n",
    "\n",
    "data_folder = '/Users/rdcrlrka/Research/Soo_locks/20251001_imagery/'\n",
    "video_folder = os.path.join(data_folder, 'video')\n",
    "inputs_folder = '/Users/rdcrlrka/Research/Soo_locks/inputs/'\n",
    "refdem_file = os.path.join(inputs_folder, 'lidar_DSM_filled_cropped.tif')\n",
    "distort_param_file = os.path.join(inputs_folder, 'initial_undistortion_params.csv')\n",
    "camera_files = sorted(glob(os.path.join(inputs_folder, '*_calibrated_camera.tsai')))\n",
    "closest_cam_map_file = os.path.join(inputs_folder, 'closest_camera_map.tiff')\n",
    "\n",
    "out_folder = os.path.join(data_folder, 'testing')\n",
    "os.makedirs(out_folder, exist_ok=True)\n",
    "image_folder = os.path.join(out_folder, 'images')\n",
    "undistorted_folder = os.path.join(out_folder, 'images_undistorted')\n",
    "ortho_folder = os.path.join(out_folder, 'orthoimages')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d80f82",
   "metadata": {},
   "source": [
    "## Extract image frames from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54e5318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_datetime(datetime_string):\n",
    "    return datetime.datetime(\n",
    "        int(datetime_string[0:4]), \n",
    "        int(datetime_string[4:6]),\n",
    "        int(datetime_string[6:8]),\n",
    "        int(datetime_string[8:10]),\n",
    "        int(datetime_string[10:12]),\n",
    "        int(datetime_string[12:14])\n",
    "        )\n",
    "\n",
    "\n",
    "def extract_frame_at_clock_time(\n",
    "        video_file: str = None, \n",
    "        target_time_string: str = None, \n",
    "        output_folder: str = None, \n",
    "        output_format: str = 'tiff'\n",
    "        ):\n",
    "    \"\"\"Extract a frame from a video at a specific clock time and save as {video_file_name}.ext\"\"\"\n",
    "    # parse start and end times from video file name\n",
    "    start_time_string = os.path.basename(video_file).split('_')[3]\n",
    "    end_time_string = os.path.splitext(os.path.basename(video_file))[0].split('_')[4].split('(')[0]\n",
    "\n",
    "    # convert datetime strings to datetime objects\n",
    "    target_time = string_to_datetime(target_time_string)\n",
    "    start_time = string_to_datetime(start_time_string)\n",
    "    end_time = string_to_datetime(end_time_string)\n",
    "\n",
    "    print(f\"\\nProcessing {video_file}\")\n",
    "    print(f'Detected video time range: {start_time} to {end_time}')\n",
    "\n",
    "    # Open video file\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file '{video_file}'.\")\n",
    "        return False\n",
    "\n",
    "    # Determine the video time duration\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    duration = total_frames / fps if fps > 0 else 0\n",
    "\n",
    "    # Check if the target time is beyond the video coverage\n",
    "    time_offset = (target_time - start_time).total_seconds()\n",
    "    if time_offset < 0 or (time_offset > duration):\n",
    "        print(f\"Error: Target time {time_offset:.2f}s is outside video duration ({duration:.2f}s)\")\n",
    "        cap.release()\n",
    "        return False\n",
    "\n",
    "    # Otherwise, get the appropriate frame\n",
    "    frame_number = int(time_offset * fps)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(f\"Error: Could not extract frame at {time_offset:.2f}s\")\n",
    "        cap.release()\n",
    "        return False\n",
    "    \n",
    "    # Determine the camera number\n",
    "    ch = os.path.basename(video_file).split('ch')[1][0:2]\n",
    "    if (frame.shape[1] > 4000) & (ch=='1_'):\n",
    "        ch = '09'\n",
    "    elif (frame.shape[1] > 4000):\n",
    "        ch = str(int(ch[0]) + 8)\n",
    "    else:\n",
    "        ch = '0' + ch[0]\n",
    "\n",
    "    # Save to file\n",
    "    output_image_file = os.path.join(\n",
    "        output_folder, \n",
    "        f\"ch{ch}_{target_time_string}.{output_format}\"\n",
    "        )\n",
    "    # determine save settings based on output format\n",
    "    save_params = []\n",
    "    if output_format == 'png':\n",
    "        save_params = [cv2.IMWRITE_PNG_COMPRESSION, 3]\n",
    "    elif output_format in ['jpg', 'jpeg']:\n",
    "        save_params = [cv2.IMWRITE_JPEG_QUALITY, 100]\n",
    "\n",
    "    if cv2.imwrite(output_image_file, frame, save_params):\n",
    "        print(f\"Extracted frame -> {output_image_file}\")\n",
    "        cap.release()\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"Failed to save frame\")\n",
    "        cap.release()\n",
    "        return False\n",
    "    \n",
    "\n",
    "def process_video_files(\n",
    "        video_files: list[str] = None, \n",
    "        target_time_string: str = None, \n",
    "        output_folder: str = None, \n",
    "        output_format: str = 'tiff'\n",
    "        ):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    print('Target time:', string_to_datetime(target_time_string))\n",
    "\n",
    "    # Iterate over video files\n",
    "    for video_file in tqdm(video_files):\n",
    "        extract_frame_at_clock_time(video_file, target_time_string, output_folder, output_format)\n",
    "\n",
    "\n",
    "video_files = sorted(glob(os.path.join(video_folder, '*.avi')))\n",
    "process_video_files(\n",
    "    video_files, \n",
    "    target_time_string=\"20251001171500\",\n",
    "    output_folder=image_folder\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c675f544",
   "metadata": {},
   "source": [
    "## Apply initial distortion correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72908cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_initial_image_distortion(\n",
    "        params_file: str = None, \n",
    "        image_files: list[str] = None, \n",
    "        output_folder: str = None,\n",
    "        full_fov: bool = True\n",
    "        ):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Load the camera and distortion parameters file\n",
    "    params = pd.read_csv(params_file)\n",
    "    params['K'] = params['K'].apply(ast.literal_eval)\n",
    "    params['K_full'] = params['K_full'].apply(ast.literal_eval)\n",
    "    params['dist'] = params['dist'].apply(ast.literal_eval)\n",
    "\n",
    "    # Iterate over image files\n",
    "    for image_file in image_files:\n",
    "        # Read image\n",
    "        image = cv2.imread(image_file, cv2.IMREAD_UNCHANGED)\n",
    "        h,w = image.shape[:2]\n",
    "\n",
    "        # Determine the camera number\n",
    "        ch = os.path.basename(image_file).split('_')[0][2:]\n",
    "\n",
    "        # Get the respective distortion parameters\n",
    "        params_im = params.loc[params['camera']==int(ch)].reset_index().iloc[0]\n",
    "        K = np.array(params_im['K']).reshape(3,3)\n",
    "        K_full = np.array(params_im['K_full']).reshape(3,3)\n",
    "        dist = np.array(params_im['dist']).reshape(-1,1)\n",
    "\n",
    "        # Undistort\n",
    "        if full_fov:\n",
    "            # must do some remapping to maintain no data values\n",
    "            map1, map2 = cv2.initUndistortRectifyMap(K, dist, None, K_full, (w, h), cv2.CV_32FC1)\n",
    "            # apply undistortion to the image\n",
    "            image_undistorted = cv2.remap(image, map1, map2, interpolation=cv2.INTER_LINEAR)\n",
    "            # create a white mask and remap it the same way to find valid areas\n",
    "            mask = np.ones((h, w), dtype=np.uint8) * 255\n",
    "            mask_undistorted = cv2.remap(mask, map1, map2, interpolation=cv2.INTER_NEAREST)\n",
    "            # convert mask to boolean\n",
    "            valid_mask = mask_undistorted > 0\n",
    "            # Now set invalid pixels to NaN\n",
    "            image_undistorted_nodata = image_undistorted.astype(np.float32)\n",
    "            image_undistorted_nodata[~valid_mask] = np.nan\n",
    "        else:\n",
    "            image_undistorted = cv2.undistort(image, K, dist, None, K)\n",
    "\n",
    "        # Save to file\n",
    "        image_undistorted_file = os.path.join(\n",
    "            output_folder, \n",
    "            os.path.splitext(os.path.basename(image_file))[0] + '_undistorted.tiff'\n",
    "            )\n",
    "        if full_fov:\n",
    "            image_undistorted_file = os.path.splitext(image_undistorted_file)[0] + '_full.tiff'\n",
    "        cv2.imwrite(image_undistorted_file, image_undistorted)\n",
    "        print('Saved undistorted image:', image_undistorted_file)\n",
    "    print('Done with intial undistortion.')\n",
    "\n",
    "    return\n",
    "\n",
    "image_files = sorted(glob(os.path.join(image_folder, '*.tiff')))\n",
    "correct_initial_image_distortion(\n",
    "    distort_param_file, \n",
    "    image_files, \n",
    "    undistorted_folder, \n",
    "    full_fov=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c542cb55",
   "metadata": {},
   "source": [
    "## Orthorectification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc09c60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cmd(bin: str = None, \n",
    "            args: list = None, **kw) -> str:\n",
    "    \"\"\"\n",
    "    Wrapper for subprocess function to execute bash commands.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bin: str\n",
    "        command to be excuted (e.g., stereo or gdalwarp)\n",
    "    args: list\n",
    "        arguments to the command as a list\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    out: str\n",
    "        log (stdout) as str if the command executed, error message if the command failed\n",
    "    \"\"\"\n",
    "    binpath = shutil.which(bin)\n",
    "    call = [binpath,]\n",
    "    if args is not None: \n",
    "        call.extend(args)\n",
    "    try:\n",
    "        out = subprocess.run(call,check=True,capture_output=True,encoding='UTF-8').stdout\n",
    "    except:\n",
    "        out = f\"the command {call} failed to run, see corresponding log\"\n",
    "    return out\n",
    "\n",
    "\n",
    "def write_log_file(log, output_prefix):\n",
    "    # create a string of the current datetime\n",
    "    now_string = (\n",
    "        str(datetime.datetime.now())\n",
    "        .replace('-','')\n",
    "        .replace(' ','')\n",
    "        .replace(':','')\n",
    "        .replace('.','')\n",
    "    )\n",
    "\n",
    "    # create output file name\n",
    "    log_file = output_prefix + '_log_' + now_string + '.txt'\n",
    "\n",
    "    # write to file\n",
    "    with open(log_file, 'w') as f:\n",
    "        f.write(log)\n",
    "\n",
    "    return log_file\n",
    "\n",
    "\n",
    "def orthorectify(\n",
    "        image_list: list[str] = None, \n",
    "        camera_list: list[str] = None, \n",
    "        refdem_file: str = None, \n",
    "        output_folder: str = None,\n",
    "        nodata_value: str = 'NaN',\n",
    "        out_res: float = 0.003\n",
    "        ):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Determine number of threads to use\n",
    "    threads = multiprocessing.cpu_count()\n",
    "    print(f'Will use up to {threads} threads for each process.')\n",
    "\n",
    "    # Iterate over files\n",
    "    for image_file, cam_file in zip(image_list, camera_list):\n",
    "        # Define output file name\n",
    "        image_out_file = os.path.join(output_folder, os.path.basename(image_file))\n",
    "\n",
    "        # Set up and run command\n",
    "        print('Orthorectifying:', image_file)\n",
    "        args = [\n",
    "            '--threads', str(threads),\n",
    "            '--nodata-value', nodata_value,\n",
    "            '--tr', str(out_res),\n",
    "            refdem_file, image_file, cam_file, image_out_file\n",
    "        ]\n",
    "        log = run_cmd('mapproject', args)\n",
    "\n",
    "        # Save log to file\n",
    "        log_prefix = os.path.join(\n",
    "            output_folder, \n",
    "            os.path.splitext(os.path.basename(image_file))[0] + '_mapproject'\n",
    "            )\n",
    "        log_file = write_log_file(log, log_prefix)\n",
    "        print('Saved log:', log_file)\n",
    "\n",
    "    print('Done orthorectifying.')\n",
    "\n",
    "\n",
    "image_files = sorted(glob(os.path.join(undistorted_folder, '*.tiff')))\n",
    "\n",
    "orthorectify(image_files, camera_files, refdem_file, ortho_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cac324",
   "metadata": {},
   "source": [
    "## Mosaic orthorectified images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f108605b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mosaic_orthoimages(\n",
    "        image_files: list[str] = None, \n",
    "        closest_cam_map_file: str = None, \n",
    "        output_folder: str = None\n",
    "        ):\n",
    "    # Load the map of closest camera\n",
    "    print(\"Reading closest camera map\")\n",
    "    closest_cam_map = rxr.open_rasterio(closest_cam_map_file)\n",
    "    crs = closest_cam_map.rio.crs\n",
    "\n",
    "    # Load orthoimages\n",
    "    print(\"Reading orthoimages\")\n",
    "    datasets = [rxr.open_rasterio(f, masked=True) for f in image_files]\n",
    "\n",
    "    # Verify consistent CRS\n",
    "    for ds in datasets:\n",
    "        if ds.rio.crs != crs:\n",
    "            raise ValueError(f\"CRS mismatch in {ds.rio.nodata}\")\n",
    "\n",
    "    # Determine number of bands (use from first image)\n",
    "    num_bands = datasets[0].rio.count\n",
    "    print(f\"Detected {num_bands} band(s) per image\")\n",
    "\n",
    "    # Determine target resolution (average or min pixel size)\n",
    "    res_x = np.mean([abs(ds.rio.resolution()[0]) for ds in datasets])\n",
    "    res_y = np.mean([abs(ds.rio.resolution()[1]) for ds in datasets])\n",
    "    print(f\"Using target resolution: {res_x:.3f}, {res_y:.3f}\")\n",
    "\n",
    "    # Determine output bounds and grid\n",
    "    bounds = closest_cam_map.rio.bounds()\n",
    "    width = int((bounds[2] - bounds[0]) / res_x)\n",
    "    height = int((bounds[3] - bounds[1]) / res_y)\n",
    "    transform = rio.transform.from_bounds(*bounds, width=width, height=height)\n",
    "\n",
    "    # Create a dummy grid (reference for reprojection)\n",
    "    dummy_grid = xr.DataArray(\n",
    "        np.nan*np.zeros((height, width), dtype=np.uint8),\n",
    "        dims=(\"y\", \"x\"),\n",
    "        coords={\n",
    "            \"y\": np.linspace(bounds[3], bounds[1], height),\n",
    "            \"x\": np.linspace(bounds[0], bounds[2], width),\n",
    "        },\n",
    "    ).rio.write_crs(crs).rio.write_transform(transform)\n",
    "\n",
    "    # Reproject images\n",
    "    print(\"Reprojecting images to target grid...\")\n",
    "    reprojected = [\n",
    "        ds.rio.reproject_match(dummy_grid, resampling=rio.enums.Resampling.nearest)\n",
    "        for ds in datasets\n",
    "    ]\n",
    "\n",
    "    # Stack all reprojected images along a \"camera\" dimension\n",
    "    stack = xr.concat(reprojected, dim=\"camera\")\n",
    "\n",
    "    # Reproject closest_cam_map\n",
    "    print(\"Reprojecting closest_cam_map to target grid...\")\n",
    "    closest_cam_map = closest_cam_map.rio.reproject_match(dummy_grid, resampling=rio.enums.Resampling.nearest)\n",
    "\n",
    "    # Initialize mosaic with NaNs for all bands\n",
    "    print(\"Creating mosaic...\")\n",
    "    mosaic_shape = (num_bands, height, width)\n",
    "    mosaic = xr.DataArray(\n",
    "        np.full(mosaic_shape, np.nan, dtype=np.float32),\n",
    "        dims=(\"band\", \"y\", \"x\"),\n",
    "        coords={\"band\": np.arange(1, num_bands + 1), \"y\": dummy_grid.y, \"x\": dummy_grid.x},\n",
    "    ).rio.write_crs(crs).rio.write_transform(transform)\n",
    "\n",
    "    # Fill mosaic by selecting pixels based on closest_cam_map\n",
    "    for i in range(len(stack.camera)):\n",
    "        mask = closest_cam_map.squeeze() == i\n",
    "        if num_bands == 1:\n",
    "            mosaic = xr.where(mask, stack.isel(camera=i)[0], mosaic)\n",
    "        else:\n",
    "            for b in range(num_bands):\n",
    "                mosaic[b] = xr.where(mask, stack.isel(camera=i, band=b), mosaic[b])\n",
    "\n",
    "    # Save mosaic\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    mosaic_file = os.path.join(output_folder, \"orthomosaic.tif\")\n",
    "    mosaic.rio.to_raster(mosaic_file)\n",
    "    print(\"Saved orthomosaic:\", mosaic_file)\n",
    "\n",
    "\n",
    "image_files = sorted(glob(os.path.join(ortho_folder, '*.tiff')))\n",
    "mosaic_orthoimages(image_files, closest_cam_map_file, out_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soo_locs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
