{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2c9d518",
   "metadata": {},
   "source": [
    "# Calibrate cameras, create initial orthoimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aac52a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from ast import literal_eval\n",
    "import rasterio\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Locate image files\n",
    "data_folder = '/Users/rdcrlrka/Research/Soo_locks'\n",
    "image_folder = os.path.join(data_folder, 'inputs', 'original_images')\n",
    "image_files = sorted(glob(os.path.join(image_folder, '*.tiff')))\n",
    "print(f\"{len(image_files)} images located\")\n",
    "\n",
    "# Grab other input files\n",
    "gcp_folder = os.path.join(data_folder, 'inputs', 'gcp_new')\n",
    "refdem_file = os.path.join(data_folder, 'inputs', 'lidar_DSM_filled_cropped.tif')\n",
    "\n",
    "# Define output folders\n",
    "out_folder = os.path.join(data_folder, 'camera_calibration')\n",
    "os.makedirs(out_folder, exist_ok=True)\n",
    "single_band_folder = os.path.join(out_folder, 'single_band_images')\n",
    "calib_folder = os.path.join(out_folder, 'calibration_params')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c8f447",
   "metadata": {},
   "source": [
    "## Merge GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef6f860",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcp_merged_file = os.path.join(gcp_folder, '..', 'GCP_merged.gpkg')\n",
    "if not os.path.exists(gcp_merged_file):\n",
    "    gdf_list = []\n",
    "    gcp_files = sorted(glob(os.path.join(gcp_folder, '*.gcp')))\n",
    "    for f in gcp_files:\n",
    "        df = pd.read_csv(\n",
    "            f, \n",
    "            skiprows=[0], \n",
    "            header=None,\n",
    "            names = ['pt_number', 'lat', 'lon', 'Z', 'std_X', 'std_Y', 'std_Z', 'image_name', 'col_sample', 'row_sample', 'use_X', 'use_Y']\n",
    "            )\n",
    "        df['geometry'] = [Point(x,y) for (x,y) in df[['lon', 'lat']].values]\n",
    "        gdf = gpd.GeoDataFrame(df, geometry='geometry', crs=\"EPSG:4326\")\n",
    "        gdf = gdf.to_crs(\"EPSG:32619\")\n",
    "        \n",
    "        gdf['X'] = [x.coords.xy[0][0] for x in gdf['geometry']]\n",
    "        gdf['Y'] = [x.coords.xy[1][0] for x in gdf['geometry']]\n",
    "\n",
    "        gdf_list += [gdf]\n",
    "    df_merged = pd.concat(gdf_list).reset_index(drop=True)\n",
    "    df_merged['channel'] = ['ch' + os.path.basename(x).split('ch')[1][0:2] for x in df_merged['image_name']]\n",
    "    df_merged = df_merged[['channel', 'X', 'Y', 'Z', 'col_sample', 'row_sample', 'geometry']]\n",
    "\n",
    "    gcp_merged = gpd.GeoDataFrame(df_merged, geometry='geometry', crs=\"EPSG:32619\")\n",
    "    gcp_merged.plot(kind='scatter', x='X', y='Y')\n",
    "    plt.show()\n",
    "    gcp_merged.to_file(gcp_merged_file, index=False)\n",
    "    print(f'Merged GCP saved to:\\n{gcp_merged_file}')\n",
    "\n",
    "else:\n",
    "    print('Merged GCP already exists in file, skipping.')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c79d1b",
   "metadata": {},
   "source": [
    "## Convert images to single band in case they're RGB\n",
    "\n",
    "A couple IR images (near the windows) were captured in RGB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d63e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(single_band_folder, exist_ok=True)\n",
    "\n",
    "# iterate over images\n",
    "print('Saving single-band images to:', single_band_folder)\n",
    "for image_file in tqdm(image_files):\n",
    "    # convert images to single band\n",
    "    out_fn = os.path.join(single_band_folder, os.path.basename(image_file))\n",
    "    if os.path.exists(out_fn):\n",
    "        continue\n",
    "    cmd = [\n",
    "        \"gdal_translate\",\n",
    "        \"-b\", \"1\",\n",
    "        image_file, out_fn\n",
    "    ]\n",
    "    subprocess.run(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105faf4f",
   "metadata": {},
   "source": [
    "## Calibrate cameras using GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c64d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_cameras(\n",
    "        image_files: str = None, \n",
    "        gcp_file: str = None, \n",
    "        plot_results: bool = True,\n",
    "        ):\n",
    "    \n",
    "    # --- Compile image and object points ---\n",
    "    # Load merged GCP file\n",
    "    gcp = gpd.read_file(gcp_file)\n",
    "    # Remove erroneous GCP\n",
    "    gcp = gcp.loc[gcp['Z'] < 0].reset_index(drop=True)\n",
    "    \n",
    "    # Compile image and object points\n",
    "    image_points_list = []\n",
    "    object_points_list = []\n",
    "    image_size = None\n",
    "    for image_file in image_files:\n",
    "        ch = 'ch' + os.path.basename(image_file).split('ch')[1][0:2]\n",
    "        gcp_image = gcp.loc[gcp['channel']==ch]\n",
    "\n",
    "        obj = gcp_image[['X','Y','Z']].values.astype(np.float64)\n",
    "        img = gcp_image[['col_sample','row_sample']].values.astype(np.float64)\n",
    "\n",
    "        # reshape for fisheye: (1, N, 3)\n",
    "        object_points_list.append(obj.reshape(1, -1, 3))\n",
    "        image_points_list.append(img.reshape(1, -1, 2))\n",
    "\n",
    "        if image_size is None:\n",
    "            im = cv2.imread(image_file, 0)\n",
    "            image_size = (im.shape[1], im.shape[0])\n",
    "\n",
    "    if len(object_points_list) == 0:\n",
    "        raise ValueError(\"No valid images for calibration\")\n",
    "\n",
    "    # --- Mean-center all object points for more stable calculations ---\n",
    "    object_points_list = [x for x in object_points_list]\n",
    "\n",
    "    # --- Initialize intrinsics & solving criteria --- \n",
    "    K_init = np.zeros((3, 3))\n",
    "    D_init = np.zeros((4, 1))\n",
    "    rvecs = [np.zeros((1, 1, 3), dtype=np.float64) for i in range(len(image_files))]\n",
    "    tvecs = [np.zeros((1, 1, 3), dtype=np.float64) for i in range(len(image_files))]\n",
    "    calibration_flags = cv2.fisheye.CALIB_FIX_SKEW + cv2.fisheye.CALIB_RECOMPUTE_EXTRINSIC # + cv2.fisheye.CALIB_CHECK_COND\n",
    "    termination_criteria = (cv2.TERM_CRITERIA_EPS+cv2.TERM_CRITERIA_MAX_ITER, 30, 1e-6)\n",
    "\n",
    "    # --- Calibrate camera intrinsics ---\n",
    "    # Note: rotation/translation vectors seem unstable at this stage. \n",
    "    # Use solvePnP for pose estimation instead.\n",
    "    print('Calibrating shared camera intrinsics...')\n",
    "    rms, K, D, rvecs, tvecs = cv2.fisheye.calibrate(\n",
    "        object_points_list,\n",
    "        image_points_list,\n",
    "        image_size,\n",
    "        K_init,\n",
    "        D_init,\n",
    "        rvecs,\n",
    "        tvecs,\n",
    "        calibration_flags,\n",
    "        termination_criteria\n",
    "    )\n",
    "\n",
    "    print(\"Shared calibration done\")\n",
    "\n",
    "    # --- Calculate camera matrix for full FOV ---\n",
    "    K_full = cv2.fisheye.estimateNewCameraMatrixForUndistortRectify(K, D, image_size, None, balance=1)\n",
    "\n",
    "    # --- Save camera extrinsics ---\n",
    "    results = [] # initialize list of camera specs\n",
    "    for i, image_file in enumerate(tqdm(image_files, desc='Extracting camera extrinsics')):\n",
    "        ch = 'ch' + os.path.basename(image_file).split('ch')[1][0:2]\n",
    "        r = {\n",
    "            'image_file': image_file,\n",
    "            'channel': ch,\n",
    "            'K': K.tolist(),\n",
    "            'dist': D.tolist(),\n",
    "            'K_full': K_full.tolist(),\n",
    "            'rvec': rvecs[i].tolist(),\n",
    "            'tvec': tvecs[i].tolist(),\n",
    "            }\n",
    "        results += [r]\n",
    "\n",
    "        # Plot results\n",
    "        if plot_results:\n",
    "            # Create undistorted image with full FOV\n",
    "            image = cv2.imread(image_file, cv2.IMREAD_GRAYSCALE)\n",
    "            map1, map2 = cv2.fisheye.initUndistortRectifyMap(K, D, np.eye(3), K_full, image_size, cv2.CV_16SC2)\n",
    "            image_undistorted = cv2.remap(image, map1, map2, interpolation=cv2.INTER_LINEAR)\n",
    "            # fill nodata values with NaNs\n",
    "            mask = np.ones(image.shape, dtype=np.uint8) * 255\n",
    "            mask_undistorted = cv2.remap(mask, map1, map2, interpolation=cv2.INTER_NEAREST)\n",
    "            valid_mask = mask_undistorted > 0\n",
    "            image_undistorted_nodata = image_undistorted.astype(np.float32)\n",
    "            image_undistorted_nodata[~valid_mask] = np.nan\n",
    "            \n",
    "            # Undistort GCP pixel coordinates\n",
    "            image_pts = gcp_image[['col_sample','row_sample']].values.astype(np.float32).reshape(1,-1,2)\n",
    "            undistorted_pts = cv2.fisheye.undistortPoints(image_pts, K, D, None, K_full).reshape(-1, 2)\n",
    "            gcp_image['col_sample_undistorted'] = undistorted_pts[:, 0]\n",
    "            gcp_image['row_sample_undistorted'] = undistorted_pts[:, 1]\n",
    "\n",
    "            # Plot\n",
    "            fig, ax = plt.subplots(1, 2, figsize=(10,5))\n",
    "            ax[0].imshow(image, cmap='Grays_r')\n",
    "            ax[0].plot(gcp_image['col_sample'], gcp_image['row_sample'], 'xr')\n",
    "            ax[1].imshow(image_undistorted, cmap='Grays_r')\n",
    "            ax[1].plot(gcp_image['col_sample_undistorted'], gcp_image['row_sample_undistorted'], 'xr')\n",
    "            fig.suptitle(os.path.basename(image_file))\n",
    "            for a in ax:\n",
    "                a.set_xticks([])\n",
    "                a.set_yticks([])\n",
    "            fig.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    # Compile results in dataframe \n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    return results_df\n",
    "\n",
    "\n",
    "def orthorectify(\n",
    "        image_file: str,\n",
    "        dem_file: str,\n",
    "        K: np.ndarray,\n",
    "        D: np.ndarray,\n",
    "        rvec: np.ndarray,\n",
    "        tvec: np.ndarray,\n",
    "        target_res: float = 0.002,\n",
    "        max_elevation_above_camera: float = 0.0,\n",
    "        fov_deg: float = 120.0,\n",
    "        buffer_size: float = 15.0,\n",
    "        out_folder: str = None\n",
    "    ) -> xr.DataArray:\n",
    "\n",
    "    # --- Load image ---\n",
    "    img_ds = rasterio.open(image_file)\n",
    "    img = img_ds.read().astype(np.float32)\n",
    "    if img.ndim == 2:\n",
    "        img = img[np.newaxis, :, :]\n",
    "    bands, h_img, w_img = img.shape\n",
    "\n",
    "    # --- Load DEM ---\n",
    "    dem = rxr.open_rasterio(dem_file).squeeze()\n",
    "    crs = dem.rio.crs\n",
    "    dem = xr.where(dem == -9999, np.nan, dem)\n",
    "\n",
    "    # --- Camera rotation and position ---\n",
    "    R = cv2.Rodrigues(rvec)[0]\n",
    "    cam_pos = (-R.T @ tvec).flatten()\n",
    "\n",
    "    # --- Clip DEM around camera ---\n",
    "    x_cam, y_cam = cam_pos[0], cam_pos[1]\n",
    "    dem_clipped = dem.sel(\n",
    "        x=slice(x_cam - buffer_size, x_cam + buffer_size),\n",
    "        y=slice(y_cam + buffer_size, y_cam - buffer_size)\n",
    "    )\n",
    "\n",
    "    if dem_clipped.size == 0:\n",
    "        raise ValueError(\"Clipped DEM area is empty â€” camera footprint does not intersect DEM.\")\n",
    "\n",
    "    # --- Create dense ortho grid at target resolution ---\n",
    "    x_min, x_max = float(dem_clipped.x.min()), float(dem_clipped.x.max())\n",
    "    y_min, y_max = float(dem_clipped.y.min()), float(dem_clipped.y.max())\n",
    "    Nx = int(np.ceil((x_max - x_min) / target_res)) + 1\n",
    "    Ny = int(np.ceil((y_max - y_min) / target_res)) + 1\n",
    "\n",
    "    X_grid = np.linspace(x_min, x_max, Nx, dtype=np.float32)\n",
    "    Y_grid = np.linspace(y_min, y_max, Ny, dtype=np.float32)\n",
    "    XX, YY = np.meshgrid(X_grid, Y_grid)\n",
    "\n",
    "    # Interpolate DEM onto ortho grid\n",
    "    dem_grid = dem_clipped.interp(x=X_grid, y=Y_grid, method=\"nearest\").values.astype(np.float32)\n",
    "    ZZ = dem_grid\n",
    "\n",
    "    # --- Flatten grid and transform to camera coordinates ---\n",
    "    world_pts = np.stack([XX.ravel(), YY.ravel(), ZZ.ravel()], axis=1)\n",
    "    cam_pts = (R @ world_pts.T + tvec).T\n",
    "\n",
    "    # --- Mask points behind camera or above max elevation ---\n",
    "    in_front = cam_pts[:,2] > 0\n",
    "    below_max = world_pts[:,2] <= cam_pos[2] + max_elevation_above_camera\n",
    "    half_fov_rad = np.radians(fov_deg / 2)\n",
    "    inside_fov = np.sqrt(cam_pts[:,0]**2 + cam_pts[:,1]**2) / cam_pts[:,2] <= np.tan(half_fov_rad)\n",
    "    valid = in_front & below_max & inside_fov\n",
    "\n",
    "    cam_pts = cam_pts[valid]\n",
    "    world_pts = world_pts[valid]\n",
    "\n",
    "    # --- Project points to image coordinates ---\n",
    "    img_pts, _ = cv2.fisheye.projectPoints(\n",
    "        cam_pts.reshape(-1,1,3),\n",
    "        rvec=np.zeros((3,1)),\n",
    "        tvec=np.zeros((3,1)),\n",
    "        K=K,\n",
    "        D=D\n",
    "    )\n",
    "    u = img_pts[:,0,0]\n",
    "    v = img_pts[:,0,1]\n",
    "\n",
    "    # --- Build dense map for remap ---\n",
    "    map_x = np.full(XX.shape, np.nan, dtype=np.float32)\n",
    "    map_y = np.full(XX.shape, np.nan, dtype=np.float32)\n",
    "\n",
    "    # Map valid world points back to grid indices\n",
    "    ix = np.round((world_pts[:,0] - x_min) / target_res).astype(int)\n",
    "    iy = np.round((world_pts[:,1] - y_min) / target_res).astype(int)\n",
    "    map_x[iy, ix] = u\n",
    "    map_y[iy, ix] = v\n",
    "\n",
    "    # --- Remap image ---\n",
    "    ortho = np.zeros((bands, Ny, Nx), dtype=np.float32)\n",
    "    for b in range(bands):\n",
    "        ortho[b] = cv2.remap(\n",
    "            img[b],\n",
    "            map_x,\n",
    "            map_y,\n",
    "            interpolation=cv2.INTER_LINEAR,\n",
    "            borderMode=cv2.BORDER_CONSTANT,\n",
    "            borderValue=np.nan\n",
    "        )\n",
    "        ortho[b][np.isnan(map_x)] = np.nan\n",
    "        ortho[b][np.isnan(map_y)] = np.nan\n",
    "\n",
    "    # --- Wrap as xarray ---\n",
    "    ortho_xr = xr.DataArray(\n",
    "        ortho,\n",
    "        dims=(\"band\", \"y\", \"x\"),\n",
    "        coords={\"x\": X_grid, \"y\": Y_grid}\n",
    "    )\n",
    "    ortho_xr = ortho_xr.dropna(how='all', dim='x').dropna(how='all', dim='y')\n",
    "    ortho_xr = ortho_xr.rio.write_crs(crs, inplace=False)\n",
    "\n",
    "    # --- Optionally save ---\n",
    "    if out_folder is not None:\n",
    "        os.makedirs(out_folder, exist_ok=True)\n",
    "        fname = os.path.basename(image_file).replace('.tiff', '_orthoimage.tiff')\n",
    "        ortho_xr.rio.to_raster(os.path.join(out_folder, fname))\n",
    "        print(f'Orthoimage saved: {fname}')\n",
    "\n",
    "    return ortho_xr\n",
    "\n",
    "\n",
    "os.makedirs(calib_folder, exist_ok=True)\n",
    "image_files = sorted(glob(os.path.join(single_band_folder, '*.tiff')))\n",
    "\n",
    "### CALIBRATE AND ORTHORECTIFY IN TWO GROUPS ###\n",
    "# First 8 images are a different size than second \n",
    "for files, results_file in [\n",
    "    [image_files[0:8], os.path.join(calib_folder, f\"ch01-ch08_calibrated_cameras.csv\")],\n",
    "    [image_files[8:], os.path.join(calib_folder, f\"ch09-ch16_calibrated_cameras.csv\")]\n",
    "]:\n",
    "\n",
    "    # Calibrate cameras\n",
    "    results_df = calibrate_cameras(\n",
    "        image_files = files, \n",
    "        gcp_file = gcp_merged_file, \n",
    "        plot_results = False\n",
    "        )\n",
    "    \n",
    "    # Save calibrated camera specs\n",
    "    results_df.to_csv(results_file, index=False, header=True)\n",
    "    print('Calibrated cameras saved to file')\n",
    "\n",
    "    # # orthorectify\n",
    "    # for i,row in tqdm(results_df.iterrows(), total=len(results_df), desc='Orthorectifying'):\n",
    "    #     ortho_xr = orthorectify(\n",
    "    #         image_file = row['image_file'],\n",
    "    #         dem_file = refdem_file,\n",
    "    #         K = row['K'],\n",
    "    #         D = row['dist'],\n",
    "    #         rvec = row['rvec'],\n",
    "    #         tvec = row['tvec'],\n",
    "    #         target_res = 0.002,\n",
    "    #         out_folder = calib_folder,\n",
    "    #     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e5fb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(results_file)\n",
    "df['K'] = np.array(df['K'].apply(literal_eval))\n",
    "df['K'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c25b18",
   "metadata": {},
   "source": [
    "## Combine calibration parameters into one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f117a516",
   "metadata": {},
   "outputs": [],
   "source": [
    "calib_files = sorted(glob(os.path.join(calib_folder, '*.csv')))\n",
    "calib_list = []\n",
    "for calib_file in calib_files:\n",
    "    calib_list += [pd.read_csv(calib_file)]\n",
    "calib = pd.concat(calib_list).reset_index(drop=True)\n",
    "calib\n",
    "# Evaluate values\n",
    "for k in ['K', 'dist', 'K_full', 'rvec', 'tvec']:\n",
    "    calib[k] = calib[k].apply(literal_eval)\n",
    "\n",
    "out_file = os.path.join(calib_folder, \"original_calibrated_cameras.csv\")\n",
    "calib.to_csv(out_file, index=False)\n",
    "print(f'Merged calibration parameters saved to:\\n{out_file}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soo_locks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
