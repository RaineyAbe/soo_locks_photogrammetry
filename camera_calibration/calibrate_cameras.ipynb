{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2c9d518",
   "metadata": {},
   "source": [
    "# Calibrate cameras, create initial orthoimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aac52a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from shapely.geometry import Point, Polygon\n",
    "import geopandas as gpd\n",
    "import shutil\n",
    "import ast\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "import rasterio as rio\n",
    "# Ignore warnings (rasterio throws a warning whenever an image is not georeferenced. Annoying in this case.)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Locate image files\n",
    "data_folder = '/Users/rdcrlrka/Research/Soo_locks'\n",
    "image_folder = os.path.join(data_folder, '20251001_imagery', 'frames_IR')\n",
    "image_list = sorted(glob(os.path.join(image_folder, '*.tiff')))\n",
    "print(f\"{len(image_list)} images located\")\n",
    "\n",
    "# Grab other input files\n",
    "masks_folder = os.path.join(os.getcwd(), '..', '..', 'inputs', 'image_masks')\n",
    "gcp_folder = os.path.join(os.getcwd(), '..', '..', 'inputs', 'gcp')\n",
    "cams_file = os.path.join(os.getcwd(), '..', '..', 'inputs', 'cams_lonlat-fake.txt')\n",
    "refdem_file = os.path.join(os.getcwd(), '..', '..', 'inputs', 'lidar_DSM_filled_cropped.tif')\n",
    "\n",
    "# Define output folders\n",
    "out_folder = image_folder + '_proc_out'\n",
    "os.makedirs(out_folder, exist_ok=True)\n",
    "new_image_folder = os.path.join(out_folder, 'single_band_images')\n",
    "masked_image_folder = os.path.join(out_folder, 'masked_images')\n",
    "undistorted_folder = os.path.join(out_folder, 'undistorted_images_cams')\n",
    "init_ortho_folder = os.path.join(out_folder, 'init_ortho')\n",
    "init_stereo_folder = os.path.join(out_folder, 'init_stereo')\n",
    "ba_folder = os.path.join(out_folder, 'bundle_adjust')\n",
    "final_ortho_folder = os.path.join(out_folder, 'final_ortho')\n",
    "final_stereo_folder = os.path.join(out_folder, 'final_stereo')\n",
    "full_cam_folder = os.path.join(out_folder, 'full_optimized_cams')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c8f447",
   "metadata": {},
   "source": [
    "## Merge GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef6f860",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcp_merged_file = os.path.join(gcp_folder, 'GCP_merged.csv')\n",
    "if not os.path.exists(gcp_merged_file):\n",
    "\n",
    "    gcp_list = sorted(glob(os.path.join(gcp_folder, '*.gcp')))\n",
    "    df_list = []\n",
    "    for gcp_file in gcp_list:\n",
    "        df = pd.read_csv(\n",
    "            gcp_file,\n",
    "            sep=',',\n",
    "            header=None,\n",
    "            skiprows=[0],\n",
    "            names=[\n",
    "                'point_index', 'lat', 'lon', 'Z', 'lat_sigma', 'lon_sigma', 'Z_sigma', \n",
    "                'image_path', 'col_sample', 'row_sample', 'use_lat', 'use_lon']\n",
    "        )\n",
    "        df_list += [df]\n",
    "\n",
    "    dfs = pd.concat(df_list).reset_index(drop=True)\n",
    "\n",
    "    # reproject to UTM zone 19N\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        dfs,\n",
    "        geometry=[Point(x,y) for x,y in dfs[['lon', 'lat']].values],\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "    gdf = gdf.to_crs(\"EPSG:32619\")\n",
    "    gdf['X'] = [x.coords.xy[0][0] for x in gdf['geometry']]\n",
    "    gdf['Y'] = [x.coords.xy[1][0] for x in gdf['geometry']]\n",
    "\n",
    "    # use just the image file name\n",
    "    gdf['image_name'] = [os.path.basename(x) for x in gdf['image_path']]\n",
    "\n",
    "    # select relevant columns\n",
    "    gdf = gdf[['image_name', 'X', 'Y', 'Z', 'col_sample', 'row_sample']]\n",
    "\n",
    "    # save to file\n",
    "    gdf.to_csv(gcp_merged_file, sep=',', index=False)\n",
    "    print('Saved merged GCP:', gcp_merged_file)\n",
    "else:\n",
    "    print('Merged GCP already exists in file, skipping merge.')\n",
    "\n",
    "\n",
    "# Reproject from UTM zone 19 N to ECEF for use in ASP\n",
    "gcp_merged_ecef_file = os.path.join(gcp_folder, 'GCP_merged_ECEF.csv')\n",
    "if not os.path.exists(gcp_merged_ecef_file):\n",
    "    # Load the merged file\n",
    "    gcp_merged = pd.read_csv(gcp_merged_file, sep=',')\n",
    "\n",
    "    # Reproject from UTM to ECEF\n",
    "    geom = [Point(x,y,z) for x,y,z in gcp_merged[['X', 'Y', 'Z']].values]\n",
    "    gdf = gpd.GeoDataFrame(geometry=geom, crs=\"EPSG:32619\")\n",
    "    gdf = gdf.to_crs(\"EPSG:4978\")\n",
    "    gcp_merged['X'] = [x.x for x in gdf['geometry']]\n",
    "    gcp_merged['Y'] = [x.y for x in gdf['geometry']]\n",
    "    gcp_merged['Z'] = [x.z for x in gdf['geometry']]\n",
    "\n",
    "    # Save to file\n",
    "    gcp_merged.to_csv(gcp_merged_ecef_file, sep=',', index=False)\n",
    "    print('Saved merged GCP in ECEF coordinates:', gcp_merged_ecef_file)\n",
    "else:\n",
    "    print('Merged GCP in ECEF coordinates already exists in file, skipping reprojection.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c79d1b",
   "metadata": {},
   "source": [
    "## Convert images to single band in case they're RGB\n",
    "\n",
    "A couple IR images (near the windows) were captured in RGB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d63e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(new_image_folder, exist_ok=True)\n",
    "\n",
    "# iterate over images\n",
    "print('Saving single-band images to:', new_image_folder)\n",
    "for image_file in tqdm(image_list):\n",
    "    # convert images to single band\n",
    "    out_fn = os.path.join(new_image_folder, os.path.basename(image_file))\n",
    "    if os.path.exists(out_fn):\n",
    "        continue\n",
    "    cmd = [\n",
    "        \"gdal_translate\",\n",
    "        \"-b\", \"1\",\n",
    "        image_file, out_fn\n",
    "    ]\n",
    "    subprocess.run(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105faf4f",
   "metadata": {},
   "source": [
    "## Calibrate cameras using GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c64d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tsai(tsai_dict, filename):\n",
    "    \"\"\"\n",
    "    Save a TSAI (.tsai) pinhole camera file from a dictionary.\n",
    "    \"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(\"VERSION_4\\n\")\n",
    "        f.write(\"PINHOLE\\n\")\n",
    "        f.write(f\"fu = {tsai_dict['fu']}\\n\")\n",
    "        f.write(f\"fv = {tsai_dict['fv']}\\n\")\n",
    "        f.write(f\"cu = {tsai_dict['cu']}\\n\")\n",
    "        f.write(f\"cv = {tsai_dict['cv']}\\n\")\n",
    "        f.write(f\"u_direction = {' '.join(map(str, tsai_dict['u_direction']))}\\n\")\n",
    "        f.write(f\"v_direction = {' '.join(map(str, tsai_dict['v_direction']))}\\n\")\n",
    "        f.write(f\"w_direction = {' '.join(map(str, tsai_dict['w_direction']))}\\n\")\n",
    "        f.write(f\"C = {' '.join(map(str, tsai_dict['C']))}\\n\")\n",
    "        f.write(\"R = \" + \" \".join(map(str, tsai_dict['R'].flatten())) + \"\\n\")\n",
    "        f.write(f\"pitch = {tsai_dict['pitch']}\\n\")\n",
    "        # Add small distortion for bundle adjust\n",
    "        f.write(\"TSAI\\n\")\n",
    "        f.write(\"k1 = -1e-6\\nk2 = 1e-6\\np1 = 0\\np2 = 0\\nk3 = 1e-6\\n\")\n",
    "\n",
    "\n",
    "def calibrate_cameras(image_files, gcp_file, output_folder=None, file_prefix=None, plot_results=True):\n",
    "    object_points_list = []\n",
    "    image_points_list = []\n",
    "    image_size = None\n",
    "\n",
    "    # --- Load merged GCP ---\n",
    "    gcp = pd.read_csv(gcp_file, sep=',')    \n",
    "\n",
    "    # --- Compile GCP (object) and image (pixel) points --- \n",
    "    for image_file in image_files:\n",
    "        # Subset GCP to image\n",
    "        gcp_image = gcp.loc[gcp['image_name']==os.path.basename(image_file)]\n",
    "\n",
    "        # Object and image points\n",
    "        obj_pts = gcp_image[['X','Y','Z']].values.astype(np.float32)\n",
    "        image_pts = gcp_image[['col_sample','row_sample']].values.astype(np.float32)\n",
    "        obj_pts = obj_pts.reshape(-1,1,3)\n",
    "        image_pts = image_pts.reshape(-1,1,2)\n",
    "\n",
    "        object_points_list.append(obj_pts)\n",
    "        image_points_list.append(image_pts)\n",
    "\n",
    "        # get image size\n",
    "        if image_size is None:\n",
    "            image = cv2.imread(image_file, cv2.IMREAD_GRAYSCALE)\n",
    "            image_size = (image.shape[1], image.shape[0])\n",
    "\n",
    "    if len(object_points_list) == 0:\n",
    "        raise ValueError(\"No valid images for calibration\")\n",
    "    \n",
    "    # --- Subtract the mean of all object points for better calculation ---\n",
    "    all_obj_pts = np.vstack([op.reshape(-1,3) for op in object_points_list])\n",
    "    object_points_mean = all_obj_pts.mean(axis=0)\n",
    "    object_points_list = [x - object_points_mean for x in object_points_list]\n",
    "\n",
    "    # --- Initialize intrinsics --- \n",
    "    fx = fy = 2000\n",
    "    cx = image_size[0] / 2\n",
    "    cy = image_size[1] / 2\n",
    "    K_init = np.array([\n",
    "        [fx,0,cx],\n",
    "        [0,fy,cy],\n",
    "        [0,0,1]\n",
    "        ], dtype=np.float64)\n",
    "    dist_init = np.zeros(8)\n",
    "    flags = (\n",
    "        cv2.CALIB_USE_INTRINSIC_GUESS\n",
    "        | cv2.CALIB_FIX_PRINCIPAL_POINT \n",
    "        | cv2.CALIB_ZERO_TANGENT_DIST\n",
    "        )\n",
    "\n",
    "    # --- Calibrate cameras ---\n",
    "    rms, K, dist, rvecs, tvecs = cv2.calibrateCamera(\n",
    "        object_points_list,\n",
    "        image_points_list,\n",
    "        image_size,\n",
    "        K_init,\n",
    "        dist_init,\n",
    "        flags=flags\n",
    "    )\n",
    "\n",
    "    print(\"Shared calibration done\")\n",
    "    print(\"RMS reprojection error:\", rms)\n",
    "    print(\"Camera matrix K:\\n\", K)\n",
    "    print(\"Distortion coefficients:\", dist.ravel())\n",
    "\n",
    "    # --- Calculate adjusted camera matrix ---\n",
    "    w,h = image_size\n",
    "    K_full, _ = cv2.getOptimalNewCameraMatrix(K, dist, (w,h), 1, (w, h))\n",
    "\n",
    "    # --- Save camera calibration parameters ---\n",
    "    calib_file = os.path.join(output_folder, file_prefix + 'camera_calibration_params.csv')\n",
    "    calib_df = pd.DataFrame({\n",
    "        'image_name': image_files,\n",
    "        'K': [[float(x) for x in K.ravel()]]*len(image_files),\n",
    "        'K_full': [[float(x) for x in K_full.ravel()]]*len(image_files),\n",
    "        'distortion_coefficients': [[float(x) for x in dist.ravel()]]*len(image_files),\n",
    "        'RMS': [rms]*len(image_files)\n",
    "    })\n",
    "    calib_df.to_csv(calib_file, index=False)\n",
    "    print(\"Saved calibration params:\", calib_file)\n",
    "\n",
    "    # --- Save undistorted images, GCP, and camera extrinsics ---\n",
    "    print('Estimating individual image extrinsics')\n",
    "    for i, image_file in enumerate(tqdm(image_files)):\n",
    "        # Undistort image\n",
    "        image_undistorted_file = os.path.join(\n",
    "            output_folder, \n",
    "            os.path.splitext(os.path.basename(image_file))[0] + '_undistorted.tiff'\n",
    "            )\n",
    "        image = cv2.imread(image_file, cv2.IMREAD_UNCHANGED)\n",
    "        # Save cropped undistorted image\n",
    "        image_undistorted = cv2.undistort(image, K, dist, None, K)\n",
    "        cv2.imwrite(image_undistorted_file, image_undistorted)\n",
    "        # Save full undistorted image\n",
    "        # must do some remapping to maintain no data values\n",
    "        map1, map2 = cv2.initUndistortRectifyMap(K, dist, None, K_full, (w, h), cv2.CV_32FC1)\n",
    "        # apply undistortion to the image\n",
    "        image_undistorted = cv2.remap(image, map1, map2, interpolation=cv2.INTER_LINEAR)\n",
    "        # create a white mask and remap it the same way to find valid areas\n",
    "        mask = np.ones((h, w), dtype=np.uint8) * 255\n",
    "        mask_undistorted = cv2.remap(mask, map1, map2, interpolation=cv2.INTER_NEAREST)\n",
    "        # convert mask to boolean\n",
    "        valid_mask = mask_undistorted > 0\n",
    "        # Now set invalid pixels to NaN\n",
    "        image_undistorted_nodata = image_undistorted.astype(np.float32)\n",
    "        image_undistorted_nodata[~valid_mask] = np.nan\n",
    "        cv2.imwrite(image_undistorted_file.replace('.tiff', '_full.tiff'), image_undistorted_nodata)\n",
    "\n",
    "        # Undistort GCP pixel coordinates\n",
    "        gcp_image = gcp.loc[gcp['image_name']==os.path.basename(image_file)]\n",
    "        image_pts = gcp_image[['col_sample','row_sample']].values.astype(np.float32)\n",
    "        undistorted_pts = cv2.undistortPoints(image_pts, K, dist, P=K).reshape(-1, 2)\n",
    "        gcp_image['col_sample_undistorted'] = undistorted_pts[:, 0]\n",
    "        gcp_image['row_sample_undistorted'] = undistorted_pts[:, 1]\n",
    "        # reproject to lat-lon\n",
    "        gcp_reformat = gcp_image.copy()\n",
    "        gcp_reformat['geometry'] = [Point(x,y) for x,y in gcp_image[['X','Y']].values]\n",
    "        gcp_gdf = gpd.GeoDataFrame(geometry=gcp_reformat['geometry'], crs='EPSG:4978')\n",
    "        gcp_gdf = gcp_gdf.to_crs(\"EPSG:4326\")\n",
    "        gcp_reformat['lon'] = [x.coords.xy[0][0] for x in gcp_gdf['geometry']]\n",
    "        gcp_reformat['lat'] = [x.coords.xy[1][0] for x in gcp_gdf['geometry']]\n",
    "        # update image names\n",
    "        gcp_reformat['image_name'] = [x.replace('.tiff','_undistorted.tiff') for x in gcp_reformat['image_name']]\n",
    "        # add other relevant columns\n",
    "        gcp_reformat[['lat_std', 'lon_std', 'Z_std']] = 0.2, 0.2, 0.2\n",
    "        gcp_reformat[['use_lat', 'use_lon']] = 1, 1\n",
    "        # reorder and select appropriate columns\n",
    "        gcp_reformat = gcp_reformat[[\n",
    "            'lat', 'lon', 'Z', 'lat_std', 'lon_std', 'Z_std', \n",
    "            'image_name', 'col_sample_undistorted', 'row_sample_undistorted',\n",
    "            'use_lat', 'use_lon'\n",
    "            ]]\n",
    "        gcp_reformat.reset_index(drop=True, inplace=True)\n",
    "        # save to file\n",
    "        gcp_undistorted_file = os.path.join(\n",
    "            output_folder, \n",
    "            os.path.splitext(os.path.basename(image_file))[0] + '_undistorted.gcp'\n",
    "            )\n",
    "        gcp_reformat.to_csv(\n",
    "            gcp_undistorted_file, \n",
    "            sep=' ',\n",
    "            index=True,\n",
    "            header=False\n",
    "            )\n",
    "\n",
    "        # Save camera extrinsics as TSAI camera model\n",
    "        # convert rotation matrix from world -> camera to camera -> world\n",
    "        R_wc = cv2.Rodrigues(rvecs[i])[0]\n",
    "        R_cw = R_wc.T\n",
    "        # calculate camera center\n",
    "        C = -R_cw @ tvecs[i].reshape(3) + object_points_mean.reshape(3)\n",
    "        # compile in dictionary\n",
    "        tsai_dict = {\n",
    "            'fu': K[0,0],\n",
    "            'fv': K[1,1],\n",
    "            'cu': K[0,2],\n",
    "            'cv': K[1,2],\n",
    "            'u_direction': [1,0,0],\n",
    "            'v_direction': [0,1,0],\n",
    "            'w_direction': [0,0,1],\n",
    "            'C': C,\n",
    "            'R': R_cw,\n",
    "            'pitch': 1,\n",
    "        }\n",
    "        # save to file\n",
    "        tsai_file = os.path.join(\n",
    "            output_folder, \n",
    "            os.path.splitext(os.path.basename(image_file))[0] + '_undistorted.tsai'\n",
    "            )\n",
    "        save_tsai(tsai_dict, tsai_file)\n",
    "\n",
    "        if plot_results:\n",
    "            fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
    "            ax[0].imshow(image, cmap='Grays_r', vmin=0, vmax=255)\n",
    "            ax[0].plot(\n",
    "                gcp_image['col_sample'], gcp_image['row_sample'], 'xr',\n",
    "                markersize=5, linewidth=1.5\n",
    "                )\n",
    "            ax[0].set_title('Original')\n",
    "            ax[1].imshow(image_undistorted_nodata, cmap='Grays_r', vmin=0, vmax=255)\n",
    "            ax[1].plot(\n",
    "                gcp_image['col_sample_undistorted'], gcp_image['row_sample_undistorted'], 'xr',\n",
    "                markersize=5, linewidth=1.5\n",
    "                )\n",
    "            ax[1].set_title('Undistorted')\n",
    "            for axis in ax:\n",
    "                axis.set_xticks([]), axis.set_yticks([])\n",
    "            plt.tight_layout()\n",
    "            # save to file\n",
    "            fig_file = os.path.join(output_folder, os.path.splitext(os.path.basename(image_file))[0] + '_undistorted.png')\n",
    "            fig.savefig(fig_file, dpi=300, bbox_inches='tight')\n",
    "            # print('Saved results figure:', fig_file)\n",
    "            plt.close()\n",
    "\n",
    "    return\n",
    "\n",
    "os.makedirs(undistorted_folder, exist_ok=True)\n",
    "\n",
    "# GROUP 1\n",
    "print('\\nGROUP 1: ch01-08\\n----------')\n",
    "image_list = sorted(glob(os.path.join(new_image_folder, '*.tiff')))[0:8]\n",
    "# calculate shared calibration\n",
    "print('Optimizing shared camera intrinsics using GCP...')\n",
    "calibrate_cameras(image_list, gcp_merged_ecef_file, undistorted_folder, file_prefix='group1-')\n",
    "\n",
    "# GROUP 2\n",
    "print('\\nGROUP 2: ch09-16\\n----------')\n",
    "image_list = sorted(glob(os.path.join(new_image_folder, '*.tiff')))[8:]\n",
    "# calculate shared calibration\n",
    "print('Optimizing shared camera intrinsics using GCP...')\n",
    "calibrate_cameras(image_list, gcp_merged_ecef_file, undistorted_folder, file_prefix='group2-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1088b165",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LEADS TO WORSE RESULTS, SKIPPING\n",
    "\n",
    "# Mask high objects in the images\n",
    "# Bridges, fans, and other beams, for example were not included in the lidar DSM. \n",
    "# Apply the manually-created masks to the images before bundle adjustment to improve camera optimization. \n",
    "\n",
    "# def apply_image_mask(image_file, mask_file, K, K_full, dist, output_folder):\n",
    "#     os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "#     # load the image\n",
    "#     image = rxr.open_rasterio(image_file).squeeze()\n",
    "#     image = image.rio.write_crs(\"EPSG:4326\")\n",
    "\n",
    "#     # load the mask\n",
    "#     mask = gpd.read_file(mask_file)\n",
    "#     mask = mask.set_crs(\"EPSG:4326\")\n",
    "#     mask = mask.to_crs(\"EPSG:32619\")\n",
    "\n",
    "#     # shift the y axis of the polygon to align with the image\n",
    "#     mask_polys = []\n",
    "#     for _, row in mask.iterrows():\n",
    "#         X = row['geometry'].exterior.coords.xy[0]\n",
    "#         Y = row['geometry'].exterior.coords.xy[1]\n",
    "#         Y_swap = [-1*x for x in Y]\n",
    "#         mask_polys += [Polygon([(x,y) for x,y in zip(X,Y_swap)])]\n",
    "\n",
    "#     # rasterize the mask polygon\n",
    "#     mask_raster = rio.features.rasterize(\n",
    "#         mask_polys,\n",
    "#         out_shape=image.shape,\n",
    "#         transform=image.rio.transform(),\n",
    "#         fill=0,\n",
    "#         all_touched=True,\n",
    "#         dtype=np.int8\n",
    "#     )\n",
    "\n",
    "#     # apply mask to the image\n",
    "#     image = image.astype(np.float32)\n",
    "#     image_masked_xr = xr.where(mask_raster==1, np.nan, image)\n",
    "\n",
    "#     # undistort the image (cropped)\n",
    "#     image_masked_undistorted_file = os.path.join(\n",
    "#         output_folder, \n",
    "#         os.path.basename(image_file).replace('.tiff', '_undistorted.tiff')\n",
    "#         )\n",
    "#     image_masked_undistorted = cv2.undistort(image_masked_xr.data, K, dist, None, K)\n",
    "#     cv2.imwrite(image_masked_undistorted_file, image_masked_undistorted)\n",
    "#     print('Saved masked, undistorted image:', image_masked_undistorted_file)\n",
    "\n",
    "#     # undistort the image (full FOV)\n",
    "#     image_masked_undistorted_full_file = os.path.join(\n",
    "#         output_folder, \n",
    "#         os.path.basename(image_file).replace('.tiff', '_undistorted_full.tiff')\n",
    "#         )\n",
    "#     h,w = image_masked_xr.data.shape\n",
    "#     # must do some remapping to maintain no data values\n",
    "#     map1, map2 = cv2.initUndistortRectifyMap(K, dist, None, K_full, (w, h), cv2.CV_32FC1)\n",
    "#     # apply undistortion to the image\n",
    "#     image_undistorted = cv2.remap(image_masked_xr.data, map1, map2, interpolation=cv2.INTER_LINEAR)\n",
    "#     # create a white mask and remap it the same way to find valid areas\n",
    "#     mask = np.ones((h, w), dtype=np.uint8) * 255\n",
    "#     mask_undistorted = cv2.remap(mask, map1, map2, interpolation=cv2.INTER_NEAREST)\n",
    "#     # convert mask to boolean\n",
    "#     valid_mask = mask_undistorted > 0\n",
    "#     # Now set invalid pixels to NaN\n",
    "#     image_undistorted_nodata = image_undistorted.astype(np.float32)\n",
    "#     image_undistorted_nodata[~valid_mask] = np.nan\n",
    "#     cv2.imwrite(image_masked_undistorted_full_file, image_undistorted_nodata)\n",
    "#     print('Saved masked, undistorted, full FOV image:', image_masked_undistorted_full_file)\n",
    "\n",
    "\n",
    "# image_files = sorted(glob(os.path.join(new_image_folder, '*.tiff')))\n",
    "# for image_file in image_files:\n",
    "#     # determine the camera to read match file\n",
    "#     ch = os.path.basename(image_file).split('ch')[1][0:2]\n",
    "#     mask_file = os.path.join(masks_folder, f'ch{ch}_mask.gpkg')\n",
    "#     # if no masks needed, copy undistorted images to new folder\n",
    "#     if not os.path.exists(mask_file):\n",
    "#         image_undistorted_files = sorted(glob(os.path.join(undistorted_folder, f\"*ch{ch}*.tiff\")))\n",
    "#         for file in image_undistorted_files:\n",
    "#             image_out_file = os.path.join(masked_image_folder, os.path.basename(file))\n",
    "#             _ = shutil.copy2(image_file, image_out_file)\n",
    "#         print(f'No masking needed for image: {os.path.basename(image_file)}. Copied undistorted images to output folder.')\n",
    "#     # otherwise, apply mask to the image\n",
    "#     else:\n",
    "#         # determine the group to read calibration params\n",
    "#         group = 1 if float(ch) < 9 else 2\n",
    "#         calib_file = os.path.join(undistorted_folder, f\"group{group}-camera_calibration_params.csv\")\n",
    "#         calib = pd.read_csv(calib_file)\n",
    "#         calib['K'] = calib['K'].apply(ast.literal_eval)\n",
    "#         calib['K_full'] = calib['K_full'].apply(ast.literal_eval)\n",
    "#         calib['distortion_coefficients'] = calib['distortion_coefficients'].apply(ast.literal_eval)\n",
    "#         K = np.array(calib.iloc[0]['K']).reshape(3,3)\n",
    "#         K_full = np.array(calib.iloc[0]['K_full']).reshape(3,3)\n",
    "#         dist = np.array(calib.iloc[0]['distortion_coefficients']).reshape(-1,1)\n",
    "#         # apply the mask\n",
    "#         apply_image_mask(image_file, mask_file, K, K_full, dist, masked_image_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec464908",
   "metadata": {},
   "source": [
    "## Initial orthorectification (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf51adfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(init_ortho_folder, exist_ok=True)\n",
    "\n",
    "image_list = sorted(glob(os.path.join(undistorted_folder, '*_undistorted.tiff')))\n",
    "cam_list = sorted(glob(os.path.join(undistorted_folder, '*_undistorted.tsai')))\n",
    "\n",
    "# Mapproject\n",
    "for image_file, cam_file in zip(image_list, cam_list):\n",
    "    image_out_file = os.path.join(init_ortho_folder, os.path.basename(image_file).replace('.tiff', '_map.tiff'))\n",
    "    cmd = [\n",
    "        'mapproject',\n",
    "        '--threads', '12',\n",
    "        '--nodata-value', '9999',\n",
    "        '--tr', '0.003',\n",
    "        refdem_file, image_file, cam_file, image_out_file\n",
    "    ]\n",
    "    subprocess.run(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3910bacc",
   "metadata": {},
   "source": [
    "## Run stereo preprocessing to create dense match files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df298f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_stereo_folder = os.path.join(out_folder, 'init_stereo')\n",
    "os.makedirs(init_stereo_folder, exist_ok=True)\n",
    "\n",
    "image_list = sorted(glob(os.path.join(undistorted_folder, '*_undistorted.tiff')))\n",
    "cam_list = sorted(glob(os.path.join(undistorted_folder, '*_undistorted.tsai')))\n",
    "\n",
    "# Set up image pairs\n",
    "image1_list, image2_list = image_list[0:-1], image_list[1:]\n",
    "cam1_list, cam2_list = cam_list[0:-1], cam_list[1:]\n",
    "\n",
    "# skip the 8/9 cams pair (different intrinsics solving during bundle adjust)\n",
    "iskip = [i for i in range(0,len(image1_list)) if 'ch08' in image1_list[i]][0]\n",
    "image1_list = image1_list[0:iskip] + image1_list[iskip+1:]\n",
    "image2_list = image2_list[0:iskip] + image2_list[iskip+1:]\n",
    "cam1_list = cam1_list[0:iskip] + cam1_list[iskip+1:]\n",
    "cam2_list = cam2_list[0:iskip] + cam2_list[iskip+1:]\n",
    "\n",
    "# Iterate over pairs\n",
    "for i in tqdm(range(len(image1_list))):\n",
    "    image1, image2 = image1_list[i], image2_list[i]\n",
    "    cam1, cam2 = cam1_list[i], cam2_list[i]\n",
    "\n",
    "    pair_prefix = os.path.join(\n",
    "        init_stereo_folder,\n",
    "        os.path.splitext(os.path.basename(image1))[0] + '__' + os.path.splitext(os.path.basename(image2))[0],\n",
    "        'run'\n",
    "        )\n",
    "    \n",
    "    cmd = [\n",
    "        'parallel_stereo',\n",
    "        '--threads-singleprocess', '12',\n",
    "        '--threads-multiprocess', '12',\n",
    "        '--stop-point', '1',\n",
    "        '--nodata-value', 'NaN',\n",
    "        image1, image2,\n",
    "        cam1, cam2,\n",
    "        pair_prefix,\n",
    "    ]\n",
    "    subprocess.run(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d9a851",
   "metadata": {},
   "source": [
    "## Bundle adjust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98bd743",
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_folder = os.path.join(out_folder, 'bundle_adjust')\n",
    "os.makedirs(ba_folder, exist_ok=True)\n",
    "\n",
    "image_list = sorted(glob(os.path.join(undistorted_folder, '*_undistorted.tiff')))\n",
    "cam_list = sorted(glob(os.path.join(undistorted_folder, '*_undistorted.tsai')))\n",
    "\n",
    "# Copy dense matches to bundle adjust folder\n",
    "match_list = sorted(glob(os.path.join(init_stereo_folder, '*', '*.match')))\n",
    "for match_file in match_list:\n",
    "    # get image pair\n",
    "    pair = os.path.dirname(match_file).split('/')[-1]\n",
    "    # check which group it's in\n",
    "    first_channel = pair.split('ch')[1][0:2]\n",
    "    group = 1 if float(first_channel) < 9 else 2\n",
    "    # define output file\n",
    "    match_out_file = os.path.join(\n",
    "        ba_folder, \n",
    "        f'run_group{group}-{pair}' + '.match'\n",
    "        )\n",
    "    # copy\n",
    "    _ = shutil.copy2(match_file, match_out_file)\n",
    "\n",
    "# GROUP 1\n",
    "print('\\nGROUP 1: ch01-08\\n----------')\n",
    "image_list_group1 = image_list[0:8]\n",
    "cam_list_group1 = cam_list[0:8]\n",
    "# Run bundle adjust\n",
    "cmd = [\n",
    "    'parallel_bundle_adjust',\n",
    "    '--threads', '12',\n",
    "    '--num-iterations', '2000',\n",
    "    '--num-passes', '2',\n",
    "    '--inline-adjustments',\n",
    "    '--force-reuse-match-files',\n",
    "    '--heights-from-dem', refdem_file,\n",
    "    '--heights-from-dem-uncertainty', '0.01',\n",
    "    '--solve-intrinsics',\n",
    "    '--intrinsics-to-share', 'optical_center,other_intrinsics',\n",
    "    '--intrinsics-to-float', 'all',\n",
    "    '-o', os.path.join(ba_folder, 'run_group1')\n",
    "] + image_list_group1 + cam_list_group1\n",
    "subprocess.run(cmd)\n",
    "\n",
    "# GROUP 2\n",
    "print('\\nGROUP 2: ch09-16\\n----------')\n",
    "image_list_group2 = image_list[8:]\n",
    "cam_list_group2 = cam_list[8:]\n",
    "# Run bundle adjust\n",
    "cmd = [\n",
    "    'parallel_bundle_adjust',\n",
    "    '--threads', '12',\n",
    "    '--num-iterations', '2000',\n",
    "    '--num-passes', '2',\n",
    "    '--inline-adjustments',\n",
    "    '--force-reuse-match-files',\n",
    "    '--heights-from-dem', refdem_file,\n",
    "    '--heights-from-dem-uncertainty', '0.01',\n",
    "    '--solve-intrinsics',\n",
    "    '--intrinsics-to-share', 'optical_center,other_intrinsics',\n",
    "    '--intrinsics-to-float', 'all',\n",
    "    '-o', os.path.join(ba_folder, 'run_group2')\n",
    "] + image_list_group2 + cam_list_group2\n",
    "subprocess.run(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c37556",
   "metadata": {},
   "source": [
    "## Modify optimized cameras to include full field of view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ef8832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_tsai_intrinsics_to_full_fov(\n",
    "    calib_csv_list,\n",
    "    ba_cam_folder,\n",
    "    output_cam_folder,\n",
    "):\n",
    "    os.makedirs(output_cam_folder, exist_ok=True)\n",
    "    cam_list = sorted(glob(os.path.join(ba_cam_folder, '*.tsai')))\n",
    "\n",
    "    for calib_file in calib_csv_list:\n",
    "        print('Processing:',calib_file)\n",
    "        calib = pd.read_csv(calib_file)\n",
    "        calib[\"K\"] = calib[\"K\"].apply(lambda s: np.array(ast.literal_eval(s)))\n",
    "        calib[\"K_full\"] = calib[\"K_full\"].apply(lambda s: np.array(ast.literal_eval(s)))\n",
    "        calib[\"distortion_coefficients\"] = calib[\"distortion_coefficients\"].apply(\n",
    "            lambda s: np.array(ast.literal_eval(s))\n",
    "        )\n",
    "\n",
    "        for _, row in tqdm(calib.iterrows(), total=len(calib)):\n",
    "            image_file = row[\"image_name\"]\n",
    "            image_base = os.path.splitext(os.path.basename(image_file))[0]\n",
    "\n",
    "            # Find matching .tsai camera file\n",
    "            cam_matches = [x for x in cam_list if image_base in os.path.basename(x)]\n",
    "            if not cam_matches:\n",
    "                print(f\"No camera found for {image_base}\")\n",
    "                continue\n",
    "            cam_file = cam_matches[0]\n",
    "\n",
    "            # Read the optimized camera intrinsics from .tsai\n",
    "            with open(cam_file, \"r\") as f:\n",
    "                cam_lines = [l.strip() for l in f.readlines() if l.strip()]\n",
    "\n",
    "            fu = fv = cu = cv = None\n",
    "            for line in cam_lines:\n",
    "                if line.startswith(\"fu\"):\n",
    "                    fu = float(line.split()[-1])\n",
    "                elif line.startswith(\"fv\"):\n",
    "                    fv = float(line.split()[-1])\n",
    "                elif line.startswith(\"cu\"):\n",
    "                    cu = float(line.split()[-1])\n",
    "                elif line.startswith(\"cv\"):\n",
    "                    cv = float(line.split()[-1])\n",
    "\n",
    "            if None in (fu, fv, cu, cv):\n",
    "                print(f\"Missing intrinsic values in {cam_file}\")\n",
    "                continue\n",
    "\n",
    "            # Construct intrinsic matrices\n",
    "            K_opt = np.array([[fu, 0, cu],\n",
    "                              [0, fv, cv],\n",
    "                              [0, 0, 1]])\n",
    "            K_crop = row[\"K\"].reshape(3, 3)\n",
    "            K_full = row[\"K_full\"].reshape(3, 3)\n",
    "\n",
    "            # Calculate transform crop -> full\n",
    "            H = K_full @ np.linalg.inv(K_crop)\n",
    "\n",
    "            # Map optimized intrinsics into full-FOV coordinate system\n",
    "            K_opt_full = H @ K_opt\n",
    "            K_opt_full /= K_opt_full[2, 2]\n",
    "\n",
    "            fu_full = K_opt_full[0, 0]\n",
    "            fv_full = K_opt_full[1, 1]\n",
    "            cu_full = K_opt_full[0, 2]\n",
    "            cv_full = K_opt_full[1, 2]\n",
    "\n",
    "            # Update lines\n",
    "            updated_lines = []\n",
    "            for line in cam_lines:\n",
    "                if line.startswith(\"fu\"):\n",
    "                    updated_lines.append(f\"fu = {fu_full}\")\n",
    "                elif line.startswith(\"fv\"):\n",
    "                    updated_lines.append(f\"fv = {fv_full}\")\n",
    "                elif line.startswith(\"cu\"):\n",
    "                    updated_lines.append(f\"cu = {cu_full}\")\n",
    "                elif line.startswith(\"cv\"):\n",
    "                    updated_lines.append(f\"cv = {cv_full}\")\n",
    "                else:\n",
    "                    updated_lines.append(line)\n",
    "\n",
    "            # Write out new camera file\n",
    "            cam_out_file = os.path.join(\n",
    "                output_cam_folder, os.path.basename(cam_file).replace(\".tsai\", \"_full.tsai\")\n",
    "            )\n",
    "            with open(cam_out_file, \"w\") as f:\n",
    "                f.write(\"\\n\".join(updated_lines) + \"\\n\")\n",
    "\n",
    "\n",
    "calib_list = sorted(glob(os.path.join(undistorted_folder, '*camera_calibration_params.csv')))\n",
    "update_tsai_intrinsics_to_full_fov(calib_list, ba_folder, full_cam_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39935435",
   "metadata": {},
   "source": [
    "## Final orthorectification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9facfc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(final_ortho_folder, exist_ok=True)\n",
    "\n",
    "image_list = sorted(glob(os.path.join(undistorted_folder, '*_full.tiff')))\n",
    "cam_list = sorted(glob(os.path.join(full_cam_folder, '*.tsai')))\n",
    "\n",
    "# Mapproject\n",
    "for image_file, cam_file in zip(image_list, cam_list):\n",
    "    image_out_file = os.path.join(final_ortho_folder, os.path.basename(image_file).replace('.tiff', '_map.tiff'))\n",
    "    cmd = [\n",
    "        'mapproject',\n",
    "        '--threads', '12',\n",
    "        '--nodata-value', 'NaN',\n",
    "        '--tr', '0.003',\n",
    "        refdem_file, image_file, cam_file, image_out_file\n",
    "    ]\n",
    "    subprocess.run(cmd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10dfaba",
   "metadata": {},
   "source": [
    "## Compile outputs for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88a842f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_folder = os.path.join(os.getcwd(), '..', 'inputs')\n",
    "\n",
    "# Initial undistortion parameters\n",
    "calib_file = os.path.join(inputs_folder, 'initial_undistortion_params.csv')\n",
    "# read CSVs\n",
    "calib_files = sorted(glob(os.path.join(undistorted_folder, f\"group*params.csv\")))\n",
    "calib_list = []\n",
    "for file in calib_files:\n",
    "    calib_list += [pd.read_csv(file)]\n",
    "calib = pd.concat(calib_list).reset_index(drop=True)\n",
    "# get camera number for simplicity\n",
    "calib['camera'] = [str(x) if x >= 10 else str(f\"0{x}\") for x in calib.index + 1]\n",
    "# select the rows\n",
    "calib.rename(columns={'distortion_coefficients': 'dist'}, inplace=True)\n",
    "calib = calib[['camera', 'K', 'K_full', 'dist']]\n",
    "# save to file\n",
    "calib.to_csv(\n",
    "    calib_file, sep=',', header=True, index=False\n",
    ")\n",
    "print('Saved compiled initial undistortion parameters:', calib_file)\n",
    "\n",
    "# Full calibrated cameras\n",
    "print('Copying full FOV calibrated cameras to inputs folder')\n",
    "cam_files = sorted(glob(os.path.join(full_cam_folder, '*.tsai')))\n",
    "for cam_file in tqdm(cam_files):\n",
    "    ch = os.path.basename(cam_file).split('ch')[1][0:2]\n",
    "    cam_out_file = os.path.join(inputs_folder, 'calibrated_cameras', f\"ch{ch}_calibrated_camera_full_fov.tsai\")\n",
    "    shutil.copy2(cam_file, cam_out_file)\n",
    "\n",
    "# Cropped calibrated cameras\n",
    "print('Copying cropped FOV calibrated cameras to inputs folder')\n",
    "cam_files = sorted(glob(os.path.join(ba_folder, '*.tsai')))\n",
    "for cam_file in tqdm(cam_files):\n",
    "    ch = os.path.basename(cam_file).split('ch')[1][0:2]\n",
    "    cam_out_file = os.path.join(inputs_folder, 'calibrated_cameras', f\"ch{ch}_calibrated_camera_cropped_fov.tsai\")\n",
    "    shutil.copy2(cam_file, cam_out_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soo_locs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
