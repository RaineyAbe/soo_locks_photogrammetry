{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2c9d518",
   "metadata": {},
   "source": [
    "# Calibrate cameras, create initial orthoimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aac52a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from ast import literal_eval\n",
    "import rasterio\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Locate image files\n",
    "data_folder = '/Users/rdcrlrka/Research/Soo_locks'\n",
    "image_folder = os.path.join(data_folder, 'inputs', 'original_images')\n",
    "image_list = sorted(glob(os.path.join(image_folder, '*.tiff')))\n",
    "print(f\"{len(image_list)} images located\")\n",
    "\n",
    "# Grab other input files\n",
    "gcp_folder = os.path.join(data_folder, 'inputs', 'gcp')\n",
    "refdem_file = os.path.join(data_folder, 'inputs', 'RLS_DSM_filled_cropped.tif')\n",
    "\n",
    "# Define output folders\n",
    "out_folder = os.path.join(data_folder, 'camera_calibration')\n",
    "os.makedirs(out_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c8f447",
   "metadata": {},
   "source": [
    "## Merge GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef6f860",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcp_merged_file = os.path.join(gcp_folder, '..', 'GCP_merged.gpkg')\n",
    "if not os.path.exists(gcp_merged_file):\n",
    "    gdf_list = []\n",
    "    gcp_files = sorted(glob(os.path.join(gcp_folder, '*.csv')))\n",
    "    for f in gcp_files:\n",
    "        df = pd.read_csv(f, header=0)\n",
    "        df['geometry'] = [Point(x,y) for (x,y) in df[['X', 'Y']].values]\n",
    "        gdf = gpd.GeoDataFrame(df, geometry='geometry', crs=\"EPSG:32619\")\n",
    "        \n",
    "        gdf['X'] = [x.coords.xy[0][0] for x in gdf['geometry']]\n",
    "        gdf['Y'] = [x.coords.xy[1][0] for x in gdf['geometry']]\n",
    "\n",
    "        # add channel column\n",
    "        gdf['channel'] = 'ch' + os.path.basename(f).split('ch')[1][0:2]\n",
    "\n",
    "        gdf_list += [gdf]\n",
    "    df_merged = pd.concat(gdf_list).reset_index(drop=True)\n",
    "    # rename image pixel columns\n",
    "    df_merged = df_merged.rename(columns={\n",
    "        'img_px': 'col_sample',\n",
    "        'img_py': 'row_sample'\n",
    "    })\n",
    "    df_merged = df_merged[['channel', 'X', 'Y', 'Z', 'col_sample', 'row_sample', 'geometry']]\n",
    "\n",
    "    gcp_merged = gpd.GeoDataFrame(df_merged, geometry='geometry', crs=\"EPSG:32619\")\n",
    "    gcp_merged.plot(kind='scatter', x='X', y='Y')\n",
    "    plt.show()\n",
    "    gcp_merged.to_file(gcp_merged_file, index=False)\n",
    "    print(f'Merged GCP saved to:\\n{gcp_merged_file}')\n",
    "\n",
    "else:\n",
    "    print('Merged GCP already exists in file, skipping.')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105faf4f",
   "metadata": {},
   "source": [
    "## Calibrate cameras using GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c64d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_cameras(\n",
    "    image_files: list,\n",
    "    gcp_file: str,\n",
    "    plot_results: bool = True,\n",
    "):\n",
    "    # Load GCPs\n",
    "    gcp = gpd.read_file(gcp_file)\n",
    "\n",
    "    # initialize strong vs. all GCP lists. \n",
    "    # Strong images used for intrinsics calibration. Then, all image extrinsics calibrated.\n",
    "    strong_obj_pts = []\n",
    "    strong_img_pts = []\n",
    "    strong_files = []\n",
    "    strong_channels = []\n",
    "\n",
    "    all_obj_list = []\n",
    "    all_img_list = []\n",
    "    all_gcp_frames = []\n",
    "    image_size = None\n",
    "\n",
    "    # build image (pixel) and object (real-world) lists\n",
    "    for image_file in image_files:\n",
    "        ch = 'ch' + os.path.basename(image_file).split('ch')[1][0:2]\n",
    "        gcp_image = gcp.loc[gcp['channel'] == ch].copy()\n",
    "\n",
    "        obj = gcp_image[['X', 'Y', 'Z']].values.astype(np.float64)\n",
    "        img = gcp_image[['col_sample', 'row_sample']].values.astype(np.float64)\n",
    "\n",
    "        # store for extrinsic stage regardless of size\n",
    "        all_obj_list.append(obj.reshape(1, -1, 3))\n",
    "        all_img_list.append(img.reshape(1, -1, 2))\n",
    "        all_gcp_frames.append(gcp_image)\n",
    "\n",
    "        if image_size is None:\n",
    "            im = cv2.imread(image_file, cv2.IMREAD_GRAYSCALE)\n",
    "            image_size = (im.shape[1], im.shape[0])\n",
    "\n",
    "        strong_obj_pts.append(obj.reshape(1, -1, 3))\n",
    "        strong_img_pts.append(img.reshape(1, -1, 2))\n",
    "        strong_files.append(image_file)\n",
    "        strong_channels.append(ch)\n",
    "\n",
    "    if len(strong_obj_pts) == 0:\n",
    "        raise ValueError(\"No images with enough GCPs for intrinsic calibration. Lower min_points_intrinsic or add GCPs.\")\n",
    "\n",
    "    # init intrinsics\n",
    "    fx = np.float64(1000)\n",
    "    fy = np.float64(1200)\n",
    "    K_init = np.array([\n",
    "        [fx, 0, np.float64(image_size[0]) / 2],\n",
    "        [0, fy, np.float64(image_size[1]) / 2],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    D_init = np.zeros((4, 1), dtype=np.float64)\n",
    "    calibration_flags = cv2.fisheye.CALIB_FIX_SKEW + cv2.fisheye.CALIB_RECOMPUTE_EXTRINSIC\n",
    "    termination_criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 1e-9)\n",
    "\n",
    "    print(f\"Using {len(strong_obj_pts)} images for intrinsic calibration.\")\n",
    "\n",
    "    # Calibrate camera fisheye intrinsics\n",
    "    rms, K, D, rvecs, tvecs = cv2.fisheye.calibrate(\n",
    "        strong_obj_pts,\n",
    "        strong_img_pts,\n",
    "        image_size,\n",
    "        K_init,\n",
    "        D_init,\n",
    "        None,\n",
    "        None,\n",
    "        calibration_flags,\n",
    "        termination_criteria\n",
    "    )\n",
    "\n",
    "    print(f\"Intrinsic calibration done. RMS: {rms:.6f}\")\n",
    "\n",
    "    # Estimate K with full field of view (default results in cropped image)\n",
    "    K_full = cv2.fisheye.estimateNewCameraMatrixForUndistortRectify(K, D, image_size, np.eye(3), balance=1.0)\n",
    "\n",
    "    # Calibrate camera extrinsics for all images using solvePnP\n",
    "    results = []\n",
    "    for i, image_file in enumerate(tqdm(image_files, desc=\"Estimating extrinsics\")):\n",
    "        ch = 'ch' + os.path.basename(image_file).split('ch')[1][0:2]\n",
    "\n",
    "        rvec = rvecs[i]\n",
    "        tvec = tvecs[i]\n",
    "        # gcp_image = all_gcp_frames[i].copy()\n",
    "        # obj = all_obj_list[i].reshape(-1, 3)\n",
    "        # img = all_img_list[i].reshape(-1, 2)\n",
    "\n",
    "        # if obj.shape[0] < min_points_extrinsic:\n",
    "        #     print(f\"Skipping extrinsic solve for {os.path.basename(image_file)}: only {obj.shape[0]} points (< {min_points_extrinsic})\")\n",
    "        #     continue\n",
    "\n",
    "        # # undistort to normalized coords\n",
    "        # pts = img.astype(np.float32).reshape(1, -1, 2)\n",
    "        # pts_norm = cv2.fisheye.undistortPoints(pts, K, D)  # shape: (1,N,2)\n",
    "\n",
    "        # # convert normalized coords -> pixel coords using K_full\n",
    "        # pts_norm = pts_norm.reshape(-1, 2)\n",
    "        # pts_pix = cv2.convertPointsToHomogeneous(pts_norm).reshape(-1, 3)  # (x, y, 1)\n",
    "        # pts_pix = (K_full @ pts_pix.T).T[:, :2]  # (N, 2)\n",
    "\n",
    "        # retval, rvec, tvec = cv2.solvePnP(\n",
    "        #     obj.astype(np.float64),\n",
    "        #     pts_pix.astype(np.float64),\n",
    "        #     K_full,\n",
    "        #     None,\n",
    "        #     flags=cv2.SOLVEPNP_ITERATIVE\n",
    "        # )\n",
    "        # if not retval:\n",
    "        #     print(f\"solvePnP failed for {image_file}\")\n",
    "        #     continue\n",
    "\n",
    "        # store results\n",
    "        r = {\n",
    "            \"channel\": int(ch[2:]),\n",
    "            \"K\": K.tolist(),\n",
    "            \"dist\": D.tolist(),\n",
    "            \"K_full\": K_full.tolist(),\n",
    "            \"rvec\": rvec.reshape(-1).tolist(),\n",
    "            \"tvec\": tvec.reshape(-1).tolist(),\n",
    "        }\n",
    "        results.append(r)\n",
    "\n",
    "        # plot results\n",
    "        if plot_results:\n",
    "            image = cv2.imread(image_file, cv2.IMREAD_GRAYSCALE)\n",
    "            # create undistort map and undistort\n",
    "            map1, map2 = cv2.fisheye.initUndistortRectifyMap(K, D, np.eye(3), K_full, image_size, cv2.CV_16SC2)\n",
    "            image_undistorted = cv2.remap(image, map1, map2, interpolation=cv2.INTER_LINEAR)\n",
    "            mask = np.ones(image.shape, dtype=np.uint8) * 255\n",
    "            mask_undistorted = cv2.remap(mask, map1, map2, interpolation=cv2.INTER_NEAREST)\n",
    "            valid_mask = mask_undistorted > 0\n",
    "            image_undistorted_nodata = image_undistorted.astype(np.float32)\n",
    "            image_undistorted_nodata[~valid_mask] = np.nan\n",
    "\n",
    "            # undistort points using fisheye.undistortPoints\n",
    "            image_pts = img.astype(np.float32).reshape(1, -1, 2)\n",
    "            undistorted_pts = cv2.fisheye.undistortPoints(image_pts, K, D, P=K_full).reshape(-1, 2)\n",
    "            gcp_image['col_sample_undistorted'] = undistorted_pts[:, 0]\n",
    "            gcp_image['row_sample_undistorted'] = undistorted_pts[:, 1]\n",
    "\n",
    "            fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "            ax[0].imshow(image, cmap='gray')\n",
    "            ax[0].plot(gcp_image['col_sample'], gcp_image['row_sample'], 'xr')\n",
    "            ax[1].imshow(image_undistorted, cmap='gray')\n",
    "            ax[1].plot(gcp_image['col_sample_undistorted'], gcp_image['row_sample_undistorted'], 'xr')\n",
    "            fig.suptitle(os.path.basename(image_file))\n",
    "            for a in ax:\n",
    "                a.set_xticks([])\n",
    "                a.set_yticks([])\n",
    "            fig.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df\n",
    "\n",
    "\n",
    "### CALIBRATE CAMERAS IN GROUPS ###\n",
    "# Define groups\n",
    "# group_images = [\n",
    "#     image_list[0:8], \n",
    "#     image_list[8:15],\n",
    "#     image_list[15:18],\n",
    "#     image_list[18:22],\n",
    "#     image_list[22:]\n",
    "# ]\n",
    "group_images = [[image] for image in image_list]\n",
    "\n",
    "for i, g_images in enumerate(group_images):\n",
    "\n",
    "    print(f'\\nGROUP {i+1}:\\n--------')\n",
    "\n",
    "    try:\n",
    "        # Calibrate cameras\n",
    "        results_df = calibrate_cameras(\n",
    "            image_files = g_images,\n",
    "            gcp_file = gcp_merged_file, \n",
    "            plot_results = False\n",
    "            )\n",
    "        \n",
    "        # Save calibrated camera specs\n",
    "        results_file = os.path.join(out_folder, f\"group{i+1}_calbration_params.csv\")\n",
    "        results_df.to_csv(results_file, index=False, header=True)\n",
    "        print('Calibrated cameras saved to file')\n",
    "    except:\n",
    "        print(\"FAILED\")\n",
    "        continue\n",
    "\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c25b18",
   "metadata": {},
   "source": [
    "## Combine calibration parameters into one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f117a516",
   "metadata": {},
   "outputs": [],
   "source": [
    "calib_files = sorted(glob(os.path.join(out_folder, '*.csv')))\n",
    "calib_list = []\n",
    "for calib_file in calib_files:\n",
    "    calib_list += [pd.read_csv(calib_file)]\n",
    "calib = pd.concat(calib_list).reset_index(drop=True)\n",
    "calib\n",
    "# Evaluate values\n",
    "for k in ['K', 'dist', 'K_full', 'rvec', 'tvec']:\n",
    "    calib[k] = calib[k].apply(literal_eval)\n",
    "calib = calib.sort_values(by='channel')\n",
    "out_file = os.path.join(out_folder, \"original_calibrated_cameras.csv\")\n",
    "calib.to_csv(out_file, index=False)\n",
    "print(f'Merged calibration parameters saved to:\\n{out_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5de299f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot camera centers\n",
    "\n",
    "def camera_center_from_rt(rvec, tvec):\n",
    "    rvec = np.asarray(rvec, dtype=float).reshape(3)\n",
    "    tvec = np.asarray(tvec, dtype=float).reshape(3)\n",
    "\n",
    "    R, _ = cv2.Rodrigues(rvec)\n",
    "\n",
    "    C = -R.T @ tvec\n",
    "    return C\n",
    "\n",
    "# Apply to your dataframe\n",
    "calib['cam_center'] = calib.apply(lambda row: camera_center_from_rt(row['rvec'], row['tvec']), axis=1)\n",
    "\n",
    "# Extract coordinates into separate columns\n",
    "calib[['cx','cy','cz']] = pd.DataFrame(calib['cam_center'].tolist(), index=calib.index)\n",
    "\n",
    "calib.plot(x='cx', y='cy', kind='scatter')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85964097",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rt_from_camera_center(rvec, C):\n",
    "    rvec = np.asarray(rvec, dtype=float).reshape(3)\n",
    "    C = np.asarray(C, dtype=float).reshape(3)\n",
    "\n",
    "    # rotation matrix\n",
    "    R, _ = cv2.Rodrigues(rvec)\n",
    "\n",
    "    # inverse of camera_center_from_rt:\n",
    "    # C = -R.T @ t  â†’  t = -R @ C\n",
    "    tvec = -R @ C\n",
    "\n",
    "    return tvec\n",
    "\n",
    "C1 = np.array([266504.559392, 4.691321e+06, 181.850910])\n",
    "C2 = np.array([266499.233621, 4.691320e+06, 181.823417])\n",
    "rvec = np.array([-3.0946134401757095, -0.21939730731184545, -0.12865256676878867])\n",
    "\n",
    "tvec1 = rt_from_camera_center(rvec, C1)\n",
    "tvec2 = rt_from_camera_center(rvec, C2)\n",
    "\n",
    "print(tvec1)\n",
    "print(tvec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7593aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "23\t[[2378.638636917316, 0.0, 2278.9747663716175], [0.0, 2378.929659808212, 1273.6454222674124], [0.0, 0.0, 1.0]]\t[[-0.09827590766055995], [0.09173511868102373], [-0.06486618695342697], [0.007577770497528054]]\t[[1382.2348473658133, 0.0, 2295.164359756932], [0.0, 1382.4039617386038, 1272.1228937442452], [0.0, 0.0, 1.0]]\t[3.0971599447015805, 0.23554003658122544, 0.10409368288105521]\t[-930559.17975548, 4604233.84936232, 120862.36654376]\n",
    "24\t[[2378.638636917316, 0.0, 2278.9747663716175], [0.0, 2378.929659808212, 1273.6454222674124], [0.0, 0.0, 1.0]]\t[[-0.09827590766055995], [0.09173511868102373], [-0.06486618695342697], [0.007577770497528054]]\t[[1382.2348473658133, 0.0, 2295.164359756932], [0.0, 1382.4039617386038, 1272.1228937442452], [0.0, 0.0, 1.0]]\t[3.0971599447015805, 0.23554003658122544, 0.10409368288105521]\t[-930553.78091779, 4604233.60295167, 120862.76205105]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soo_locks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
